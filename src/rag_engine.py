# src/rag_engine.py â€” RAG ìœ í‹¸(ì„ë² ë”© 1íšŒ + LLM 2ê°œ) + ì·¨ì†Œ(ìº”ìŠ¬) ì§€ì›
#                     + tqdm ì½˜ì†” ì§„í–‰ë°” ì–µì œ(ì—°ê²° ë¦¬ì…‹/ë¡œê·¸ ìŠ¤íŒ¸ ë°©ì§€)

from __future__ import annotations
import os, json, shutil, re
from typing import Callable, Any, Mapping

# ğŸ”‡ tqdm(ì½˜ì†” ì§„í–‰ë°”) ì–µì œ â€” Streamlit Cloud ë¡œê·¸ ìŠ¤íŒ¸/ì›Œì»¤ë¶€í•˜ ì™„í™”
os.environ.setdefault("TQDM_DISABLE", "1")

import streamlit as st
from src.config import settings

# (ì„ íƒ) llama_index ë¡œê·¸ ì–µì œ â€” ê³¼ë„í•œ ë””ë²„ê·¸ ì¶œë ¥ ë°©ì§€
import logging
logging.getLogger("llama_index").setLevel(logging.WARNING)

# ì·¨ì†Œ ì‹ í˜¸ìš© ì˜ˆì™¸
class CancelledError(Exception):
    """ì‚¬ìš©ìê°€ 'ì·¨ì†Œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹¤í–‰ì„ ì¤‘ë‹¨í–ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤."""
    pass

# ============================================================================
# 0) ê³µí†µ: ì„œë¹„ìŠ¤ê³„ì • JSON ì •ê·œí™” + Drive ì„œë¹„ìŠ¤
# ============================================================================

def _normalize_sa(raw_sa: Any | None) -> Mapping[str, Any] | None:
    """ì„œë¹„ìŠ¤ê³„ì • JSONì„ dictë¡œ ì •ê·œí™”(+private_key ê°œí–‰ ë³´ì •)"""
    if raw_sa is None:
        return None
    if isinstance(raw_sa, Mapping):
        return dict(raw_sa)

    if isinstance(raw_sa, str):
        s = raw_sa.strip()
        if not s:
            return None
        # 1) ì •ìƒ JSON ì‹œë„
        try:
            return json.loads(s)
        except Exception:
            pass
        # 2) private_key ê°œí–‰ ë³´ì •
        try:
            m = re.search(r'"private_key"\s*:\s*"(?P<key>.*?)"', s, re.DOTALL)
            if m:
                key = m.group("key")
                key_fixed = key.replace("\r\n", "\n").replace("\n", "\\n")
                s_fixed = s[:m.start("key")] + key_fixed + s[m.end("key"):]
                return json.loads(s_fixed)
        except Exception:
            pass
    return None

def _build_drive_service(creds_dict):
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    scopes = ["https://www.googleapis.com/auth/drive.readonly"]
    creds = service_account.Credentials.from_service_account_info(creds_dict, scopes=scopes)
    return build("drive", "v3", credentials=creds, cache_discovery=False)

# ============================================================================
# 1) ì„ë² ë”©/LLM ì´ˆê¸°í™” (ì„ë² ë”© 1íšŒ, LLMì€ í•„ìš” ìˆ˜ë§Œí¼)
# ============================================================================

def set_embed_provider(provider: str, api_key: str, embed_model: str):
    """ì„ë² ë”© ê³µê¸‰ìë§Œ ì§€ì •í•´ Settings.embed_model ì„¤ì •"""
    from llama_index.core import Settings
    p = (provider or "google").lower()
    try:
        if p == "openai":
            from llama_index.embeddings.openai import OpenAIEmbedding as _EMB
            Settings.embed_model = _EMB(model=embed_model, api_key=api_key)
        else:
            from llama_index.embeddings.google_genai import GoogleGenAIEmbedding as _EMB
            Settings.embed_model = _EMB(model_name=embed_model, api_key=api_key)

        # ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸
        _ = Settings.embed_model.get_text_embedding("ping")
    except Exception as e:
        st.error("ì„ë² ë”© ì´ˆê¸°í™” ì‹¤íŒ¨ â€” í‚¤/ëª¨ë¸/íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        with st.expander("ìì„¸í•œ ì˜¤ë¥˜ ë³´ê¸°", expanded=True):
            st.exception(e)
        st.stop()

def make_llm(provider: str, api_key: str, llm_model: str, temperature: float = 0.0):
    """ê³µê¸‰ìì˜ LLM ì¸ìŠ¤í„´ìŠ¤ë§Œ ë§Œë“¤ì–´ ë°˜í™˜(SettingsëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)"""
    p = (provider or "google").lower()
    try:
        if p == "openai":
            from llama_index.llms.openai import OpenAI as _LLM
            return _LLM(model=llm_model, api_key=api_key, temperature=temperature)
        else:
            from llama_index.llms.google_genai import GoogleGenAI as _LLM
            return _LLM(model=llm_model, api_key=api_key, temperature=temperature)
    except Exception as e:
        st.error(f"{provider} LLM ì´ˆê¸°í™” ì‹¤íŒ¨ â€” í‚¤/ëª¨ë¸ì„ í™•ì¸í•˜ì„¸ìš”.")
        with st.expander("ìì„¸í•œ ì˜¤ë¥˜ ë³´ê¸°", expanded=True):
            st.exception(e)
        st.stop()

# ============================================================================
# 2) Drive í…ŒìŠ¤íŠ¸/ë¯¸ë¦¬ë³´ê¸°
# ============================================================================

def smoke_test_drive() -> tuple[bool, str]:
    folder_id = settings.GDRIVE_FOLDER_ID
    if not str(folder_id).strip():
        return (False, "GDRIVE_FOLDER_IDê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤. Secretsì— ê°’ì„ ì¶”ê°€í•˜ì„¸ìš”.")

    sa = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
    if not sa:
        return (False, "GOOGLE_SERVICE_ACCOUNT_JSON(ì„œë¹„ìŠ¤ê³„ì •) íŒŒì‹± ì‹¤íŒ¨")

    try:
        svc = _build_drive_service(sa)
        svc.files().get(fileId=folder_id, fields="id").execute()
        return (True, "Google Drive ì—°ê²° OK")
    except Exception as e:
        return (False, f"Drive ì—°ê²° ì ê²€ ì‹¤íŒ¨: {e}")

def preview_drive_files(max_items: int = 10) -> tuple[bool, str, list[dict]]:
    folder_id = settings.GDRIVE_FOLDER_ID
    sa = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
    if not sa or not str(folder_id).strip():
        return (False, "ì„œë¹„ìŠ¤ê³„ì •/í´ë” ID ì„¤ì •ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.", [])

    try:
        svc = _build_drive_service(sa)
        q = f"'{folder_id}' in parents and trashed=false"
        fields = "files(id,name,mimeType,modifiedTime), nextPageToken"
        resp = svc.files().list(
            q=q,
            orderBy="modifiedTime desc",
            pageSize=max_items,
            fields=fields,
            supportsAllDrives=True,
            includeItemsFromAllDrives=True,
        ).execute()
        files = resp.get("files", [])
        rows = [{
            "name": f.get("name"),
            "link": f"https://drive.google.com/file/d/{f.get('id')}/view",
            "mime": f.get("mimeType"),
            "modified": f.get("modifiedTime"),
        } for f in files]
        return (True, f"{len(rows)}ê°œ íŒŒì¼", rows)
    except Exception as e:
        return (False, f"ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", [])

# ============================================================================
# 3) ì¸ë±ìŠ¤ ë¡œë”©/ë¹Œë“œ & ë³€ê²½ ê°ì§€(ë§¤ë‹ˆí˜ìŠ¤íŠ¸) + ì·¨ì†Œ ì§€ì›
# ============================================================================

def _fetch_drive_manifest(creds_dict, folder_id: str, is_cancelled: Callable[[], bool] | None = None) -> dict:
    svc = _build_drive_service(creds_dict)
    files = []
    page_token = None
    q = f"'{folder_id}' in parents and trashed=false"
    fields = "nextPageToken, files(id,name,mimeType,modifiedTime,md5Checksum,size)"
    while True:
        if is_cancelled and is_cancelled():
            raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì¡°íšŒ ì¤‘)")
        resp = svc.files().list(
            q=q, fields=fields, pageToken=page_token,
            pageSize=1000, supportsAllDrives=True, includeItemsFromAllDrives=True
        ).execute()
        files.extend(resp.get("files", []))
        page_token = resp.get("nextPageToken")
        if not page_token:
            break
    return {
        f["id"]: {
            "name": f.get("name"),
            "mimeType": f.get("mimeType"),
            "modifiedTime": f.get("modifiedTime"),
            "md5": f.get("md5Checksum"),
            "size": f.get("size"),
        } for f in files
    }

def _load_local_manifest(path: str) -> dict | None:
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as fp:
                return json.load(fp)
        except Exception:
            return None
    return None

def _save_local_manifest(path: str, m: dict) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as fp:
        json.dump(m, fp, ensure_ascii=False, indent=2, sort_keys=True)

def _manifests_differ(local: dict | None, remote: dict) -> bool:
    if local is None:
        return True
    if set(local.keys()) != set(remote.keys()):
        return True
    for fid, r in remote.items():
        l = local.get(fid, {})
        if l.get("md5") and r.get("md5"):
            if l["md5"] != r["md5"]:
                return True
        if l.get("modifiedTime") != r.get("modifiedTime"):
            return True
    return False

@st.cache_resource(show_spinner=False)
def _load_index_from_disk(persist_dir: str):
    from llama_index.core import StorageContext, load_index_from_storage
    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
    return load_index_from_storage(storage_context)

def _build_index_with_progress(update_pct: Callable[[int, str | None], None],
                               update_msg: Callable[[str], None],
                               gdrive_folder_id: str,
                               gcp_creds: Mapping[str, Any],
                               persist_dir: str,
                               max_docs: int | None = None,
                               is_cancelled: Callable[[], bool] | None = None):
    """ì¸ë±ìŠ¤ ì‹ ê·œ ìƒì„±(ì·¨ì†Œ ì²´í¬ ì§€ì›)"""
    from llama_index.core import VectorStoreIndex
    from llama_index.readers.google import GoogleDriveReader

    if is_cancelled and is_cancelled():
        raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ì´ˆê¸° ë‹¨ê³„)")

    update_pct(5, "Google Drive ì¸ì¦ ì¤€ë¹„")
    if not gcp_creds:
        st.error("âŒ ì„œë¹„ìŠ¤ê³„ì • JSONì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    if is_cancelled and is_cancelled():
        raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ë¦¬ë” ì´ˆê¸°í™” ì „)")

    update_pct(15, "Drive ë¦¬ë” ì´ˆê¸°í™”")
    try:
        try:
            loader = GoogleDriveReader(service_account_key=gcp_creds)   # ì‹ í˜•
        except TypeError:
            loader = GoogleDriveReader(gcp_creds_dict=gcp_creds)        # êµ¬í˜•
    except Exception as e:
        st.error("Google Drive ë¦¬ë” ì´ˆê¸°í™” ì‹¤íŒ¨")
        with st.expander("ìì„¸í•œ ì˜¤ë¥˜ ë³´ê¸°", expanded=True):
            st.exception(e)
        st.stop()

    if is_cancelled and is_cancelled():
        raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ë¬¸ì„œ ë¡œë“œ ì „)")

    update_pct(30, "ë¬¸ì„œ ë¡œë“œ ì¤‘â€¦")
    try:
        documents = loader.load_data(folder_id=gdrive_folder_id)
    except Exception as e:
        st.error("Google Driveì—ì„œ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ìì„¸í•œ ì˜¤ë¥˜ ë³´ê¸°", expanded=True):
            st.exception(e)
        st.stop()

    if is_cancelled and is_cancelled():
        raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ë¬¸ì„œ ë¡œë“œ í›„)")

    # ë¹ ë¥¸ ëª¨ë“œ: ê°œìˆ˜ ì œí•œ
    if max_docs and len(documents) > max_docs:
        documents = documents[:max_docs]
        update_msg(f"ë¹ ë¥¸ ëª¨ë“œ: ì²˜ìŒ {max_docs}ê°œ ë¬¸ì„œë§Œ ì¸ë±ì‹±")

    update_pct(60, f"ë¬¸ì„œ {len(documents)}ê°œ â†’ ì¸ë±ìŠ¤ ìƒì„±")
    if is_cancelled and is_cancelled():
        raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ì¸ë±ìŠ¤ ìƒì„± ì „)")

    try:
        # âœ… tqdm ì½˜ì†” ì§„í–‰ë°” ë„ê¸°: show_progress=False
        index = VectorStoreIndex.from_documents(documents, show_progress=False)
    except Exception as e:
        st.error("ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ìì„¸í•œ ì˜¤ë¥˜ ë³´ê¸°", expanded=True):
            st.exception(e)
        st.stop()

    if is_cancelled and is_cancelled():
        raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ì¸ë±ìŠ¤ ìƒì„± í›„)")

    update_pct(90, "ë‘ë‡Œ ì €ì¥ ì¤‘")
    try:
        index.storage_context.persist(persist_dir=persist_dir)
    except Exception as e:
        st.error("ì¸ë±ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ìì„¸í•œ ì˜¤ë¥˜ ë³´ê¸°", expanded=True):
            st.exception(e)
        st.stop()

    update_pct(100, "ì™„ë£Œ")
    return index

def get_or_build_index(update_pct: Callable[[int, str | None], None],
                       update_msg: Callable[[str], None],
                       gdrive_folder_id: str,
                       raw_sa: Any | None,
                       persist_dir: str,
                       manifest_path: str,
                       max_docs: int | None = None,
                       is_cancelled: Callable[[], bool] | None = None):
    """ë³€ê²½ ì—†ìœ¼ë©´ ë¡œë”©, ìˆìœ¼ë©´ ë¹Œë“œ(ì·¨ì†Œ ì²´í¬ ì§€ì›)"""
    gcp_creds = _normalize_sa(raw_sa)
    if not gcp_creds:
        st.error("ì„œë¹„ìŠ¤ê³„ì • JSON íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    update_pct(5, "ë“œë¼ì´ë¸Œ ë³€ê²½ í™•ì¸ ì¤‘â€¦")
    remote = _fetch_drive_manifest(gcp_creds, gdrive_folder_id, is_cancelled=is_cancelled)
    local = _load_local_manifest(manifest_path)

    if is_cancelled and is_cancelled():
        raise CancelledError("ì‚¬ìš©ì ì·¨ì†Œ(ë³€ê²½ í™•ì¸ ë‹¨ê³„)")

    if os.path.exists(persist_dir) and not _manifests_differ(local, remote):
        update_pct(25, "ë³€ê²½ ì—†ìŒ â†’ ì €ì¥ëœ ë‘ë‡Œ ë¡œë”©")
        idx = _load_index_from_disk(persist_dir)
        update_pct(100, "ì™„ë£Œ!")
        return idx

    if os.path.exists(persist_dir):
        shutil.rmtree(persist_dir)

    update_pct(40, "ë³€ê²½ ê°ì§€ â†’ ì¸ë±ìŠ¤ ìƒì„±")
    idx = _build_index_with_progress(
        update_pct, update_msg, gdrive_folder_id, gcp_creds, persist_dir,
        max_docs=max_docs, is_cancelled=is_cancelled
    )

    _save_local_manifest(manifest_path, remote)
    update_pct(100, "ì™„ë£Œ!")
    return idx

# ============================================================================
# 4) QA ìœ í‹¸
# ============================================================================

def get_text_answer(query_engine, question: str, system_prompt: str) -> str:
    """ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ + ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•©ì³ ì¿¼ë¦¬í•˜ê³ , ì¶œì²˜ íŒŒì¼ëª…ì„ í•¨ê»˜ ë°˜í™˜."""
    try:
        full_query = (
            f"{system_prompt}\n\n"
            "[ì§€ì‹œì‚¬í•­] ë°˜ë“œì‹œ ì—…ë¡œë“œëœ ê°•ì˜ ìë£Œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ê³ , "
            "ê·¼ê±°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ë°í˜€ë¼.\n\n"
            f"[í•™ìƒì˜ ì§ˆë¬¸]\n{question}"
        )
        response = query_engine.query(full_query)
        answer_text = str(response)
        try:
            files = [n.metadata.get("file_name", "ì•Œ ìˆ˜ ì—†ìŒ")
                     for n in getattr(response, "source_nodes", [])]
            source_files = ", ".join(sorted(set(files))) if files else "ì¶œì²˜ ì •ë³´ ì—†ìŒ"
        except Exception:
            source_files = "ì¶œì²˜ ì •ë³´ ì—†ìŒ"

        return f"{answer_text}\n\n---\n*ì°¸ê³  ìë£Œ: {source_files}*"
    except Exception as e:
        return f"í…ìŠ¤íŠ¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
