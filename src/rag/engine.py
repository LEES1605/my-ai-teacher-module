# src/rag/engine.py
from __future__ import annotations
import os, json
from datetime import datetime
from typing import Callable, Any

import streamlit as st
from src.config import settings
from .drive import (
    _normalize_sa, _validate_sa, fetch_drive_manifest,
    try_restore_index_from_drive, export_brain_to_drive, prune_old_backups,
    INDEX_BACKUP_PREFIX,
)
from .checkpoint import CHECKPOINT_PATH
from .index_build import build_index_with_checkpoint

def get_or_build_index(
    update_pct: Callable[[int, str | None], None],
    update_msg: Callable[[str], None],
    gdrive_folder_id: str,
    raw_sa: Any | None,
    persist_dir: str,
    manifest_path: str,
    should_stop: Callable[[], bool] | None = None,
):
    """
    Drive ë³€ê²½ì„ ê°ì§€í•´ ì €ì¥ë³¸ì„ ì“°ê±°ë‚˜, ë³€ê²½ ì‹œì—ë§Œ ì¬ì¸ë±ì‹±(ì²´í¬í¬ì¸íŠ¸ & ì¤‘ì§€ ì§€ì›).
    + (ì˜µì…˜) ë¡œì»¬ ì €ì¥ë³¸ ì—†ìœ¼ë©´ ë“œë¼ì´ë¸Œ ë°±ì—…ì—ì„œ ìë™ ë³µì›
    + (ì˜µì…˜) ë¹Œë“œ ì„±ê³µ ì‹œ ìë™ ë°±ì—… ì—…ë¡œë“œ + ë³´ê´€ Nê°œ ìœ ì§€
    """
    update_pct(5, "ë“œë¼ì´ë¸Œ ë³€ê²½ í™•ì¸ ì¤‘â€¦")
    gcp_creds = _validate_sa(_normalize_sa(raw_sa))

    # 0) ë¡œì»¬ ì €ì¥ë³¸ì´ ì—†ê³  ìë™ ë³µì›ì´ ì¼œì ¸ ìˆìœ¼ë©´ ì‹œë„
    if settings.AUTO_RESTORE_ON_START and not os.path.exists(persist_dir):
        update_msg("ğŸ—‚ï¸ ë¡œì»¬ ì €ì¥ë³¸ ì—†ìŒ â†’ ë“œë¼ì´ë¸Œ ë°±ì—… ìë™ ë³µì› ì‹œë„")
        try:
            restored = try_restore_index_from_drive(gcp_creds, persist_dir, gdrive_folder_id)
            if restored:
                update_msg("âœ… ë“œë¼ì´ë¸Œ ë°±ì—… ë³µì› ì™„ë£Œ")
                update_pct(20, None)
        except Exception:
            # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ì²˜ìŒë¶€í„° ë¹Œë“œ)
            pass

    # 1) ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¹„êµ
    remote = fetch_drive_manifest(gcp_creds, gdrive_folder_id)

    local = None
    if os.path.exists(manifest_path):
        try:
            with open(manifest_path, "r", encoding="utf-8") as fp:
                local = json.load(fp)
        except Exception:
            local = None

    def _manifests_differ(local_m: dict | None, remote_m: dict) -> bool:
        if local_m is None:
            return True
        if set(local_m.keys()) != set(remote_m.keys()):
            return True
        for fid, r in remote_m.items():
            l = local_m.get(fid, {})
            if l.get("md5") and r.get("md5"):
                if l["md5"] != r["md5"]:
                    return True
            if l.get("modifiedTime") != r.get("modifiedTime"):
                return True
        return False

    # ë³€ê²½ ì—†ìŒ â†’ ì €ì¥ë³¸ ë°”ë¡œ ë¡œë“œ
    if os.path.exists(persist_dir) and not _manifests_differ(local, remote):
        update_pct(25, "ë³€ê²½ ì—†ìŒ â†’ ì €ì¥ëœ ë‘ë‡Œ ë¡œë”©")
        from llama_index.core import StorageContext, load_index_from_storage
        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
        idx = load_index_from_storage(storage_context)
        update_pct(100, "ì™„ë£Œ!")
        return idx

    # ë³€ê²½ ìˆìŒ â†’ ì²´í¬í¬ì¸íŠ¸ ì´ì–´ì„œ ë¹Œë“œ
    update_pct(40, "ë³€ê²½ ê°ì§€ â†’ ì „ì²˜ë¦¬/ì²­í‚¹/ì¸ë±ìŠ¤ ìƒì„± (ì²´í¬í¬ì¸íŠ¸)")
    idx = build_index_with_checkpoint(
        update_pct, update_msg, gdrive_folder_id, gcp_creds, persist_dir, remote,
        should_stop=should_stop
    )

    # 'ì™„ì£¼' ìƒíƒœë©´ ìƒˆ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì €ì¥ + ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬ + (ì˜µì…˜) ìë™ ë°±ì—…
    try:
        if not (should_stop and should_stop()):
            os.makedirs(os.path.dirname(manifest_path), exist_ok=True)
            with open(manifest_path, "w", encoding="utf-8") as fp:
                json.dump(remote, fp, ensure_ascii=False, indent=2, sort_keys=True)
            # ì™„ë£Œ ì—¬ë¶€ ê°„ë‹¨ ì²´í¬: ì²´í¬í¬ì¸íŠ¸ì˜ í‚¤ì…‹ê³¼ remote í‚¤ì…‹ì´ ê°™ìœ¼ë©´ ì™„ë£Œ
            if os.path.exists(CHECKPOINT_PATH):
                with open(CHECKPOINT_PATH, "r", encoding="utf-8") as f:
                    cp = json.load(f)
                if set(cp.keys()) == set(remote.keys()):
                    try:
                        os.remove(CHECKPOINT_PATH)
                    except Exception:
                        pass

            # âœ… ìë™ ë°±ì—…(ì˜µì…˜)
            if settings.AUTO_BACKUP_ON_SUCCESS:
                update_msg("â˜ï¸ ë°±ì—… ì—…ë¡œë“œ ì¤‘â€¦")
                fname = f"{INDEX_BACKUP_PREFIX}-{datetime.now():%Y%m%d_%H%M%S}.zip"
                try:
                    _, name = export_brain_to_drive(gcp_creds, persist_dir, gdrive_folder_id, filename=fname)
                    update_msg(f"âœ… ë°±ì—… ì—…ë¡œë“œ ì™„ë£Œ: {name}")
                except Exception as e:
                    update_msg(f"âš ï¸ ë°±ì—… ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

                # ë³´ê´€ ê°œìˆ˜ ìœ ì§€
                try:
                    deleted = prune_old_backups(gcp_creds, gdrive_folder_id, keep=settings.BACKUP_KEEP_N)
                    if deleted:
                        update_msg(f"ğŸ§¹ ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ {len(deleted)}ê±´")
                except Exception:
                    pass

    except Exception:
        pass

    update_pct(100, "ì™„ë£Œ!")
    return idx

def get_text_answer(query_engine, question: str, system_prompt: str) -> str:
    """ì§ˆì˜ì‘ë‹µ(ì¶œì²˜ íŒŒì¼ëª… í‘œì‹œ)."""
    try:
        full_query = (
            f"{system_prompt}\n\n"
            "[ì§€ì‹œì‚¬í•­] ë°˜ë“œì‹œ ì—…ë¡œë“œëœ ê°•ì˜ ìë£Œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ê³ , "
            "ê·¼ê±°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ë°í˜€ë¼.\n\n"
            f"[í•™ìƒì˜ ì§ˆë¬¸]\n{question}"
        )
        response = query_engine.query(full_query)
        answer_text = str(response)
        try:
            files = [n.metadata.get("file_name", "ì•Œ ìˆ˜ ì—†ìŒ") for n in getattr(response, "source_nodes", [])]
            source_files = ", ".join(sorted(list(set(files)))) if files else "ì¶œì²˜ ì •ë³´ ì—†ìŒ"
        except Exception:
            source_files = "ì¶œì²˜ ì •ë³´ ì—†ìŒ"
        return f"{answer_text}\n\n---\n*ì°¸ê³  ìë£Œ: {source_files}*"
    except Exception as e:
        return f"í…ìŠ¤íŠ¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
