# app.py â€” ìŠ¤í… ì¸ë±ì‹±(ì¤‘ê°„ì·¨ì†Œ/ì¬ê°œ) + ë‘ë‡Œì¤€ë¹„ ì•ˆì •í™”
#        + ì¸ë±ì‹± ë³´ê³ ì„œ(ìŠ¤í‚µ í‘œì‹œ)
#        + Drive ëŒ€í™”ë¡œê·¸ ì €ì¥(â¶ OAuth: Markdown / â· ì„œë¹„ìŠ¤ê³„ì •: JSONL, chat_log/)
#        + í˜ë¥´ì†Œë‚˜: ğŸ¤–Gemini(ì¹œì ˆ/ê¼¼ê¼¼), ğŸ¤–ChatGPT(ìœ ë¨¸ëŸ¬ìŠ¤/ë³´ì™„)

from __future__ import annotations
import os, time, uuid, re, json
import pandas as pd
import streamlit as st

# ============= 0) í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ìµœìƒë‹¨) ====================================
st.set_page_config(page_title="ë‚˜ì˜ AI ì˜ì–´ êµì‚¬", layout="wide", initial_sidebar_state="collapsed")

# ============= 1) ë¶€íŠ¸ ê°€ë“œ & ëŸ°íƒ€ì„ ì•ˆì •í™” ===================================
ss = st.session_state
ss.setdefault("_boot_log", [])
ss.setdefault("_oauth_checked", False)

def _boot(msg: str): ss["_boot_log"].append(msg)

with st.sidebar:
    st.caption("ğŸ›  Boot log (ì„ì‹œ)")
    _boot_box = st.empty()

def _flush_boot():
    try:
        _boot_box.write("\n".join(ss["_boot_log"]) or "(empty)")
    except Exception:
        pass

_boot("A: page_config set"); _flush_boot()

# ëŸ°íƒ€ì„ íŠœë‹(ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤/ê²½í•© ë°©ì§€)
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_SERVER_ENABLE_WEBSOCKET_COMPRESSION"] = "false"

# ============= 2) ì„¸ì…˜ í‚¤ ì´ˆê¸°í™” ==============================================
ss.setdefault("session_id", uuid.uuid4().hex[:12])
ss.setdefault("messages", [])
ss.setdefault("auto_save_chatlog", True)    # OAuth Markdown ì €ì¥(ë‚´ ë“œë¼ì´ë¸Œ)
ss.setdefault("save_logs", False)           # SA JSONL ì €ì¥(ê³µìœ ë“œë¼ì´ë¸Œ writer í•„ìš”)
ss.setdefault("prep_both_running", False)
ss.setdefault("prep_both_done", ("qe_google" in ss) or ("qe_openai" in ss))
ss.setdefault("prep_cancel_requested", False)
ss.setdefault("session_terminated", False)
ss.setdefault("index_job", None)

# (ì§„ë‹¨) í•˜íŠ¸ë¹„íŠ¸
st.caption(f"heartbeat âœ… keys={list(ss.keys())[:8]}")

# ============= 3) ê¸°ë³¸ UI í—¤ë”/ìŠ¤íƒ€ì¼ =========================================
from src.ui import load_css, render_header
load_css()
render_header()
st.info("âœ… ë³€ê²½ì´ ìˆì„ ë•Œë§Œ ì¸ë±ì‹±í•©ë‹ˆë‹¤. ì €ì¥ëœ ë‘ë‡Œê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ë¡œë“œí•©ë‹ˆë‹¤. (ì¤‘ê°„ ì·¨ì†Œ/ì¬ê°œ ì§€ì›)")

# ============= 4) OAuth ë¦¬ë‹¤ì´ë ‰íŠ¸ ì²˜ë¦¬(ìµœì¢…í™” 1íšŒë§Œ) ==========================
#  - ì´ì „ ì½”ë“œì— ìˆì—ˆë˜ ì´ì¤‘ í˜¸ì¶œì„ ì œê±°í•˜ì—¬ ê¹”ë”í•˜ê²Œ ìœ ì§€
try:
    from src.google_oauth import finish_oauth_if_redirected
    if not st.secrets.get("OAUTH_DISABLE_FINISH"):
        if not ss.get("_oauth_finalized", False):
            finalized = finish_oauth_if_redirected()
            if finalized:
                ss["_oauth_finalized"] = True
                try:
                    st.query_params.clear()
                except Exception:
                    st.experimental_set_query_params()
                st.rerun()
except Exception as e:
    st.warning(f"OAuth finalize skipped: {e}")

# ============= 5) ì‚¬ì´ë“œë°”: OAuth ë¡œê·¸ì¸/ë¡œê·¸ì•„ì›ƒ, ì €ì¥ ì˜µì…˜ ==================
from src.google_oauth import start_oauth, is_signed_in, build_drive_service, get_user_email, sign_out
with st.sidebar:
    ss.auto_save_chatlog = st.toggle(
        "ëŒ€í™” ìë™ ì €ì¥ (OAuth/ë‚´ ë“œë¼ì´ë¸Œ, Markdown)",
        value=ss.auto_save_chatlog
    )
    ss.save_logs = st.toggle(
        "ëŒ€í™” JSONL ì €ì¥ (ì„œë¹„ìŠ¤ê³„ì •/chat_log/)",
        value=ss.save_logs,
        help="ê³µìœ ë“œë¼ì´ë¸Œ Writer ê¶Œí•œ í•„ìš”. ì¿¼í„° ë¬¸ì œ ì‹œ ë„ê¸° ê¶Œì¥."
    )
    st.markdown("---")
    st.markdown("### Google ë¡œê·¸ì¸ (ë‚´ ë“œë¼ì´ë¸Œ ì €ì¥)")
    if not is_signed_in():
        if st.button("ğŸ” Googleë¡œ ë¡œê·¸ì¸"):
            url = start_oauth()
            st.markdown(f"[ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ ë¡œê·¸ì¸í•˜ì„¸ìš”]({url})")
    else:
        st.success(f"ë¡œê·¸ì¸ë¨: {get_user_email() or 'ì•Œ ìˆ˜ ì—†ìŒ'}")
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            sign_out()
            st.rerun()

# ============= 6) Google Drive ì—°ê²° í…ŒìŠ¤íŠ¸(ì•ˆì •í™” ë²„ì „) ========================
st.markdown("## ğŸ”— Google Drive ì—°ê²° í…ŒìŠ¤íŠ¸")
st.caption("ì„œë¹„ìŠ¤ê³„ì • ì €ì¥ì€ ê³µìœ ë“œë¼ì´ë¸Œ Writer ê¶Œí•œì´ í•„ìš”. ì¸ë±ì‹±ì€ Readonlyë©´ ì¶©ë¶„í•©ë‹ˆë‹¤.")

from src.config import settings
from src.rag_engine import smoke_test_drive, preview_drive_files, drive_diagnostics

try:
    ok_sa, head_sa, details_sa = drive_diagnostics(settings.GDRIVE_FOLDER_ID)  # (ok, í—¤ë“œë¼ì¸, ìƒì„¸ ë¦¬ìŠ¤íŠ¸[str])
    if ok_sa:
        st.success(head_sa)
    else:
        st.warning(head_sa)
    with st.expander("ì„œë¹„ìŠ¤ê³„ì • JSON ì§„ë‹¨ ìƒì„¸", expanded=not ok_sa):
        st.code("\n".join(details_sa), language="text")
except Exception as e:
    st.warning("ì§„ë‹¨ í•¨ìˆ˜ ì˜ˆì™¸:")
    st.code(
        f"{type(e).__name__}: {e}\n"
        f"íƒ€ì…={type(settings.GDRIVE_SERVICE_ACCOUNT_JSON).__name__}\n"
        f"í”„ë¦¬ë·°={str(settings.GDRIVE_SERVICE_ACCOUNT_JSON)[:200]}...",
        language="text"
    )

colL, colR = st.columns([0.65, 0.35], vertical_alignment="top")

with colL:
    if st.button("í´ë” íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ìµœì‹  10ê°œ)", use_container_width=True):
        ok, msg, rows = preview_drive_files(max_items=10)
        if ok and rows:
            df = pd.DataFrame(rows)
            # ë³´ê¸° ì¹œí™”ì ìœ¼ë¡œ ê°€ê³µ
            df["type"] = df["mime"].str.replace("application/vnd.google-apps.", "", regex=False)
            df = df.rename(columns={"modified": "modified_at"})[["name","link","type","modified_at"]]
            st.dataframe(
                df,
                use_container_width=True,
                height=360,
                column_config={
                    "name": st.column_config.TextColumn("íŒŒì¼ëª…"),
                    "link": st.column_config.LinkColumn("open", display_text="ì—´ê¸°"),
                    "type": st.column_config.TextColumn("ìœ í˜•"),
                    "modified_at": st.column_config.TextColumn("ìˆ˜ì •ì‹œê°"),
                },
                hide_index=True
            )
            st.success(f"ì´ {len(rows)}ê°œ í•­ëª© í‘œì‹œ (ìµœì‹  10ê°œ ê¸°ì¤€).")
        elif ok:
            st.info("í´ë”ì— íŒŒì¼ì´ ì—†ê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error(msg)

with colR:
    ok, msg = smoke_test_drive()
    if ok:
        st.success(msg)     # âš ï¸ ë°˜í™˜ê°’ì„ st.write ë“±ìœ¼ë¡œ ë‹¤ì‹œ ì°ì§€ ì•ŠìŒ
    else:
        st.warning(msg)

# ============= 6.5) ğŸ“¤ ê´€ë¦¬ì: ìë£Œ ì—…ë¡œë“œ (ì›ë³¸ â†’ prepared ì €ì¥) ===============
with st.expander("ğŸ“¤ ê´€ë¦¬ì: ìë£Œ ì—…ë¡œë“œ (ì›ë³¸â†’prepared ì €ì¥)", expanded=False):
    st.caption(
        "ì›ë³¸ íŒŒì¼ì„ prepared í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì¶”ì¶œë¬¼ì€ ì¸ë±ìŠ¤ ìºì‹œì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.\n"
        "ë¡œì»¬ íŒŒì¼ ì—…ë¡œë“œ + Google Docs/Slides/Sheets URL ê°€ì ¸ì˜¤ê¸° ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.\n"
        "ì˜µì…˜ì„ ì¼œë©´ AIê°€ ì œëª©ì„ ì •í•´ íŒŒì¼ëª…ì„ ë³€ê²½í•©ë‹ˆë‹¤."
    )

    # â”€â”€ ì˜µì…˜: AIê°€ ì œëª© ìë™ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    auto_title = st.toggle("AI ì œëª© ìë™ ìƒì„±(ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸° í›„ ì´ë¦„ ë°”ê¾¸ê¸°)", value=True,
                           help="LLMì´ ì§§ê³  ëª…í™•í•œ ì œëª©ì„ ë½‘ì•„ íŒŒì¼ëª…ì„ ë°”ê¿‰ë‹ˆë‹¤. í‚¤ê°€ ì—†ìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì œëª© ìƒì„±.")
    title_hint = st.text_input("ì œëª© íŒíŠ¸(ì„ íƒ)", placeholder="ì˜ˆ: ê³ 1 ì˜ì–´ ë¬¸ë²• / í•™ì› êµì¬ / ì¤‘ê°„ê³ ì‚¬ ëŒ€ë¹„ ë“±")

    # â”€â”€ (A) ë¡œì»¬ íŒŒì¼ ì—…ë¡œë“œ: ì—¬ëŸ¬ í˜•ì‹ ì§€ì› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SUPPORTED_TYPES = [
        "pdf", "docx", "doc", "pptx", "ppt", "md", "txt", "rtf", "odt", "html", "epub",
        "xlsx", "xls", "csv"
    ]
    files = st.file_uploader(
        "ë¡œì»¬ íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
        type=SUPPORTED_TYPES,
        accept_multiple_files=True
    )

    # â”€â”€ (B) Google Docs/Slides/Sheets URLë¡œ ê°€ì ¸ì˜¤ê¸° (ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—¬ëŸ¬ ê°œ) â”€â”€â”€â”€â”€â”€â”€
    gdocs_urls = st.text_area(
        "Google Docs/Slides/Sheets URL ë¶™ì—¬ë„£ê¸° (ì—¬ëŸ¬ ê°œë©´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
        placeholder="ì˜ˆ) https://docs.google.com/document/d/............/edit\nhttps://docs.google.com/presentation/d/............/edit",
        height=96
    )

    # ì§„í–‰/ìƒíƒœ ì˜ì—­
    prog = st.progress(0, text="ëŒ€ê¸° ì¤‘â€¦")
    status_area = st.empty()
    result_area = st.empty()

    # â”€â”€ ìœ í‹¸: íƒ€ì„ìŠ¤íƒ¬í”„/íŒŒì¼ëª… ì •ë¦¬/í™•ì¥ìâ†’MIME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _ts():
        import time
        return time.strftime("%Y%m%d_%H%M%S")

    def _safe_name(name: str) -> str:
        import re
        # Windows/NIX ê¸ˆì§€ë¬¸ì ì œê±°
        name = re.sub(r'[\\/:*?"<>|]+', " ", name)
        name = re.sub(r"\s+", " ", name).strip()
        return name or "untitled"

    def _guess_mime_by_ext(fname: str) -> str:
        ext = (fname.rsplit(".", 1)[-1] if "." in fname else "").lower()
        MIMES = {
            "pdf":  "application/pdf",
            "docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "doc":  "application/msword",
            "pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
            "ppt":  "application/vnd.ms-powerpoint",
            "md":   "text/markdown",
            "txt":  "text/plain",
            "rtf":  "application/rtf",
            "odt":  "application/vnd.oasis.opendocument.text",
            "html": "text/html",
            "epub": "application/epub+zip",
            "xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            "xls":  "application/vnd.ms-excel",
            "csv":  "text/csv",
        }
        return MIMES.get(ext, "application/octet-stream")

    def _parse_gdoc_id(s: str) -> str | None:
        import re
        s = s.strip()
        if not s:
            return None
        for pat in [r"/d/([-\w]{15,})", r"[?&]id=([-\w]{15,})$", r"^([-\w]{15,})$"]:
            m = re.search(pat, s)
            if m:
                return m.group(1)
        return None

# â”€â”€ AI ì œëª© ìƒì„±ê¸°(LLM + íœ´ë¦¬ìŠ¤í‹±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from src.rag_engine import make_llm, llm_complete

def _get_title_model():
    """OpenAI ìˆìœ¼ë©´ OpenAI, ì—†ìœ¼ë©´ Gemini, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ None"""
    global _TITLE_MODEL                      # â† nonlocal ëŒ€ì‹  global ì‚¬ìš©
    if _TITLE_MODEL is not None:
        return _TITLE_MODEL
    try:
        from src.config import settings
        if getattr(settings, "OPENAI_API_KEY", None) and settings.OPENAI_API_KEY.get_secret_value():
            _TITLE_MODEL = make_llm(
                "openai",
                settings.OPENAI_API_KEY.get_secret_value(),
                getattr(settings, "OPENAI_LLM_MODEL", "gpt-4o-mini"),
                0.2,
            )
            return _TITLE_MODEL
        # OpenAI í‚¤ ì—†ìœ¼ë©´ Geminië¡œ
        _TITLE_MODEL = make_llm(
            "google",
            settings.GEMINI_API_KEY.get_secret_value(),
            getattr(settings, "LLM_MODEL", "gemini-1.5-pro"),
            0.2,
        )
        return _TITLE_MODEL
    except Exception:
        return None

def _heuristic_title(orig_base: str, hint: str = "") -> str:
    """í™•ì¥ì ì œê±°ëœ ì›ë˜ ì´ë¦„ + íŒíŠ¸ë¥¼ ê¹”ë”íˆ ì •ë¦¬í•´ 40ì ë‚´ë¡œ"""
    import re
    base = orig_base
    base = re.sub(r"\.[^.]+$", "", base)            # .ext ì œê±°
    base = re.sub(r"^\d{8}_\d{6}__", "", base)      # íƒ€ì„ìŠ¤íƒ¬í”„ íŒ¨í„´ ì œê±°
    base = base.replace("_", " ").replace("-", " ")
    base = re.sub(r"\s+", " ", base).strip()
    if hint:
        base = f"{hint.strip()} â€” {base}" if base else hint.strip()
    return (base[:40]).strip() or "untitled"

def _ai_title(orig_base: str, sample_text: str = "", hint: str = "") -> str:
    """LLMìœ¼ë¡œ ì§§ì€ í•œêµ­ì–´ ì œëª© ìƒì„±(ìµœëŒ€ 40ì). ì‹¤íŒ¨ ì‹œ íœ´ë¦¬ìŠ¤í‹±."""
    model = _get_title_model()
    if model is None:
        return _heuristic_title(orig_base, hint)

    prompt = (
        "ë‹¤ìŒ íŒŒì¼ì˜ ì œëª©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ê·œì¹™:\n"
        "1) ìµœëŒ€ 40ì, 2) ë¶ˆí•„ìš”í•œ ìˆ«ì/í™•ì¥ì ì œê±°, 3) í•µì‹¬ í‚¤ì›Œë“œ ìœ„ì£¼, 4) ë”°ì˜´í‘œ/ê´„í˜¸ ë‚¨ë°œ ê¸ˆì§€,\n"
        "5) ë¬¸ì¥í˜• ë§íˆ¬ë³´ë‹¤ ëª…ì‚¬êµ¬ ì„ í˜¸, 6) ì¶œë ¥ì€ ì œëª©ë§Œ(ë¶€ê°€ ì„¤ëª…/ë”°ì˜´í‘œ X).\n\n"
        f"[íŒŒì¼ëª… íŒíŠ¸]\n{orig_base}\n\n"
    )
    if hint:
        prompt += f"[ì¶”ê°€ íŒíŠ¸]\n{hint}\n\n"
    if sample_text:
        prompt += f"[ë³¸ë¬¸ ì¼ë¶€]\n{sample_text[:1200]}\n\n"

    try:
        title = llm_complete(model, prompt).strip()
        # ì•ˆì „í™” (ì•„ë˜ _safe_nameì€ ê°™ì€ ì„¹ì…˜ì— ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)
        title = _safe_name(title)
        return (title[:40]).strip() or _heuristic_title(orig_base, hint)
    except Exception:
        return _heuristic_title(orig_base, hint)

    # â”€â”€ ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸° ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.button("ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸° â†’ prepared", type="primary"):
        import io, time
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaIoBaseUpload
        from googleapiclient.errors import HttpError
        from src.rag_engine import _normalize_sa
        from src.config import settings
        from src.google_oauth import is_signed_in, build_drive_service

        # ì„œë¹„ìŠ¤ê³„ì • Drive(ì“°ê¸°), OAuth Drive(ìˆìœ¼ë©´ ì½ê¸°/ë³µì‚¬)
        creds_sa = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
        drive_sa = build("drive", "v3", credentials=creds_sa)
        drive_oauth = build_drive_service() if is_signed_in() else None

        rows, done, total_steps = [], 0, 1
        if files: total_steps += len(files)
        url_list = [u.strip() for u in (gdocs_urls.splitlines() if gdocs_urls else []) if u.strip()]
        if url_list: total_steps += len(url_list)

        def _tick(msg):
            nonlocal done
            done += 1
            pct = int(done / max(total_steps, 1) * 100)
            prog.progress(pct, text=msg)
            status_area.info(msg)

        # ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸° ê²°ê³¼(Drive id, name, link) ì €ì¥
        created = []  # [{id, name, link, ext, orig_base, sample_text?}]

        try:
            # 1) ë¡œì»¬ íŒŒì¼ ì—…ë¡œë“œ
            if files:
                for f in files:
                    data = f.read()
                    buf = io.BytesIO(data)
                    base = _safe_name(f.name)
                    ext = (base.rsplit(".", 1)[-1].lower() if "." in base else "")
                    name = f"{_ts()}__{base}"
                    mime = _guess_mime_by_ext(base)

                    media = MediaIoBaseUpload(buf, mimetype=mime, resumable=False)
                    meta = {"name": name, "parents": [settings.GDRIVE_FOLDER_ID]}
                    _tick(f"ì—…ë¡œë“œ ì¤‘: {name}")
                    res = drive_sa.files().create(body=meta, media_body=media, fields="id,webViewLink").execute()
                    created.append({"id": res["id"], "name": name, "link": res.get("webViewLink",""),
                                    "ext": ext, "orig_base": base, "sample_text": ""})

                    time.sleep(0.05)

            # 2) Google ë¬¸ì„œ ë§í¬ â†’ export/copy í›„ ì €ì¥
            for raw in url_list:
                file_id = _parse_gdoc_id(raw)
                if not file_id:
                    rows.append({"name": f"(ì˜ëª»ëœ ë§í¬) {raw[:40]}â€¦", "open": ""})
                    _tick("ì˜ëª»ëœ ë§í¬ ê±´ë„ˆëœ€")
                    continue

                drive_ro = drive_oauth or drive_sa  # ë¡œê·¸ì¸ë˜ì–´ ìˆìœ¼ë©´ OAuth ìš°ì„ 
                try:
                    meta = drive_ro.files().get(fileId=file_id, fields="id,name,mimeType").execute()
                    name0 = meta.get("name", "untitled")
                    mtype = meta.get("mimeType", "")
                except HttpError as he:
                    if drive_ro is drive_oauth:
                        try:
                            meta = drive_sa.files().get(fileId=file_id, fields="id,name,mimeType").execute()
                            name0 = meta.get("name", "untitled")
                            mtype = meta.get("mimeType", "")
                            drive_ro = drive_sa
                        except Exception as e2:
                            rows.append({"name": f"(ì ‘ê·¼ ì‹¤íŒ¨) {raw[:40]}â€¦", "open": f"{type(e2).__name__}: ê¶Œí•œ í•„ìš”"})
                            _tick("ì ‘ê·¼ ì‹¤íŒ¨(ê³µìœ  í•„ìš”)")
                            continue
                    else:
                        rows.append({"name": f"(ì ‘ê·¼ ì‹¤íŒ¨) {raw[:40]}â€¦", "open": f"{type(he).__name__}: ê¶Œí•œ í•„ìš”"})
                        _tick("ì ‘ê·¼ ì‹¤íŒ¨(ê³µìœ  í•„ìš”)")
                        continue

                GOOGLE_NATIVE = {
                    "application/vnd.google-apps.document": ("application/pdf", ".pdf"),
                    "application/vnd.google-apps.presentation": ("application/pdf", ".pdf"),
                    "application/vnd.google-apps.spreadsheet": ("application/pdf", ".pdf"),
                }

                if mtype in GOOGLE_NATIVE:
                    export_mime, ext = GOOGLE_NATIVE[mtype]
                    _tick(f"ë‚´ë³´ë‚´ëŠ” ì¤‘: {name0}{ext} (Google ë¬¸ì„œ)")
                    data = drive_ro.files().export(fileId=file_id, mimeType=export_mime).execute()
                    buf = io.BytesIO(data)
                    name = f"{_ts()}__{_safe_name(name0)}{ext}"
                    media = MediaIoBaseUpload(buf, mimetype=export_mime, resumable=False)
                    meta2 = {"name": name, "parents": [settings.GDRIVE_FOLDER_ID]}
                    res2 = drive_sa.files().create(body=meta2, media_body=media, fields="id,webViewLink").execute()
                    created.append({"id": res2["id"], "name": name, "link": res2.get("webViewLink",""),
                                    "ext": ext.strip("."), "orig_base": name0, "sample_text": ""})
                else:
                    # ë„¤ì´í‹°ë¸Œê°€ ì•„ë‹Œ ê²½ìš°: preparedë¡œ ë³µì‚¬
                    _tick(f"ë³µì‚¬ ì¤‘: {name0} (íŒŒì¼)")
                    body = {"name": f"{_ts()}__{_safe_name(name0)}", "parents": [settings.GDRIVE_FOLDER_ID]}
                    try:
                        res3 = drive_sa.files().copy(fileId=file_id, body=body, fields="id,webViewLink").execute()
                    except HttpError:
                        if drive_oauth:
                            res3 = drive_oauth.files().copy(fileId=file_id, body=body, fields="id,webViewLink").execute()
                        else:
                            rows.append({"name": f"(ë³µì‚¬ ì‹¤íŒ¨) {name0}", "open": "ê¶Œí•œ ë¶€ì¡± â€” ì„œë¹„ìŠ¤ê³„ì •ì— ê³µìœ í•˜ê±°ë‚˜ OAuth ë¡œê·¸ì¸"})
                            continue
                    created.append({"id": res3["id"], "name": body["name"], "link": res3.get("webViewLink",""),
                                    "ext": "", "orig_base": name0, "sample_text": ""})
                    time.sleep(0.05)

            # 3) (ì˜µì…˜) AI ì œëª©ìœ¼ë¡œ íŒŒì¼ëª… ë³€ê²½
            renamed_rows = []
            if auto_title and created:
                used = set()
                for item in created:
                    fid = item["id"]
                    old_name = item["name"]
                    ext = f".{item['ext']}" if item.get("ext") else ""
                    # ìƒ˜í”Œ í…ìŠ¤íŠ¸ í™•ë³´: ê°„ë‹¨íˆ ì›ë˜ ì´ë¦„ë§Œìœ¼ë¡œë„ ê°€ëŠ¥, í…ìŠ¤íŠ¸ íŒŒì¼/MDë©´ ì¼ë¶€ ë³¸ë¬¸ê¹Œì§€
                    sample = ""
                    if item.get("ext") in {"txt", "md"}:
                        # í…ìŠ¤íŠ¸/MDëŠ” ì›ë³¸ ì—…ë¡œë“œ ì „ì—ë„ ì½ì„ ìˆ˜ ìˆì§€ë§Œ ì§€ê¸ˆì€ ì´ë¯¸ ì—…ë¡œë“œ ìƒíƒœ.
                        # ê°„ë‹¨íˆ íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œë„ ì¶©ë¶„. (ì¶”í›„ Drive download í›„ ë³¸ë¬¸ ì‚¬ìš© ê°€ëŠ¥)
                        sample = ""

                    ai_title = _ai_title(item.get("orig_base", old_name), sample_text=sample, hint=title_hint)
                    # ìµœì¢… íŒŒì¼ëª…: íƒ€ì„ìŠ¤íƒ¬í”„__AIì œëª© + ì›ë˜ í™•ì¥ì
                    new_name = f"{_ts()}__{ai_title}{ext}"
                    new_name = _safe_name(new_name)
                    # ì¤‘ë³µ ìµœì†Œí™”(ë™ì¼ ë°°ì¹˜ ë‚´)
                    k = new_name; n = 2
                    while k in used:
                        k = f"{new_name} ({n})"; n += 1
                    new_name = k; used.add(new_name)

                    try:
                        upd = drive_sa.files().update(fileId=fid, body={"name": new_name}).execute()
                        renamed_rows.append({"original": old_name, "renamed_to": new_name, "open": item["link"]})
                    except Exception as e:
                        renamed_rows.append({"original": old_name, "renamed_to": f"(ì´ë¦„ ë³€ê²½ ì‹¤íŒ¨) {e}", "open": item["link"]})
            else:
                for item in created:
                    renamed_rows.append({"original": item["name"], "renamed_to": "(AI ì œëª© ìƒì„± êº¼ì§)", "open": item["link"]})

            # 4) ê²°ê³¼ í‘œì‹œ
            prog.progress(100, text="ì™„ë£Œ")
            status_area.success(f"ì´ {len(created)}ê°œ í•­ëª© ì²˜ë¦¬ ì™„ë£Œ (prepared)")
            if renamed_rows:
                import pandas as pd
                df = pd.DataFrame(renamed_rows)
                result_area.dataframe(
                    df, use_container_width=True, hide_index=True,
                    column_config={
                        "original": st.column_config.TextColumn("ì›ë˜ íŒŒì¼ëª…"),
                        "renamed_to": st.column_config.TextColumn("ë³€ê²½ í›„ íŒŒì¼ëª…"),
                        "open": st.column_config.LinkColumn("ì—´ê¸°", display_text="ì—´ê¸°")
                    }
                )
            st.toast("ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ â€” ë³€ê²½ ì‚¬í•­ì€ ì¸ë±ì‹± ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.", icon="âœ…")

            # ì¸ë±ì‹±ì„ ë‹¤ì‹œ ëŒë¦´ ìˆ˜ ìˆë„ë¡ ì¤€ë¹„ ë²„íŠ¼ ì¬í™œì„±í™”
            ss.prep_both_done = False

        except Exception as e:
            prog.progress(0, text="ì˜¤ë¥˜")
            status_area.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
# ==============================================================================

# ============= 6.7) ğŸ“š ë¬¸ë²•ì„œ í† í”½ë³„ ì†Œì±…ì ìƒì„±(Drive ì €ì¥) =====================
with st.expander("ğŸ“š ë¬¸ë²•ì„œ í† í”½ë³„ ì†Œì±…ì ìƒì„±(Drive ì €ì¥)", expanded=False):
    st.caption(
        "ì›ë³¸ì€ prepared/ì— ê·¸ëŒ€ë¡œ ë‘ê³ , ë¬¸ë²• í† í”½ë³„ ìµœì í™”ëœ ì†Œì±…ì(.md)ë¥¼ "
        "prepared_volumes/ í•˜ìœ„ í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤. overview.mdì™€ manifest.jsonë„ í•¨ê»˜ ìƒì„±í•©ë‹ˆë‹¤."
    )

    default_topics = [
        "Parts of Speech(í’ˆì‚¬)", "Articles(ê´€ì‚¬)", "Nouns & Pronouns(ëª…ì‚¬/ëŒ€ëª…ì‚¬)",
        "Verbs & Tenses(ì‹œì œ: í˜„ì¬/ê³¼ê±°/ì™„ë£Œ/ì§„í–‰)", "Modals(ì¡°ë™ì‚¬)", "Passive(ìˆ˜ë™íƒœ)",
        "Gerunds & Infinitives(ë™ëª…ì‚¬/ë¶€ì •ì‚¬)", "Adjectives & Adverbs(í˜•ìš©ì‚¬/ë¶€ì‚¬/ë¹„êµê¸‰)",
        "Prepositions(ì „ì¹˜ì‚¬)", "Phrasal Verbs(êµ¬ë™ì‚¬)", "Conjunctions & Clauses(ì ‘ì†ì‚¬/ì ˆ)",
        "Conditionals(ì¡°ê±´ë¬¸)", "Relative Clauses(ê´€ê³„ì‚¬ì ˆ)", "Reported Speech(í™”ë²•ì „í™˜)",
        "Questions & Negation(ì˜ë¬¸ë¬¸/ë¶€ì •ë¬¸)", "Sentence Structure(ë¬¸ì¥êµ¬ì¡°Â·ì–´ìˆœ)"
    ]
    topics_text = st.text_area(
        "í† í”½ ëª©ë¡(ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„, ìˆ˜ì • ê°€ëŠ¥)", 
        value="\n".join(default_topics), height=200
    )
    booklet_title = st.text_input("ì†Œì±…ì ì„¸íŠ¸ ì œëª©(í´ë”ëª…)", value="Grammar Booklets")
    make_citations = st.toggle("ì†Œì±…ì í•˜ë‹¨ì— â€˜ì°¸ê³  ìë£Œ(ì¶œì²˜)â€™ í¬í•¨", value=True)
    start_btn = st.button("í† í”½ë³„ ì†Œì±…ì ìƒì„± â†’ Drive ì €ì¥", type="primary", use_container_width=True)

    if start_btn:
        if "qe_google" not in ss:
            st.warning("ë¨¼ì € ìƒë‹¨ì˜ [ğŸš€ í•œ ë²ˆì— ì¤€ë¹„í•˜ê¸°]ë¡œ ì¸ë±ìŠ¤ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.")
        else:
            import re, json, time, io
            import pandas as pd
            from googleapiclient.discovery import build
            from googleapiclient.http import MediaIoBaseUpload
            from src.rag_engine import _normalize_sa, get_text_answer
            from src.config import settings

            def _ts(): return time.strftime("%Y%m%d_%H%M%S")
            def _safe(s: str) -> str:
                s = re.sub(r'[\\/:*?"<>|]+', " ", str(s))
                s = re.sub(r"\s+", " ", s).strip()
                return s[:120] or "untitled"

            # 1) Drive ì¤€ë¹„: prepared_volumes/<ì„¸íŠ¸ëª…_íƒ€ì„ìŠ¤íƒ¬í”„>/ ìƒì„±
            creds = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
            drive = build("drive", "v3", credentials=creds)

            def _ensure_child(parent_id: str, name: str) -> str:
                q = (
                    f"'{parent_id}' in parents and name = '{name}' "
                    "and mimeType = 'application/vnd.google-apps.folder' and trashed = false"
                )
                res = drive.files().list(
                    q=q, fields="files(id,name)", pageSize=1,
                    includeItemsFromAllDrives=True, supportsAllDrives=True
                ).execute()
                files = res.get("files", [])
                if files: 
                    return files[0]["id"]
                meta = {"name": name, "parents":[parent_id], "mimeType": "application/vnd.google-apps.folder"}
                f = drive.files().create(body=meta, fields="id").execute()
                return f["id"]

            parent_volumes_id = _ensure_child(settings.GDRIVE_FOLDER_ID, "prepared_volumes")
            set_name = f"{_safe(booklet_title)}_{_ts()}"
            set_folder = _ensure_child(parent_volumes_id, set_name)

            # 2) í† í”½ë³„ ìƒì„±
            topics = [t.strip() for t in topics_text.splitlines() if t.strip()]
            prog = st.progress(0, text="ìƒì„± ì¤‘â€¦")
            table_rows, manifest = [], {"title": booklet_title, "created_at": _ts(), "items": []}

            for i, topic in enumerate(topics, start=1):
                # í”„ë¡¬í”„íŠ¸(ì›ì „ ê¸°ë°˜ ìš”ì•½)
                guide = (
                    "ë‹¹ì‹ ì€ ì˜ì–´ ë¬¸ë²• êµì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ í† í”½ì„ í•™ìƒìš© ì†Œì±…ì í˜•íƒœë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n"
                    f"â€¢ í† í”½: {topic}\n"
                    "â€¢ í•µì‹¬ ê°œë…ì„ í•œêµ­ì–´ë¡œ, ê·œì¹™/í˜•íƒœëŠ” ì˜ë¬¸ í˜¼ìš©\n"
                    "â€¢ ì˜ˆë¬¸ 3~5ê°œ (ì‰¬ìš´â†’ì¤‘ê°„ ë‚œì´ë„), í•œ-ì˜ ë³‘ê¸°\n"
                    "â€¢ ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜/ì˜¤ê°œë… 3ê°œ ì •ë¦¬\n"
                    "â€¢ ë¯¸ë‹ˆ ì—°ìŠµë¬¸ì œ 5ë¬¸í•­(+ì •ë‹µ/í•´ì„¤)\n"
                    "â€¢ ë¶„ëŸ‰ 500~900ì ë‚´ì™¸\n"
                )
                if make_citations:
                    guide += "â€¢ ë§ˆì§€ë§‰ì— â€˜---\\n*ì°¸ê³  ìë£Œ: íŒŒì¼ëª… â€¦â€™ ì„¹ì…˜ í¬í•¨\n"

                # ìƒì„±
                md = get_text_answer(
                    ss["qe_google"],
                    f"[í† í”½]\n{topic}\n\n[ê³¼ì œ]\nìœ„ ê°€ì´ë“œë¥¼ ë”°ë¥´ë˜, í•™ìƒìš© ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±",
                    guide,
                )
                name = f"{_safe(topic)}.md"

                # Driveì— ì—…ë¡œë“œ
                buf = io.BytesIO(md.encode("utf-8"))
                media = MediaIoBaseUpload(buf, mimetype="text/markdown", resumable=False)
                meta = {"name": name, "parents": [set_folder]}
                file = drive.files().create(body=meta, media_body=media, fields="id,webViewLink").execute()

                table_rows.append({"topic": topic, "open": file.get("webViewLink")})
                manifest["items"].append({"topic": topic, "file_id": file["id"], "name": name})

                prog.progress(int(i/len(topics)*100), text=f"[{i}/{len(topics)}] {topic}")

            # 3) overview.md & manifest.json ì €ì¥
            overview_lines = [f"# {booklet_title}", "", f"ìƒì„±ì‹œê°: {time.strftime('%Y-%m-%d %H:%M:%S')} (KST)", ""]
            for it in manifest["items"]:
                overview_lines.append(f"- {it['topic']} â€” {it['name']}")
            overview_md = "\n".join(overview_lines) + "\n"

            # overview
            ov_buf = io.BytesIO(overview_md.encode("utf-8"))
            ov_meta = {"name": "overview.md", "parents": [set_folder]}
            ov_media = MediaIoBaseUpload(ov_buf, mimetype="text/markdown", resumable=False)
            ov_file = drive.files().create(body=ov_meta, media_body=ov_media, fields="id,webViewLink").execute()

            # manifest
            mf_buf = io.BytesIO(json.dumps(manifest, ensure_ascii=False, indent=2).encode("utf-8"))
            mf_meta = {"name": "manifest.json", "parents": [set_folder]}
            mf_media = MediaIoBaseUpload(mf_buf, mimetype="application/json", resumable=False)
            mf_file = drive.files().create(body=mf_meta, media_body=mf_media, fields="id,webViewLink").execute()

            prog.progress(100, text="ì™„ë£Œ")
            st.success(f"ì´ {len(table_rows)}ê°œ ì†Œì±…ì ìƒì„± â†’ í´ë”: prepared_volumes/{set_name}")
            if table_rows:
                st.dataframe(
                    pd.DataFrame(table_rows),
                    use_container_width=True, hide_index=True,
                    column_config={
                        "topic": st.column_config.TextColumn("í† í”½"),
                        "open": st.column_config.LinkColumn("ì—´ê¸°", display_text="ì—´ê¸°")
                    }
                )
            st.toast("Drive ì €ì¥ ì™„ë£Œ â€” ì›ë³¸ì€ prepared/ ìœ ì§€, ì†Œì±…ìëŠ” prepared_volumes/ ë³´ê´€", icon="âœ…")
# ===============================================================================

# ============= 7) ì¸ë±ì‹± ë³´ê³ ì„œ(ìŠ¤í‚µëœ íŒŒì¼ í¬í•¨) ===============================
rep = ss.get("indexing_report")
if rep:
    with st.expander("ğŸ§¾ ì¸ë±ì‹± ë³´ê³ ì„œ (ìŠ¤í‚µëœ íŒŒì¼ ë³´ê¸°)", expanded=False):
        st.write(
            f"ì´ íŒŒì¼(ë§¤ë‹ˆí˜ìŠ¤íŠ¸): {rep.get('total_manifest')}, "
            f"ë¡œë”©ëœ ë¬¸ì„œ ìˆ˜: {rep.get('loaded_docs')}, "
            f"ìŠ¤í‚µ: {rep.get('skipped_count')}"
        )
        skipped = rep.get("skipped", [])
        if skipped:
            st.dataframe(pd.DataFrame(skipped), use_container_width=True, hide_index=True)
        else:
            st.caption("ìŠ¤í‚µëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ ğŸ‰")

# ============= 8) ë‘ë‡Œ ì¤€ë¹„(ì¦ë¶„ ì¸ë±ì‹± Â· ì¤‘ê°„ì·¨ì†Œ/ì¬ê°œ) =======================
st.markdown("---")
st.subheader("ğŸ§  ë‘ë‡Œ ì¤€ë¹„ â€” ì €ì¥ë³¸ ë¡œë“œ â†” ë³€ê²½ ì‹œ ì¦ë¶„ ì¸ë±ì‹± (ì¤‘ê°„ ì·¨ì†Œ/ì¬ê°œ)")

c_g, c_o = st.columns(2)
with c_g: st.caption("Gemini ì§„í–‰"); g_bar = st.empty(); g_msg = st.empty()
with c_o: st.caption("ChatGPT ì§„í–‰"); o_bar = st.empty(); o_msg = st.empty()

def _render_progress(slot_bar, slot_msg, pct: int, msg: str | None = None):
    p = max(0, min(100, int(pct)))
    slot_bar.markdown(
        f"<div class='gp-wrap'><div class='gp-fill' style='width:{p}%'></div>"
        f"<div class='gp-label'>{p}%</div></div>",
        unsafe_allow_html=True
    )
    if msg is not None:
        slot_msg.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)

def _is_cancelled() -> bool:
    return bool(ss.get("prep_cancel_requested", False))

from src.rag_engine import (
    set_embed_provider, make_llm, CancelledError,
    start_index_builder, resume_index_builder, cancel_index_builder,
    get_text_answer, llm_complete,   # ëŒ€í™” ë‹¨ê³„ì—ì„œ ì¬ì‚¬ìš©
)

def run_prepare_both_step():
    # 1) ì„ë² ë”© ì„¤ì • (OpenAI ìš°ì„ , ì—†ìœ¼ë©´ Google)
    embed_provider = "openai"
    embed_api = (getattr(settings, "OPENAI_API_KEY", None).get_secret_value()
                 if getattr(settings, "OPENAI_API_KEY", None) else "")
    embed_model = getattr(settings, "OPENAI_EMBED_MODEL", "text-embedding-3-small")
    if not embed_api:
        embed_provider = "google"
        embed_api = settings.GEMINI_API_KEY.get_secret_value()
        embed_model = getattr(settings, "EMBED_MODEL", "text-embedding-004")
    try:
        _render_progress(g_bar, g_msg, 3, f"ì„ë² ë”© ì„¤ì •({embed_provider})")
        _render_progress(o_bar, o_msg, 3, f"ì„ë² ë”© ì„¤ì •({embed_provider})")
        set_embed_provider(embed_provider, embed_api, embed_model)
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"ì„ë² ë”© ì‹¤íŒ¨: {e}")
        _render_progress(o_bar, o_msg, 100, f"ì„ë² ë”© ì‹¤íŒ¨: {e}")
        ss.prep_both_running = False
        return

    # 2) ì¸ë±ìŠ¤ ìŠ¤í… ì§„í–‰
    def upd(p, m=None):
        _render_progress(g_bar, g_msg, p, m)
        _render_progress(o_bar, o_msg, p, m)

    def umsg(m):
        _render_progress(g_bar, g_msg, ss.get("p_shared", 0), m)
        _render_progress(o_bar, o_msg, ss.get("p_shared", 0), m)

    persist_dir = f"{getattr(settings,'PERSIST_DIR','/tmp/my_ai_teacher/storage_gdrive')}_shared"
    job = ss.get("index_job")

    try:
        if job is None:
            res = start_index_builder(
                update_pct=upd,
                update_msg=umsg,
                gdrive_folder_id=settings.GDRIVE_FOLDER_ID,
                raw_sa=settings.GDRIVE_SERVICE_ACCOUNT_JSON,
                persist_dir=persist_dir,
                manifest_path=getattr(settings, "MANIFEST_PATH", "/tmp/my_ai_teacher/drive_manifest.json"),
                max_docs=None,     # ì „ì²´ ì¸ë±ì‹±
                is_cancelled=_is_cancelled,
            )
        else:
            res = resume_index_builder(
                job=job,
                update_pct=upd,
                update_msg=umsg,
                is_cancelled=_is_cancelled,
                batch_size=6
            )

        status = res.get("status")
        if status == "running":
            ss.index_job = res["job"]
            _render_progress(g_bar, g_msg, res.get("pct", 8), res.get("msg", "ì§„í–‰ ì¤‘â€¦"))
            _render_progress(o_bar, o_msg, res.get("pct", 8), res.get("msg", "ì§„í–‰ ì¤‘â€¦"))
            time.sleep(0.15)
            st.rerun()
            return

        if status == "cancelled":
            ss.prep_both_running = False
            ss.prep_cancel_requested = False
            ss.index_job = None
            _render_progress(g_bar, g_msg, res.get("pct", 0), "ì‚¬ìš©ì ì·¨ì†Œ")
            _render_progress(o_bar, o_msg, res.get("pct", 0), "ì‚¬ìš©ì ì·¨ì†Œ")
            return

        if status != "done":
            _render_progress(g_bar, g_msg, 100, "ì¸ë±ì‹± ì‹¤íŒ¨")
            _render_progress(o_bar, o_msg, 100, "ì¸ë±ì‹± ì‹¤íŒ¨")
            ss.prep_both_running = False
            return

        index = res["index"]
        ss.index_job = None

    except Exception as e:
        ss.prep_both_running = False
        ss.index_job = None
        _render_progress(g_bar, g_msg, 100, f"ì—ëŸ¬: {e}")
        _render_progress(o_bar, o_msg, 100, f"ì—ëŸ¬: {e}")
        return

    # 3) QueryEngine ìƒì„±
    try:
        g_llm = make_llm(
            "google",
            settings.GEMINI_API_KEY.get_secret_value(),
            getattr(settings, "LLM_MODEL", "gemini-1.5-pro"),
            float(ss.get("temperature", 0.0))
        )
        ss["llm_google"] = g_llm
        ss["qe_google"] = index.as_query_engine(
            llm=g_llm,
            response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
            similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
        )
        _render_progress(g_bar, g_msg, 100, "ì™„ë£Œ!")
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"Gemini ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    try:
        if getattr(settings, "OPENAI_API_KEY", None) and settings.OPENAI_API_KEY.get_secret_value():
            o_llm = make_llm(
                "openai",
                settings.OPENAI_API_KEY.get_secret_value(),
                getattr(settings, "OPENAI_LLM_MODEL", "gpt-4o-mini"),
                float(ss.get("temperature", 0.0))
            )
            ss["llm_openai"] = o_llm
            ss["qe_openai"] = index.as_query_engine(
                llm=o_llm,
                response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
                similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
            )
            _render_progress(o_bar, o_msg, 100, "ì™„ë£Œ!")
        else:
            _render_progress(o_bar, o_msg, 100, "í‚¤ ëˆ„ë½ â€” OPENAI_API_KEY í•„ìš”")
    except Exception as e:
        _render_progress(o_bar, o_msg, 100, f"ChatGPT ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    ss.prep_both_running = False
    ss.prep_both_done = True
    time.sleep(0.2)
    st.rerun()

# ì‹¤í–‰/ì·¨ì†Œ ë²„íŠ¼ ì¤„
left, right = st.columns([0.7, 0.3])
with left:
    clicked = st.button(
        "ğŸš€ í•œ ë²ˆì— ì¤€ë¹„í•˜ê¸°",
        key="prepare_both",
        use_container_width=True,
        disabled=ss.prep_both_running or ss.prep_both_done
    )
with right:
    cancel_clicked = st.button(
        "â›” ì¤€ë¹„ ì·¨ì†Œ",
        key="cancel_prepare",
        use_container_width=True,
        type="secondary",
        disabled=not ss.prep_both_running
    )

from src.rag_engine import cancel_index_builder  # ì¬ë…¸ì¶œ(ëª…ì‹œ)

if cancel_clicked and ss.prep_both_running:
    ss.prep_cancel_requested = True
    if ss.get("index_job"):
        cancel_index_builder(ss.index_job)
    st.rerun()

if clicked and not (ss.prep_both_running or ss.prep_both_done):
    ss.prep_cancel_requested = False
    ss.prep_both_running = True
    ss.index_job = None
    st.rerun()

if ss.prep_both_running:
    run_prepare_both_step()

st.caption("ì¤€ë¹„ ë²„íŠ¼ì„ ë‹¤ì‹œ í™œì„±í™”í•˜ë ¤ë©´ ì•„ë˜ ì¬ì„¤ì • ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
if st.button("ğŸ”§ ì¬ì„¤ì •(ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”)", disabled=not ss.prep_both_done):
    ss.prep_both_done = False
    st.rerun()

# ============= 9) ëŒ€í™” UI (ê·¸ë£¹í† ë¡ ) ===========================================
st.markdown("---")
st.subheader("ğŸ’¬ ê·¸ë£¹í† ë¡  â€” í•™ìƒ â†” ğŸ¤–Gemini(ì¹œì ˆ/ê¼¼ê¼¼) â†” ğŸ¤–ChatGPT(ìœ ë¨¸ëŸ¬ìŠ¤/ë³´ì™„)")

ready_google = "qe_google" in ss
ready_openai = "qe_openai" in ss

if ss.session_terminated:
    st.warning("ì„¸ì…˜ì´ ì¢…ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”.")
    st.stop()

if not ready_google:
    st.info("ë¨¼ì € **[ğŸš€ í•œ ë²ˆì— ì¤€ë¹„í•˜ê¸°]**ë¡œ ë‘ë‡Œë¥¼ ì¤€ë¹„í•˜ì„¸ìš”. (OpenAI í‚¤ ì—†ìœ¼ë©´ Geminië§Œ ì‘ë‹µ)")
    st.stop()

# ê³¼ê±° ë©”ì‹œì§€ ë Œë”
for m in ss.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ë§¥ë½/ë„ìš°ë¯¸
def _strip_sources(text: str) -> str:
    return re.sub(r"\n+---\n\*ì°¸ê³  ìë£Œ:.*$", "", text, flags=re.DOTALL)

def _build_context(messages, limit_pairs=2, max_chars=2000) -> str:
    pairs, buf_user = [], None
    for m in reversed(messages):
        role, content = m.get("role"), str(m.get("content","")).strip()
        if role == "assistant":
            content = re.sub(r"^\*\*ğŸ¤– .*?\*\*\s*\n+", "", content).strip()
            if buf_user is not None:
                pairs.append((buf_user, content))
                buf_user = None
                if len(pairs) >= limit_pairs:
                    break
        elif role == "user" and buf_user is None:
            buf_user = content
    pairs = list(reversed(pairs))
    blocks = [f"[í•™ìƒ]\n{u}\n\n[êµì‚¬]\n{a}" for u,a in pairs]
    ctx = "\n\n---\n\n".join(blocks).strip()
    return ctx[-max_chars:] if len(ctx) > max_chars else ctx

from src.prompts import EXPLAINER_PROMPT, ANALYST_PROMPT, READER_PROMPT
def _persona():
    mode = ss.get("mode_select", "ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…")
    base = EXPLAINER_PROMPT if mode=="ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…" else (ANALYST_PROMPT if mode=="ğŸ” êµ¬ë¬¸ ë¶„ì„" else READER_PROMPT)
    common = "ì—­í• : í•™ìƒì˜ ì˜ì–´ ì‹¤ë ¥ì„ ë•ëŠ” AI êµì‚¬.\nê·œì¹™: ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ë°íŒë‹¤. ì˜ˆì‹œëŠ” ì§§ê³  ì ì§„ì ìœ¼ë¡œ."
    return base + "\n" + common

GEMINI_STYLE = "ë‹¹ì‹ ì€ ì°©í•˜ê³  ë˜‘ë˜‘í•œ ì¹œêµ¬ ê°™ì€ êµì‚¬ì…ë‹ˆë‹¤. ì¹­ì°¬ê³¼ ê²©ë ¤, ì •í™•í•œ ì„¤ëª…."
CHATGPT_STYLE = (
    "ë‹¹ì‹ ì€ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ì§€ë§Œ ì •í™•í•œ ë™ë£Œ êµì‚¬ì…ë‹ˆë‹¤. ë™ë£Œ(Gemini)ì˜ ë‹µì„ ì½ê³  "
    "ë¹ ì§„ ë¶€ë¶„ì„ ë³´ì™„/êµì •í•˜ê³  ë§ˆì§€ë§‰ì— <ìµœì¢… ì •ë¦¬>ë¡œ ìš”ì•½í•˜ì„¸ìš”. ê³¼í•œ ë†ë‹´ ê¸ˆì§€."
)

mode = st.radio(
    "í•™ìŠµ ëª¨ë“œ",
    ["ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…", "ğŸ” êµ¬ë¬¸ ë¶„ì„", "ğŸ“š ë…í•´ ë° ìš”ì•½"],
    horizontal=True, key="mode_select"
)

# ì„œë¹„ìŠ¤ê³„ì • JSONL ì €ì¥ (chat_log/)
from src import chat_store
from src.drive_log import get_chatlog_folder_id, save_chatlog_markdown_oauth

def _jsonl_log(items):
    if not ss.save_logs:
        return
    try:
        parent_id = (getattr(settings, "CHATLOG_FOLDER_ID", None) or settings.GDRIVE_FOLDER_ID)
        sa = settings.GDRIVE_SERVICE_ACCOUNT_JSON
        if isinstance(sa, str):
            try:
                sa = json.loads(sa)
            except Exception:
                pass
        sub_id = get_chatlog_folder_id(parent_folder_id=parent_id, sa_json=sa)
        chat_store.append_jsonl(folder_id=sub_id, sa_json=sa, items=items)
        st.toast("ëŒ€í™” JSONL ì €ì¥ ì™„ë£Œ", icon="ğŸ’¾")
    except Exception as e:
        st.warning(f"ëŒ€í™” JSONL ì €ì¥ ì‹¤íŒ¨: {e}")

# ì…ë ¥ & ì‘ë‹µ
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ë¶„ì„/ìš”ì•½í•  ë¬¸ì¥ì´ë‚˜ ê¸€ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
if user_input:
    ss.messages.append({"role":"user","content":user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    _jsonl_log([chat_store.make_entry(
        ss.session_id, "user", "user", user_input, mode, model="user"
    )])

    # Gemini 1ì°¨
    with st.spinner("ğŸ¤– Gemini ì„ ìƒë‹˜ì´ ë¨¼ì € ë‹µí•©ë‹ˆë‹¤â€¦"):
        prev_ctx = _build_context(ss.messages[:-1], limit_pairs=2, max_chars=2000)
        gemini_query = (f"[ì´ì „ ëŒ€í™”]\n{prev_ctx}\n\n" if prev_ctx else "") + f"[í•™ìƒ ì§ˆë¬¸]\n{user_input}"
        ans_g = get_text_answer(ss["qe_google"], gemini_query, _persona() + "\n" + GEMINI_STYLE)

    content_g = f"**ğŸ¤– Gemini**\n\n{ans_g}"
    ss.messages.append({"role":"assistant","content":content_g})
    with st.chat_message("assistant"):
        st.markdown(content_g)

    _jsonl_log([chat_store.make_entry(
        ss.session_id, "assistant", "Gemini", content_g, mode, model=getattr(settings,"LLM_MODEL","gemini")
    )])

    # ChatGPT ë³´ì™„(í‚¤ê°€ ìˆì„ ë•Œ)
    if ready_openai:
        review_directive = (
            "ì—­í• : ë™ë£Œ AI ì˜ì–´êµì‚¬\n"
            "ëª©í‘œ: [ì´ì „ ëŒ€í™”], [í•™ìƒ ì§ˆë¬¸], [ë™ë£Œì˜ 1ì°¨ ë‹µë³€]ì„ ì½ê³  ì‚¬ì‹¤ì˜¤ë¥˜/ë¹ ì§„ì /ëª¨í˜¸í•¨ì„ ë³´ì™„.\n"
            "ì§€ì¹¨: 1)í•µì‹¬ ê°„ê²° ì¬ì •ë¦¬ 2)í‹€ë¦° ë¶€ë¶„ ê·¼ê±°ì™€ êµì • 3)ì˜ˆë¬¸ 2~3ê°œ 4)<ìµœì¢… ì •ë¦¬>ë¡œ ìš”ì•½. ì™¸ë¶€ê²€ìƒ‰ ê¸ˆì§€."
        )
        prev_all = _build_context(ss.messages, limit_pairs=2, max_chars=2000)
        augmented = (
            (f"[ì´ì „ ëŒ€í™”]\n{prev_all}\n\n" if prev_all else "") +
            f"[í•™ìƒ ì§ˆë¬¸]\n{user_input}\n\n"
            f"[ë™ë£Œì˜ 1ì°¨ ë‹µë³€(Gemini)]\n{_strip_sources(ans_g)}\n\n"
            "[ë‹¹ì‹ ì˜ ì‘ì—…]\nìœ„ ê¸°ì¤€ìœ¼ë¡œë§Œ ë³´ì™„/ê²€ì¦."
        )
        with st.spinner("ğŸ¤ ChatGPT ì„ ìƒë‹˜ì´ ë³´ì™„/ê²€ì¦ ì¤‘â€¦"):
            ans_o = llm_complete(
                ss.get("llm_openai"),
                _persona() + "\n" + CHATGPT_STYLE + "\n\n" + review_directive + "\n\n" + augmented
            )
        content_o = f"**ğŸ¤– ChatGPT**\n\n{ans_o}"
        ss.messages.append({"role":"assistant","content":content_o})
        with st.chat_message("assistant"):
            st.markdown(content_o)
    else:
        with st.chat_message("assistant"):
            st.info("ChatGPT í‚¤ê°€ ì—†ì–´ Geminië§Œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤. OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ë©´ ë³´ì™„/ê²€ì¦ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

    # OAuth Markdown ì €ì¥(ë‚´ ë“œë¼ì´ë¸Œ)
    if ss.auto_save_chatlog and ss.messages:
        try:
            if is_signed_in():
                svc = build_drive_service()
                parent_id = (st.secrets.get("OAUTH_CHAT_PARENT_ID") or "").strip() or None
                _fid = save_chatlog_markdown_oauth(ss.session_id, ss.messages, svc, parent_id)
                st.toast("ë‚´ ë“œë¼ì´ë¸Œì— ëŒ€í™” ì €ì¥ ì™„ë£Œ âœ…", icon="ğŸ’¾")
            else:
                st.info("êµ¬ê¸€ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ë©´ ëŒ€í™”ê°€ **ë‚´ ë“œë¼ì´ë¸Œ**ì— ì €ì¥ë©ë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"OAuth ì €ì¥ ì‹¤íŒ¨: {e}")

# EOF
