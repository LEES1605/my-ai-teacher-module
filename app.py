# app.py
# ===== TOP OF FILE ============================================================
# 0) Streamlit í˜ì´ì§€ ì„¤ì •ì€ ë°˜ë“œì‹œ ìµœìƒë‹¨ì—ì„œ!
import os

# ëŸ°íƒ€ì„ ì•ˆì •í™”(Cloud ì¬ì‹œì‘ ë£¨í”„/ì§€ì—° ë°©ì§€)
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"
os.environ["STREAMLIT_RUN_ON_SAVE"] = "false"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_SERVER_ENABLE_WEBSOCKET_COMPRESSION"] = "false"

import time
import streamlit as st

# 1) ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from src.config import settings, APP_DATA_DIR, PERSIST_DIR
from src.ui import load_css, safe_render_header, ensure_progress_css, render_progress_bar
from src.prompts import EXPLAINER_PROMPT, ANALYST_PROMPT, READER_PROMPT
from src.rag_engine import get_or_build_index, init_llama_settings, get_text_answer
from src.auth import admin_login_flow

# 2) í˜ì´ì§€ ë©”íƒ€
st.set_page_config(page_title="ë‚˜ì˜ AI ì˜ì–´ êµì‚¬", layout="wide", initial_sidebar_state="collapsed")

# 3) ì „ì—­ CSS + (ì„ íƒ) ë°°ê²½
load_css("assets/style.css", use_bg=settings.USE_BG_IMAGE, bg_path="assets/background_book.png")
ensure_progress_css()

# 4) í—¤ë”
safe_render_header()

# 5) ìƒë‹¨ ìš°ì¸¡ ê´€ë¦¬ì ë²„íŠ¼
_, _, c3 = st.columns([0.8, 0.1, 0.1])
with c3:
    if st.button("ğŸ› ï¸", key="admin_icon_top_bar"):
        st.session_state.admin_mode = True

# 6) ê³ ê¸‰/RAG íŠœë‹ íŒ¨ë„(ê´€ë¦¬ìë§Œ ë³´ì´ê²Œ)
if admin_login_flow(settings.ADMIN_PASSWORD or ""):
    with st.expander("âš™ï¸ ê³ ê¸‰ RAG/LLM ì„¤ì •", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.session_state.setdefault("similarity_top_k", settings.SIMILARITY_TOP_K)
            k = st.slider("similarity_top_k", 1, 12, st.session_state["similarity_top_k"])
        with col2:
            st.session_state.setdefault("temperature", 0.0)
            temp = st.slider("LLM temperature", 0.0, 1.0, float(st.session_state["temperature"]), 0.05)
        with col3:
            st.session_state.setdefault("response_mode", settings.RESPONSE_MODE)
            mode_sel = st.selectbox("response_mode", ["compact", "refine", "tree_summarize"], index=["compact","refine","tree_summarize"].index(st.session_state["response_mode"]))

        if st.button("ì ìš©"):
            st.session_state["similarity_top_k"] = k
            st.session_state["temperature"] = temp
            st.session_state["response_mode"] = mode_sel
            st.success("RAG/LLM ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¸ë±ìŠ¤/ì—”ì§„ì€ ë‹¤ìŒ ì¿¼ë¦¬ë¶€í„° ë°˜ì˜)")

    with st.expander("ğŸ› ï¸ ê´€ë¦¬ì ë„êµ¬", expanded=False):
        if st.button("ğŸ“¥ ê°•ì˜ ìë£Œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸° (ë‘ë‡Œ ì´ˆê¸°í™”)"):
            import shutil, os
            if os.path.exists(PERSIST_DIR):
                shutil.rmtree(PERSIST_DIR)
            if "query_engine" in st.session_state:
                del st.session_state["query_engine"]
            st.success("ë‘ë‡Œ íŒŒì¼ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë‹¤ì‹œ ì¤€ë¹„í•˜ì„¸ìš”.")

# 7) ë©”ì¸ ì›Œí¬í”Œë¡œìš°
def main():
    # ë‘ë‡Œ(ì¸ë±ìŠ¤)ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì€ ê²½ìš°
    if "query_engine" not in st.session_state:
        st.info("AI êµì‚¬ë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. ì²˜ìŒì—ëŠ” í•™ìŠµëŸ‰ì— ë”°ë¼ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        if st.button("ğŸ§  AI ë‘ë‡Œ ì¤€ë¹„ ì‹œì‘í•˜ê¸°"):
            # ì§„í–‰ë°” ìŠ¬ë¡¯
            bar_slot = st.empty()
            msg_slot = st.empty()
            state_key = "_gp_pct"
            st.session_state[state_key] = 0

            def update_pct(pct: int, msg: str | None = None):
                st.session_state[state_key] = max(0, min(100, int(pct)))
                render_progress_bar(bar_slot, st.session_state[state_key])
                if msg is not None:
                    msg_slot.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)

            def update_msg(msg: str):
                render_progress_bar(bar_slot, st.session_state[state_key])
                msg_slot.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)

            render_progress_bar(bar_slot, 0)
            update_msg("ë‘ë‡Œ ì¤€ë¹„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤â€¦")

            # LLM/Embedding ì„¤ì •(ì˜¨ë””ë§¨ë“œ)
            init_llama_settings(api_key=settings.GEMINI_API_KEY.get_secret_value(),
                                llm_model=settings.LLM_MODEL,
                                embed_model=settings.EMBED_MODEL,
                                temperature=float(st.session_state.get("temperature", 0.0)))

            # ì¸ë±ìŠ¤ ì¤€ë¹„(ë³€ê²½ ê°ì§€ â†’ í•„ìš” ì‹œ ì¬ë¹Œë“œ)
            index = get_or_build_index(
                update_pct=update_pct,
                update_msg=update_msg,
                gdrive_folder_id=settings.GDRIVE_FOLDER_ID,
                raw_sa=settings.GDRIVE_SERVICE_ACCOUNT_JSON,
                persist_dir=PERSIST_DIR,
                manifest_path=settings.MANIFEST_PATH,
            )

            # ì§ˆì˜ ì—”ì§„
            st.session_state.query_engine = index.as_query_engine(
                response_mode=st.session_state.get("response_mode", settings.RESPONSE_MODE),
                similarity_top_k=int(st.session_state.get("similarity_top_k", settings.SIMILARITY_TOP_K))
            )
            update_pct(100, "ì™„ë£Œ!")
            time.sleep(0.6)
            bar_slot.empty(); msg_slot.empty()
            st.rerun()

        st.stop()

    # === ì±„íŒ… UI ===
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    st.markdown("---")

    mode = st.radio(
        "**ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•œê°€ìš”?**",
        ["ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…", "ğŸ” êµ¬ë¬¸ ë¶„ì„", "ğŸ“š ë…í•´ ë° ìš”ì•½"],
        horizontal=True,
        key="mode_select"
    )

    prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ë¶„ì„/ìš”ì•½í•  ë¬¸ì¥ì´ë‚˜ ê¸€ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")

    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.spinner("AI ì„ ìƒë‹˜ì´ ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
            if mode == "ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…":
                selected_prompt = EXPLAINER_PROMPT
            elif mode == "ğŸ” êµ¬ë¬¸ ë¶„ì„":
                selected_prompt = ANALYST_PROMPT
            else:
                selected_prompt = READER_PROMPT

            answer = get_text_answer(st.session_state.query_engine, prompt, selected_prompt)

        st.session_state.messages.append({"role": "assistant", "content": answer})
        st.rerun()

if __name__ == "__main__":
    main()
# ===== END OF FILE ============================================================
