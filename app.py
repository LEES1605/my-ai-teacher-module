# app.py â€” ìŠ¤í… ì¸ë±ì‹±(ì¤‘ê°„ì·¨ì†Œ/ì¬ê°œ) + ë‘ë‡Œì¤€ë¹„ ì•ˆì •í™”
#        + ì¸ë±ì‹± ë³´ê³ ì„œ(ìŠ¤í‚µ íŒŒì¼ í‘œì‹œ)
#        + Drive ëŒ€í™”ë¡œê·¸ ì €ì¥(â¶ OAuth: Markdown / â· ì„œë¹„ìŠ¤ê³„ì •: JSONL, chat_log/)
#        + í˜ë¥´ì†Œë‚˜: ğŸ¤–Gemini(ì¹œì ˆ/ê¼¼ê¼¼), ğŸ¤–ChatGPT(ìœ ë¨¸ëŸ¬ìŠ¤/ë³´ì™„)
#        + ì–‘ìª½ ëª¨ë‘ RAG ìš°ì„ , ë¶€ì¡± ì‹œ "(ìë£Œ ë°– ì§€ì‹)"ìœ¼ë¡œ ìµœì†Œ ë³´ì™„

# ===== Imports =====
import os
import time
import uuid
import re
import json
import pandas as pd
import streamlit as st

# ---- Streamlit query_params í˜¸í™˜ íŒ¨ì¹˜ (deprecation ë°°ë„ˆ ì œê±°) ----
# old -> st.experimental_get_query_params / st.experimental_set_query_params
# new -> st.query_params
if not hasattr(st, "_qp_compat_patched"):
    def _compat_get_query_params():
        try:
            raw = dict(st.query_params)      # {'k': 'v'} or {'k': ['a','b']}
            return {k: (v if isinstance(v, list) else [v]) for k, v in raw.items()}
        except Exception:
            return {}

    def _compat_set_query_params(**kwargs):
        try:
            qp = st.query_params
            qp.clear()
            for k, v in kwargs.items():
                qp[k] = v
        except Exception:
            pass

    st.experimental_get_query_params = _compat_get_query_params
    st.experimental_set_query_params = _compat_set_query_params
    st._qp_compat_patched = True
# ---------------------------------------------------------------

# ê¸°ë³¸ UI
from src.ui import load_css, render_header

# ì„¤ì •
from src.config import settings

# RAG/ì¸ë±ì‹± ìœ í‹¸(ìŠ¤í… ë¹Œë”)
from src.rag_engine import (
    set_embed_provider, make_llm, get_text_answer, CancelledError,
    start_index_builder, resume_index_builder, cancel_index_builder,
    smoke_test_drive, preview_drive_files,
)

# JSONL ë¡œê·¸ ìŠ¤í† ì–´(ì„œë¹„ìŠ¤ê³„ì • ê²½ë¡œ)
from src import chat_store

# Drive ë¡œê·¸ ìœ í‹¸
# â¶ OAuthë¡œ Markdown ì €ì¥
from src.drive_log import save_chatlog_markdown_oauth
# â· ì„œë¹„ìŠ¤ê³„ì •ìœ¼ë¡œ JSONL ì €ì¥ ì‹œ chat_log/ ë³´ì¥
from src.drive_log import get_chatlog_folder_id

# í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸
from src.prompts import EXPLAINER_PROMPT, ANALYST_PROMPT, READER_PROMPT

# ===== ê³µí†µ ê·œì¹™(ì—…ë¡œë“œ ìë£Œ ìµœìš°ì„  + ë¶€ì¡±ë¶„ë§Œ ë³´ê°•) =====
RAG_FIRST_RULES = (
    "ê·œì¹™: ë°˜ë“œì‹œ ì—…ë¡œë“œëœ í•™ìŠµ ìë£Œ(ë¬¸ì„œ/ìŠ¬ë¼ì´ë“œ ë“±)ì—ì„œ ê·¼ê±°ë¥¼ ë¨¼ì € ì°¾ëŠ”ë‹¤. "
    "ìë£Œì— ì§ì ‘ ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ê·¸ë•Œì—ë§Œ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ì§§ê²Œ ë³´ì™„í•˜ë˜, "
    "ë³´ê°•í•œ ë¬¸ì¥ ì•ì— '(ìë£Œ ë°– ì§€ì‹)'ì´ë¼ê³  í‘œì‹œí•œë‹¤. "
    "ìë£Œ ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ë°íŒë‹¤."
)

# ë‘ ìºë¦­í„° ìŠ¤íƒ€ì¼
GEMINI_STYLE = (
    "ë‹¹ì‹ ì€ ì°©í•˜ê³  ë˜‘ë˜‘í•œ ì¹œêµ¬ ê°™ì€ êµì‚¬ì…ë‹ˆë‹¤. ì§€ë‚˜ì¹˜ê²Œ ì–´ë µê²Œ ë§í•˜ì§€ ë§ê³ , "
    "ì¹­ì°¬ê³¼ ê²©ë ¤ë¥¼ ê³ë“¤ì—¬ ì°¨ë¶„íˆ ì•ˆë‚´í•˜ì„¸ìš”. í•µì‹¬ ê·œì¹™ì€ ì •í™•ì„±ì…ë‹ˆë‹¤."
)
CHATGPT_REVIEW_STYLE = (
    "ë‹¹ì‹ ì€ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ì§€ë§Œ ì •í™•í•œ ë™ë£Œ êµì‚¬ì…ë‹ˆë‹¤. ë™ë£Œ(Gemini)ì˜ ë‹µì„ ì½ê³  "
    "ë¹ ì§„ ë¶€ë¶„ì„ ë³´ì™„/êµì •í•˜ê³ , ë§ˆì§€ë§‰ì— <ìµœì¢… ì •ë¦¬>ë¥¼ ì œì‹œí•˜ì„¸ìš”. ê³¼í•œ ë†ë‹´ì€ í”¼í•˜ê³ , "
    "ì§§ê³  ëª…ë£Œí•œ ìœ ë¨¸ í•œë‘ ì¤„ë§Œ í—ˆìš©ë©ë‹ˆë‹¤."
)

# ===== ëŸ°íƒ€ì„ ì•ˆì •í™” í™˜ê²½ë³€ìˆ˜ =====
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_SERVER_ENABLE_WEBSOCKET_COMPRESSION"] = "false"

# ===== í˜ì´ì§€ ì„¤ì • (ì²« í˜¸ì¶œë§Œ!) =====
st.set_page_config(
    page_title="ë‚˜ì˜ AI ì˜ì–´ êµì‚¬",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# OAuth ë¦¬ë‹¤ì´ë ‰íŠ¸ ì²˜ë¦¬ (í˜ì´ì§€ ì„¤ì • ì§í›„)
from src.google_oauth import finish_oauth_if_redirected
finish_oauth_if_redirected()

# ===== ì„¸ì…˜ ìƒíƒœ(ë¨¼ì € ì •ì˜! ì´í›„ì— ss ì°¸ì¡°) =====
ss = st.session_state
ss.setdefault("session_id", uuid.uuid4().hex[:12])   # ëŒ€í™” ì„¸ì…˜ ID
ss.setdefault("messages", [])                        # {"role": "user"|"assistant", "content": str}
ss.setdefault("auto_save_chatlog", True)             # OAuth Markdown ìë™ ì €ì¥
ss.setdefault("save_logs", False)                    # ì„œë¹„ìŠ¤ê³„ì • JSONL ì €ì¥(ê¸°ë³¸ False; ì¿¼í„° ì´ìŠˆ íšŒí”¼)
ss.setdefault("prep_both_running", False)
ss.setdefault("prep_both_done", ("qe_google" in ss) or ("qe_openai" in ss))
ss.setdefault("p_shared", 0)
ss.setdefault("prep_cancel_requested", False)
ss.setdefault("session_terminated", False)
ss.setdefault("index_job", None)                     # ìŠ¤í… ë¹Œë” ìƒíƒœ

# ===== ê¸°ë³¸ UI / í—¤ë” =====
load_css()
render_header()
st.info("âœ… ë³€ê²½ì´ ìˆì„ ë•Œë§Œ ì¸ë±ì‹±í•©ë‹ˆë‹¤. ì €ì¥ëœ ë‘ë‡Œê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. (ì¤‘ê°„ ì·¨ì†Œ/ì¬ê°œ ì§€ì›)")

# ===== ì‚¬ì´ë“œë°”: ìë™ì €ì¥ í† ê¸€ + OAuth ë¡œê·¸ì¸ =====
from src.google_oauth import start_oauth, is_signed_in, build_drive_service, get_user_email, sign_out

with st.sidebar:
    ss.auto_save_chatlog = st.toggle("ëŒ€í™” ìë™ ì €ì¥ (OAuth/ë‚´ ë“œë¼ì´ë¸Œ, Markdown)", value=ss.auto_save_chatlog)
    ss.save_logs = st.toggle("ëŒ€í™” JSONL ì €ì¥ (ì„œë¹„ìŠ¤ê³„ì •/chat_log/)", value=ss.save_logs,
                             help="ê³µìœ ë“œë¼ì´ë¸Œ Writer ê¶Œí•œ í•„ìš”. ì¿¼í„° ë¬¸ì œ ì‹œ ë„ê¸° ê¶Œì¥.")
    st.markdown("---")
    st.markdown("### Google ë¡œê·¸ì¸ (ë‚´ ë“œë¼ì´ë¸Œ ì €ì¥)")
    if not is_signed_in():
        if st.button("ğŸ” Googleë¡œ ë¡œê·¸ì¸"):
            url = start_oauth()
            st.markdown(f"[ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ ë¡œê·¸ì¸í•˜ì„¸ìš”]({url})")
    else:
        st.success(f"ë¡œê·¸ì¸ë¨: {get_user_email() or 'ì•Œ ìˆ˜ ì—†ìŒ'}")
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            sign_out()
            st.rerun()

# ===== Google Drive ì—°ê²° í…ŒìŠ¤íŠ¸ =====
st.markdown("## ğŸ”— Google Drive ì—°ê²° í…ŒìŠ¤íŠ¸")
st.caption("ì„œë¹„ìŠ¤ê³„ì •ì€ **ê³µìœ  ë“œë¼ì´ë¸Œ**ì— Writer ê¶Œí•œì´ ìˆì–´ì•¼(ì €ì¥ ì‹œ) ì˜¤ë¥˜ ì—†ì´ ë™ì‘í•©ë‹ˆë‹¤. ì¸ë±ì‹±ì€ Readonlyë©´ ì¶©ë¶„.")

col1, col2 = st.columns([0.65, 0.35])
with col1:
    if st.button("í´ë” íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ìµœì‹  10ê°œ)", use_container_width=True):
        ok, msg, rows = preview_drive_files(max_items=10)
        if ok and rows:
            df = pd.DataFrame(rows)
            df["type"] = df["mime"].str.replace("application/vnd.google-apps.", "", regex=False)
            df = df.rename(columns={"modified": "modified_at"})
            df = df[["name", "link", "type", "modified_at"]]
            st.dataframe(
                df, use_container_width=True, height=360,
                column_config={
                    "name": st.column_config.TextColumn("íŒŒì¼ëª…"),
                    "link": st.column_config.LinkColumn("open", display_text="ì—´ê¸°"),
                    "type": st.column_config.TextColumn("ìœ í˜•"),
                    "modified_at": st.column_config.TextColumn("ìˆ˜ì •ì‹œê°"),
                }, hide_index=True
            )
        elif ok:
            st.warning("í´ë”ì— íŒŒì¼ì´ ì—†ê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error(msg)
with col2:
    ok, msg = smoke_test_drive()
    if ok: st.success(msg)
    else:  st.warning(msg)

# ===== ì¸ë±ì‹± ë³´ê³ ì„œ(ìŠ¤í‚µ íŒŒì¼ í™•ì¸) =====
rep = st.session_state.get("indexing_report")
if rep:
    with st.expander("ğŸ§¾ ì¸ë±ì‹± ë³´ê³ ì„œ (ìŠ¤í‚µëœ íŒŒì¼ ë³´ê¸°)", expanded=False):
        st.write(
            f"ì´ íŒŒì¼(ë§¤ë‹ˆí˜ìŠ¤íŠ¸): {rep.get('total_manifest')}, "
            f"ë¡œë”©ëœ ë¬¸ì„œ ìˆ˜: {rep.get('loaded_docs')}, "
            f"ìŠ¤í‚µ: {rep.get('skipped_count')}"
        )
        skipped = rep.get("skipped", [])
        if skipped:
            st.dataframe(pd.DataFrame(skipped), use_container_width=True, hide_index=True)
        else:
            st.caption("ìŠ¤í‚µëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ ğŸ‰")

# ===== ë‘ë‡Œ ì¤€ë¹„(ìŠ¤í…) =====
st.markdown("---")
st.subheader("ğŸ§  ë‘ë‡Œ ì¤€ë¹„ â€” ì €ì¥ë³¸ ë¡œë“œ â†” ë³€ê²½ ì‹œ ì¦ë¶„ ì¸ë±ì‹± (ì¤‘ê°„ ì·¨ì†Œ/ì¬ê°œ)")

# ì§„í–‰ë¥  ë°”
c_g, c_o = st.columns(2)
with c_g:
    st.caption("Gemini ì§„í–‰"); g_bar = st.empty(); g_msg = st.empty()
with c_o:
    st.caption("ChatGPT ì§„í–‰"); o_bar = st.empty(); o_msg = st.empty()

def _render_progress(slot_bar, slot_msg, pct: int, msg: str | None = None):
    p = max(0, min(100, int(pct)))
    slot_bar.markdown(
        f"""
<div class="gp-wrap"><div class="gp-fill" style="width:{p}%"></div><div class="gp-label">{p}%</div></div>
""", unsafe_allow_html=True
    )
    if msg is not None:
        slot_msg.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)

def _is_cancelled() -> bool:
    return bool(ss.get("prep_cancel_requested", False))

def run_prepare_both_step():
    # 1) ì„ë² ë”© ê³µê¸‰ì ì„ íƒ/ì„¤ì •
    embed_provider = "openai"
    embed_api = (getattr(settings, "OPENAI_API_KEY", None).get_secret_value()
                 if getattr(settings, "OPENAI_API_KEY", None) else "")
    embed_model = getattr(settings, "OPENAI_EMBED_MODEL", "text-embedding-3-small")
    if not embed_api:
        embed_provider = "google"
        embed_api = settings.GEMINI_API_KEY.get_secret_value()
        embed_model = getattr(settings, "EMBED_MODEL", "text-embedding-004")
    try:
        _render_progress(g_bar, g_msg, 3, f"ì„ë² ë”© ì„¤ì •({embed_provider})")
        _render_progress(o_bar, o_msg, 3, f"ì„ë² ë”© ì„¤ì •({embed_provider})")
        set_embed_provider(embed_provider, embed_api, embed_model)
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"ì„ë² ë”© ì‹¤íŒ¨: {e}")
        _render_progress(o_bar, o_msg, 100, f"ì„ë² ë”© ì‹¤íŒ¨: {e}")
        ss.prep_both_running = False
        return

    # 2) ì¸ë±ìŠ¤ ìŠ¤í… ì§„í–‰
    def upd(p, m=None):
        _render_progress(g_bar, g_msg, p, m); _render_progress(o_bar, o_msg, p, m)

    def umsg(m):
        _render_progress(g_bar, g_msg, ss.get("p_shared", 0), m)
        _render_progress(o_bar, o_msg, ss.get("p_shared", 0), m)

    job = ss.get("index_job")
    persist_dir = f"{getattr(settings,'PERSIST_DIR','/tmp/my_ai_teacher/storage_gdrive')}_shared"

    if job is None:
        # ì²˜ìŒ ì‹œì‘ (ë¹ ë¥¸ ëª¨ë“œ ì œê±° â†’ ì „ì²´ ì¸ë±ì‹±)
        res = start_index_builder(
            update_pct=upd, update_msg=umsg,
            gdrive_folder_id=settings.GDRIVE_FOLDER_ID,
            raw_sa=settings.GDRIVE_SERVICE_ACCOUNT_JSON,
            persist_dir=persist_dir,
            manifest_path=getattr(settings, "MANIFEST_PATH", "/tmp/my_ai_teacher/drive_manifest.json"),
            max_docs=None,                 # ğŸ”¸ ë¹ ë¥¸ ëª¨ë“œ ì œê±°
            is_cancelled=_is_cancelled,
        )
        status = res.get("status")
        if status == "done":
            index = res["index"]
        elif status == "running":
            ss.index_job = res["job"]
            _render_progress(g_bar, g_msg, res.get("pct", 8), res.get("msg", "ì§„í–‰ ì¤‘â€¦"))
            _render_progress(o_bar, o_msg, res.get("pct", 8), res.get("msg", "ì§„í–‰ ì¤‘â€¦"))
            time.sleep(0.2); st.rerun(); return
        else:
            _render_progress(g_bar, g_msg, 100, "ì¸ë±ì‹± ì‹œì‘ ì‹¤íŒ¨")
            _render_progress(o_bar, o_msg, 100, "ì¸ë±ì‹± ì‹œì‘ ì‹¤íŒ¨")
            ss.prep_both_running = False; return
    else:
        # ì¬ê°œ
        res = resume_index_builder(job=job, update_pct=upd, update_msg=umsg,
                                   is_cancelled=_is_cancelled, batch_size=6)
        status = res.get("status")
        if status == "running":
            _render_progress(g_bar, g_msg, res.get("pct", 8), res.get("msg", "ì§„í–‰ ì¤‘â€¦"))
            _render_progress(o_bar, o_msg, res.get("pct", 8), res.get("msg", "ì§„í–‰ ì¤‘â€¦"))
            time.sleep(0.15); st.rerun(); return
        elif status == "cancelled":
            ss.prep_both_running = False; ss.prep_cancel_requested = False; ss.index_job = None
            _render_progress(g_bar, g_msg, ss.get("p_shared", 0), "ì‚¬ìš©ì ì·¨ì†Œ")
            _render_progress(o_bar, o_msg, ss.get("p_shared", 0), "ì‚¬ìš©ì ì·¨ì†Œ")
            return
        elif status == "done":
            index = res["index"]
            ss.index_job = None
        else:
            _render_progress(g_bar, g_msg, 100, "ì¸ë±ì‹± ì‹¤íŒ¨")
            _render_progress(o_bar, o_msg, 100, "ì¸ë±ì‹± ì‹¤íŒ¨")
            ss.prep_both_running = False; return

    # 3) ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ â†’ LLM 2ê°œ ì¤€ë¹„ + QE ìƒì„±
    try:
        g_llm = make_llm("google", settings.GEMINI_API_KEY.get_secret_value(),
                         getattr(settings, "LLM_MODEL", "gemini-1.5-pro"),
                         float(ss.get("temperature", 0.0)))
        ss["llm_google"] = g_llm
        ss["qe_google"] = index.as_query_engine(
            llm=g_llm,
            response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
            similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
        )
        _render_progress(g_bar, g_msg, 100, "ì™„ë£Œ!")
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"Gemini ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    try:
        if getattr(settings, "OPENAI_API_KEY", None) and settings.OPENAI_API_KEY.get_secret_value():
            o_llm = make_llm("openai", settings.OPENAI_API_KEY.get_secret_value(),
                             getattr(settings, "OPENAI_LLM_MODEL", "gpt-4o-mini"),
                             float(ss.get("temperature", 0.0)))
            ss["llm_openai"] = o_llm
            ss["qe_openai"] = index.as_query_engine(
                llm=o_llm,
                response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
                similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
            )
            _render_progress(o_bar, o_msg, 100, "ì™„ë£Œ!")
        else:
            _render_progress(o_bar, o_msg, 100, "í‚¤ ëˆ„ë½ â€” OPENAI_API_KEY í•„ìš”")
    except Exception as e:
        _render_progress(o_bar, o_msg, 100, f"ChatGPT ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    ss.prep_both_running = False
    ss.prep_both_done = True
    time.sleep(0.2); st.rerun()

# ì‹¤í–‰/ì·¨ì†Œ ë²„íŠ¼
left, right = st.columns([0.7, 0.3])
with left:
    clicked = st.button("ğŸš€ í•œ ë²ˆì— ì¤€ë¹„í•˜ê¸°", key="prepare_both", use_container_width=True,
                        disabled=ss.prep_both_running or ss.prep_both_done)
with right:
    cancel_clicked = st.button("â›” ì¤€ë¹„ ì·¨ì†Œ", key="cancel_prepare", use_container_width=True, type="secondary",
                               disabled=not ss.prep_both_running)

if cancel_clicked and ss.prep_both_running:
    ss.prep_cancel_requested = True
    if ss.get("index_job"):
        cancel_index_builder(ss.index_job)
    st.rerun()

if clicked and not (ss.prep_both_running or ss.prep_both_done):
    ss.p_shared = 0
    ss.prep_cancel_requested = False
    ss.prep_both_running = True
    ss.index_job = None
    st.rerun()

if ss.prep_both_running:
    run_prepare_both_step()

st.caption("ì¤€ë¹„ ë²„íŠ¼ì„ ë‹¤ì‹œ í™œì„±í™”í•˜ë ¤ë©´ ì•„ë˜ ì¬ì„¤ì • ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
if st.button("ğŸ”§ ì¬ì„¤ì •(ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”)", disabled=not ss.prep_both_done):
    ss.prep_both_done = False
    ss.p_shared = 0
    st.rerun()

# ===== ëŒ€í™” UI (ê·¸ë£¹í† ë¡ ) =====
st.markdown("---")
st.subheader("ğŸ’¬ ê·¸ë£¹í† ë¡  â€” í•™ìƒ â†” ğŸ¤–Gemini(ì¹œì ˆ/ê¼¼ê¼¼) â†” ğŸ¤–ChatGPT(ìœ ë¨¸ëŸ¬ìŠ¤/ë³´ì™„)")

ready_google = "qe_google" in ss
ready_openai = "llm_openai" in ss  # RAGê°€ ì—†ì–´ë„ í´ë°± ë³´ì™„ì€ ê°€ëŠ¥

if ss.session_terminated:
    st.warning("ì„¸ì…˜ì´ ì¢…ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”.")
    st.stop()

if "qe_google" not in ss:
    st.info("ë¨¼ì € **[ğŸš€ í•œ ë²ˆì— ì¤€ë¹„í•˜ê¸°]** ë¥¼ í´ë¦­í•´ ë‘ë‡Œë¥¼ ì¤€ë¹„í•˜ì„¸ìš”. (OpenAI í‚¤ê°€ ì—†ìœ¼ë©´ Geminië§Œ ì‘ë‹µ)")
    st.stop()

# ì´ë¯¸ ìŒ“ì¸ ë©”ì‹œì§€ ë Œë”
for m in ss.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ìœ í‹¸: ì°¸ê³ ìë£Œ ê¼¬ë¦¬ ì œê±° & ë§¥ë½ êµ¬ì„±
def _strip_sources(text: str) -> str:
    return re.sub(r"\n+---\n\*ì°¸ê³  ìë£Œ:.*$", "", text, flags=re.DOTALL)

def _build_context_for_models(messages: list[dict], limit_pairs: int = 2, max_chars: int = 2000) -> str:
    pairs, buf_user = [], None
    for m in reversed(messages):
        role, content = m.get("role"), str(m.get("content", "")).strip()
        if role == "assistant":
            content = re.sub(r"^\*\*ğŸ¤– .*?\*\*\s*\n+", "", content).strip()
            if buf_user is not None:
                pairs.append((buf_user, content)); buf_user = None
                if len(pairs) >= limit_pairs: break
        elif role == "user" and buf_user is None:
            buf_user = content
    pairs = list(reversed(pairs))
    blocks = [f"[í•™ìƒ]\n{u}\n\n[êµì‚¬]\n{a}" for u, a in pairs]
    ctx = "\n\n---\n\n".join(blocks).strip()
    return ctx[-max_chars:] if len(ctx) > max_chars else ctx

# í˜ë¥´ì†Œë‚˜ í•©ì„±
def _persona():
    mode = st.session_state.get("mode_select", "ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…")
    base = EXPLAINER_PROMPT if mode == "ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…" else (ANALYST_PROMPT if mode == "ğŸ” êµ¬ë¬¸ ë¶„ì„" else READER_PROMPT)
    common = (
        "ì—­í• : í•™ìƒì˜ ì˜ì–´ ì‹¤ë ¥ì„ ë•ëŠ” AI êµì‚¬.\n"
        "ê·œì¹™: ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ë°íŒë‹¤. ì˜ˆì‹œ ë¬¸ì¥ì€ ì§§ê³  ì ì§„ì ìœ¼ë¡œ.\n"
    )
    return base + "\n" + common

# ëª¨ë“œ ìŠ¤ìœ„ì²˜
mode = st.radio("í•™ìŠµ ëª¨ë“œ", ["ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…", "ğŸ” êµ¬ë¬¸ ë¶„ì„", "ğŸ“š ë…í•´ ë° ìš”ì•½"],
                horizontal=True, key="mode_select")

# JSONL ë¡œê·¸ ì €ì¥(ì„œë¹„ìŠ¤ê³„ì •, chat_log/)
def _log_try(items):
    if not ss.save_logs:
        return
    try:
        parent_id = (getattr(settings, "CHATLOG_FOLDER_ID", None) or settings.GDRIVE_FOLDER_ID)
        sa = settings.GDRIVE_SERVICE_ACCOUNT_JSON
        if isinstance(sa, str):
            try: sa = json.loads(sa)
            except Exception: pass
        sub_id = get_chatlog_folder_id(parent_folder_id=parent_id, sa_json=sa)
        chat_store.append_jsonl(folder_id=sub_id, sa_json=sa, items=items)
        st.toast("ëŒ€í™” JSONL ì €ì¥ ì™„ë£Œ", icon="ğŸ’¾")
    except Exception as e:
        st.warning(f"ëŒ€í™” JSONL ì €ì¥ ì‹¤íŒ¨: {e}")

# ===== ì…ë ¥ì°½ =====
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ë¶„ì„/ìš”ì•½í•  ë¬¸ì¥ì´ë‚˜ ê¸€ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
if user_input:
    # 0) ì‚¬ìš©ì ë©”ì‹œì§€
    ss.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # JSONL ë¡œê·¸: ì‚¬ìš©ì
    _log_try([chat_store.make_entry(ss.session_id, "user", "user", user_input, mode, model="user")])

    # 1) Gemini 1ì°¨ (RAG ìš°ì„ )
    with st.spinner("ğŸ¤– Gemini ì„ ìƒë‹˜ì´ ë¨¼ì € ë‹µë³€í•©ë‹ˆë‹¤â€¦"):
        prev_ctx = _build_context_for_models(ss.messages[:-1], limit_pairs=2, max_chars=2000)
        gemini_query = (f"[ì´ì „ ëŒ€í™”]\n{prev_ctx}\n\n" if prev_ctx else "") + f"[í•™ìƒ ì§ˆë¬¸]\n{user_input}"
        ans_g = get_text_answer(
            ss["qe_google"],
            gemini_query,
            _persona() + "\n" + GEMINI_STYLE + "\n" + RAG_FIRST_RULES
        )

    content_g = f"**ğŸ¤– Gemini**\n\n{ans_g}"
    ss.messages.append({"role": "assistant", "content": content_g})
    with st.chat_message("assistant"):
        st.markdown(content_g)

    # JSONL ë¡œê·¸: Gemini
    _log_try([chat_store.make_entry(
        ss.session_id, "assistant", "Gemini", content_g, mode,
        model=getattr(settings, "LLM_MODEL", "gemini")
    )])

    # 2) ChatGPT ë³´ì™„/ê²€ì¦ â€” RAG ìš°ì„ (OpenAI QueryEngine) â†’ ì‹¤íŒ¨ ì‹œ LLM í´ë°±
    if ready_openai:
        review_directive = (
            "ì—­í• : ë‹¹ì‹ ì€ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ì§€ë§Œ ì •í™•í•œ ë™ë£Œ ì˜ì–´êµì‚¬ë‹¤. "
            "ë™ë£Œ(Gemini)ì˜ 1ì°¨ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ êµì •/ë³´ì™„í•˜ê³  ë§ˆë¬´ë¦¬í•œë‹¤.\n"
            "ì¶œë ¥ ì§€ì¹¨:\n"
            "1) ì˜ëª»ëœ ë¶€ë¶„ì€ ë°”ë¡œì¡ê³  ëˆ„ë½ í¬ì¸íŠ¸ë¥¼ ì±„ìš´ë‹¤.\n"
            "2) ì˜ˆë¬¸ 2~3ê°œ(ê°„ë‹¨/ì ì§„ì ) ì¶”ê°€.\n"
            "3) ë§ˆì§€ë§‰ì— <ìµœì¢… ì •ë¦¬>ë¥¼ ë¶ˆë¦¿ 3~5ê°œë¡œ ì œì‹œ.\n"
        )

        prev_ctx_all = _build_context_for_models(ss.messages, limit_pairs=2, max_chars=2000)  # Gemini ë°©ê¸ˆ ë‹µ í¬í•¨
        rag_query_for_openai = (
            (f"[ì´ì „ ëŒ€í™”]\n{prev_ctx_all}\n\n" if prev_ctx_all else "") +
            f"[í•™ìƒ ì§ˆë¬¸]\n{user_input}\n\n"
            f"[ë™ë£Œì˜ 1ì°¨ ë‹µë³€(Gemini)]\n{_strip_sources(ans_g)}\n\n"
            "[ì‘ì—…]\nìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—…ë¡œë“œ ìë£Œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì ê²€Â·ë³´ì™„í•˜ê³ , "
            "ëˆ„ë½/ì˜¤ë¥˜ë¥¼ ê³ ì¹œ ë’¤ ê°„ê²°í•˜ê²Œ ë§ˆë¬´ë¦¬í•˜ë¼."
        )

        used_rag = False
        ans_o = None
        try:
            if "qe_openai" in ss:
                ans_o = get_text_answer(
                    ss["qe_openai"],
                    rag_query_for_openai,
                    _persona() + "\n" + CHATGPT_REVIEW_STYLE + "\n" + RAG_FIRST_RULES + "\n" + review_directive,
                )
                used_rag = True
        except Exception as e:
            used_rag = False
            ans_o = f"(RAG ë³´ì™„ ì‹¤íŒ¨ë¡œ í´ë°±í•©ë‹ˆë‹¤) ì—ëŸ¬: {e}"

        if not used_rag:
            from src.rag_engine import llm_complete
            augmented = (
                (f"[ì´ì „ ëŒ€í™”]\n{prev_ctx_all}\n\n" if prev_ctx_all else "") +
                f"[í•™ìƒ ì§ˆë¬¸]\n{user_input}\n\n"
                f"[ë™ë£Œì˜ 1ì°¨ ë‹µë³€(Gemini)]\n{_strip_sources(ans_g)}\n\n"
                f"[ë‹¹ì‹ ì˜ ì‘ì—…]\nì—…ë¡œë“œ ìë£Œë¥¼ ìš°ì„ í•œë‹¤ëŠ” ì „ì œë¥¼ ìœ ì§€í•˜ë˜, ìë£Œ ì°¸ì¡°ê°€ ë¶ˆê°€ëŠ¥í•˜ë©´ "
                f"ê°„ë‹¨í•œ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œë§Œ ë³´ì™„í•˜ë¼. ë³´ê°• ë¬¸ì¥ ì•ì—ëŠ” '(ìë£Œ ë°– ì§€ì‹)'ì„ ë¶™ì—¬ë¼."
            )
            try:
                ans_o = llm_complete(
                    ss.get("llm_openai"),
                    _persona() + "\n" + CHATGPT_REVIEW_STYLE + "\n" + review_directive + "\n\n" + augmented
                )
            except Exception as e:
                ans_o = f"(ë³´ì™„ ë‹¨ê³„ ì˜¤ë¥˜ë¡œ Gemini ë‹µë³€ë§Œ ì œê³µí•©ë‹ˆë‹¤)\n\nì—ëŸ¬: {e}"

        content_o = f"**ğŸ¤– ChatGPT**\n\n{ans_o}"
        ss.messages.append({"role": "assistant", "content": content_o})
        with st.chat_message("assistant"):
            st.markdown(content_o)
    else:
        with st.chat_message("assistant"):
            st.info("ChatGPT í‚¤ê°€ ì—†ì–´ Geminië§Œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤. OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ë©´ ë³´ì™„/ê²€ì¦ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

    # â¶ OAuth: Markdown ìë™ ì €ì¥ (ë‚´ ë“œë¼ì´ë¸Œ, my-ai-teacher-data/chat_log/)
    if ss.auto_save_chatlog and ss.messages:
        try:
            if is_signed_in():
                svc = build_drive_service()
                parent_id = (st.secrets.get("OAUTH_CHAT_PARENT_ID") or "").strip() or None
                _fid = save_chatlog_markdown_oauth(ss.session_id, ss.messages, svc, parent_id)
                st.toast("ë‚´ ë“œë¼ì´ë¸Œì— ëŒ€í™” ì €ì¥ ì™„ë£Œ âœ…", icon="ğŸ’¾")
            else:
                st.info("êµ¬ê¸€ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ë©´ ëŒ€í™”ê°€ **ë‚´ ë“œë¼ì´ë¸Œ**ì— ì €ì¥ë©ë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"OAuth ì €ì¥ ì‹¤íŒ¨: {e}")

    st.rerun()
