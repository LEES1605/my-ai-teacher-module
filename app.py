# app.py â€” ê´€ë¦¬ì ì´ˆê¸° "ì™„ì „ ìŠ¤ìº”(heavy) + ìˆ«ì ì§„í–‰ë¥  + ë©ˆì¶¤ ê°ì§€" ì§€ì›
#        + prepared/ ì§ì ‘ íˆ¬ì… ê°ì§€(ì¤‘ë³µ ìŠ¤í‚µ) + ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸°
#        + ì¦ë¶„ ì¸ë±ì‹±(ì¤‘ê°„ì·¨ì†Œ/ì¬ê°œ) + ì†Œì±…ì ìƒì„± ìë™í™”
#        + Drive ëŒ€í™”ë¡œê·¸ ì €ì¥(OAuth/ì„œë¹„ìŠ¤ê³„ì •) + ê·¸ë£¹í† ë¡  UI(Gemini+ChatGPT)

from __future__ import annotations
import os, time, uuid, re, json, io, hashlib
import pandas as pd
import streamlit as st

# ================= 0) í˜ì´ì§€/ëŸ°íƒ€ì„ ê¸°ë³¸ =================
st.set_page_config(page_title="ë‚˜ì˜ AI ì˜ì–´ êµì‚¬", layout="wide", initial_sidebar_state="collapsed")
ss = st.session_state
ss.setdefault("_boot_log", []); ss.setdefault("_oauth_checked", False)

def _boot(msg: str): ss["_boot_log"].append(msg)
with st.sidebar:
    st.caption("ğŸ›  Boot log (ì„ì‹œ)"); _boot_box = st.empty()
def _flush_boot():
    try: _boot_box.write("\n".join(ss["_boot_log"]) or "(empty)")
    except Exception: pass
_boot("A: page_config set"); _flush_boot()

# ëŸ°íƒ€ì„ íŠœë‹
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_SERVER_ENABLE_WEBSOCKET_COMPRESSION"] = "false"

# ================= 1) ì„¸ì…˜ í‚¤ ì´ˆê¸°í™” ====================
ss.setdefault("session_id", uuid.uuid4().hex[:12])
ss.setdefault("messages", [])
ss.setdefault("auto_save_chatlog", True)
ss.setdefault("save_logs", False)
ss.setdefault("prep_both_running", False)
ss.setdefault("prep_both_done", ("qe_google" in ss) or ("qe_openai" in ss))
ss.setdefault("prep_cancel_requested", False)
ss.setdefault("session_terminated", False)
ss.setdefault("index_job", None)

# ì—…ë¡œë“œ/ê°ì‹œ íŒŒì´í”„ë¼ì¸
ss.setdefault("_auto_booklets_pending", False)
ss.setdefault("_auto_topics_text", "")
ss.setdefault("_auto_booklet_title", "Grammar Booklets")
ss.setdefault("_auto_make_citations", True)

# í´ë” ê°ì‹œ ì˜µì…˜
ss.setdefault("_watch_on_load", True)            # í˜ì´ì§€ ì—´ë¦¬ë©´ ìë™ ìŠ¤ìº”
ss.setdefault("_watch_ran_once", False)          # ë¬´í•œ rerun ë°©ì§€
ss.setdefault("_watch_rename_title", False)      # ê°ì‹œ ì‹œ AI ì œëª© ì •ë¦¬ ì—¬ë¶€

# ê´€ë¦¬ì ì „ìš© ìƒíƒœ
ss.setdefault("_admin_initial_fullscan_done", False)
ss.setdefault("_admin_scan_cancel", False)

# ì§„í–‰/ì›Œì¹˜ë… ì„¤ì •
STALL_WARN_SEC = int(os.getenv("STALL_WARN_SEC", "20"))   # Nì´ˆ ì´ìƒ ë¬´ì§„í–‰ â†’ ê²½ê³ 
YIELD_SLEEP    = float(os.getenv("YIELD_SLEEP", "0.05"))  # ë£¨í”„ UI ê°±ì‹  í…€

# Fast-scan ë…¸ë¸Œ(ì¼ë°˜ ì‚¬ìš©ì ìë™ ê°ì‹œìš©; ê´€ë¦¬ìëŠ” heavy ìš°ì„ )
FAST_LIST_LIMIT = int(os.getenv("PREPARED_FAST_LIST_LIMIT", "400"))
FAST_HASH_LIMIT = int(os.getenv("PREPARED_FAST_HASH_LIMIT", "40"))

st.caption(f"heartbeat âœ… keys={list(ss.keys())[:8]}")

# ================= 2) í—¤ë”/ìŠ¤íƒ€ì¼ =======================
from src.ui import load_css, render_header
load_css(); render_header()
st.info("âœ… ì²« ë°©ë¬¸(ê´€ë¦¬ì)ì€ ì •í™•ë„ë¥¼ ìœ„í•´ **ì™„ì „ ìŠ¤ìº”**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì§„í–‰ë¥ /ì§€ì—° ê²½ê³ ë¡œ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.")

# ================= 3) OAuth ë¦¬ë‹¤ì´ë ‰íŠ¸ ===================
try:
    from src.google_oauth import finish_oauth_if_redirected
    if not st.secrets.get("OAUTH_DISABLE_FINISH"):
        if not ss.get("_oauth_finalized", False):
            finalized = finish_oauth_if_redirected()
            if finalized:
                ss["_oauth_finalized"] = True
                try: st.query_params.clear()
                except Exception: st.experimental_set_query_params()
                st.rerun()
except Exception as e:
    st.warning(f"OAuth finalize skipped: {e}")

# ================= 4) ì‚¬ì´ë“œë°”: ë¡œê·¸ì¸/ì˜µì…˜ ==============
from src.google_oauth import start_oauth, is_signed_in, build_drive_service, get_user_email, sign_out
with st.sidebar:
    ss.auto_save_chatlog = st.toggle("ëŒ€í™” ìë™ ì €ì¥ (OAuth/ë‚´ ë“œë¼ì´ë¸Œ, Markdown)", value=ss.auto_save_chatlog)
    ss.save_logs = st.toggle("ëŒ€í™” JSONL ì €ì¥ (ì„œë¹„ìŠ¤ê³„ì •/chat_log/)", value=ss.save_logs,
                             help="ê³µìœ ë“œë¼ì´ë¸Œ Writer ê¶Œí•œ í•„ìš”. ì¿¼í„° ë¬¸ì œ ì‹œ ë„ê¸° ê¶Œì¥.")
    st.markdown("---")
    st.markdown("### Google ë¡œê·¸ì¸ (ë‚´ ë“œë¼ì´ë¸Œ ì €ì¥)")
    if not is_signed_in():
        if st.button("ğŸ” Googleë¡œ ë¡œê·¸ì¸"):
            url = start_oauth(); st.markdown(f"[ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ ë¡œê·¸ì¸í•˜ì„¸ìš”]({url})")
    else:
        st.success(f"ë¡œê·¸ì¸ë¨: {get_user_email() or 'ì•Œ ìˆ˜ ì—†ìŒ'}")
        if st.button("ë¡œê·¸ì•„ì›ƒ"): sign_out(); st.rerun()

# ================= 5) ê´€ë¦¬ì íŒë³„ ========================
def _admin_emails() -> set[str]:
    raw = str(st.secrets.get("ADMIN_EMAILS", "")).strip()
    return set([e.strip().lower() for e in raw.split(",") if e.strip()])
def _is_admin() -> bool:
    if str(st.secrets.get("ADMIN_MODE_ALWAYS_ON","0")).strip() == "1":
        return True
    try:
        return (get_user_email() or "").lower() in _admin_emails()
    except Exception:
        return False

IS_ADMIN = _is_admin()

# ================= 6) Drive ì—°ê²° í…ŒìŠ¤íŠ¸ ==================
st.markdown("## ğŸ”— Google Drive ì—°ê²° í…ŒìŠ¤íŠ¸")
st.caption("ì„œë¹„ìŠ¤ê³„ì • ì €ì¥ì€ ê³µìœ ë“œë¼ì´ë¸Œ Writer ê¶Œí•œì´ í•„ìš”. ì¸ë±ì‹±ì€ Readonlyë©´ ì¶©ë¶„í•©ë‹ˆë‹¤.")

from src.config import settings
from src.rag_engine import smoke_test_drive, preview_drive_files, drive_diagnostics
try:
    ok_sa, head_sa, details_sa = drive_diagnostics(settings.GDRIVE_FOLDER_ID)
    if ok_sa: st.success(head_sa)
    else:     st.warning(head_sa)
    with st.expander("ì„œë¹„ìŠ¤ê³„ì • JSON ì§„ë‹¨ ìƒì„¸", expanded=not ok_sa):
        st.code("\n".join(details_sa), language="text")
except Exception as e:
    st.warning("ì§„ë‹¨ í•¨ìˆ˜ ì˜ˆì™¸:")
    st.code(f"{type(e).__name__}: {e}\níƒ€ì…={type(settings.GDRIVE_SERVICE_ACCOUNT_JSON).__name__}\n"
            f"í”„ë¦¬ë·°={str(settings.GDRIVE_SERVICE_ACCOUNT_JSON)[:200]}...", language="text")

colL, colR = st.columns([0.65, 0.35], vertical_alignment="top")
with colL:
    if st.button("í´ë” íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ìµœì‹  10ê°œ)", use_container_width=True):
        ok, msg, rows = preview_drive_files(max_items=10)
        if ok and rows:
            df = pd.DataFrame(rows)
            df["type"] = df["mime"].str.replace("application/vnd.google-apps.", "", regex=False)
            df = df.rename(columns={"modified": "modified_at"})[["name","link","type","modified_at"]]
            st.dataframe(df, use_container_width=True, height=360,
                         column_config={"name": st.column_config.TextColumn("íŒŒì¼ëª…"),
                                        "link": st.column_config.LinkColumn("open", display_text="ì—´ê¸°"),
                                        "type": st.column_config.TextColumn("ìœ í˜•"),
                                        "modified_at": st.column_config.TextColumn("ìˆ˜ì •ì‹œê°")},
                         hide_index=True)
            st.success(f"ì´ {len(rows)}ê°œ í•­ëª© í‘œì‹œ (ìµœì‹  10ê°œ ê¸°ì¤€).")
        elif ok: st.info("í´ë”ì— íŒŒì¼ì´ ì—†ê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:    st.error(msg)

with colR:
    ok, msg = smoke_test_drive()
    if ok: st.success(msg)
    else:  st.warning(msg)

# ================= 7) ìœ í‹¸ ===============================
def _ts(): return time.strftime("%Y%m%d_%H%M%S")
def _safe_name(name: str) -> str:
    name = re.sub(r'[\\/:*?"<>|]+', " ", str(name)); name = re.sub(r"\s+", " ", name).strip()
    return name or "untitled"
def _guess_mime_by_ext(fname: str) -> str:
    ext = (fname.rsplit(".", 1)[-1] if "." in fname else "").lower()
    MIMES = {
        "pdf":"application/pdf","docx":"application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        "doc":"application/msword","pptx":"application/vnd.openxmlformats-officedocument.presentationml.presentation",
        "ppt":"application/vnd.ms-powerpoint","md":"text/markdown","txt":"text/plain","rtf":"application/rtf",
        "odt":"application/vnd.oasis.opendocument.text","html":"text/html","epub":"application/epub+zip",
        "xlsx":"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet","xls":"application/vnd.ms-excel","csv":"text/csv",
    }; return MIMES.get(ext, "application/octet-stream")

# ì œëª© ìƒì„±ê¸°
_TITLE_MODEL = None
from src.rag_engine import make_llm, llm_complete
def _get_title_model():
    global _TITLE_MODEL
    if _TITLE_MODEL is not None: return _TITLE_MODEL
    try:
        if getattr(settings, "OPENAI_API_KEY", None) and settings.OPENAI_API_KEY.get_secret_value():
            _TITLE_MODEL = make_llm("openai", settings.OPENAI_API_KEY.get_secret_value(),
                                    getattr(settings,"OPENAI_LLM_MODEL","gpt-4o-mini"), 0.2)
        else:
            _TITLE_MODEL = make_llm("google", settings.GEMINI_API_KEY.get_secret_value(),
                                    getattr(settings,"LLM_MODEL","gemini-1.5-pro"), 0.2)
    except Exception:
        _TITLE_MODEL = None
    return _TITLE_MODEL
def _heuristic_title(orig_base: str, hint: str = "") -> str:
    base = re.sub(r"\.[^.]+$", "", orig_base)
    base = re.sub(r"^\d{8}_\d{6}__", "", base)
    base = base.replace("_"," ").replace("-"," "); base = re.sub(r"\s+"," ",base).strip()
    if hint: base = f"{hint.strip()} â€” {base}" if base else hint.strip()
    return (base[:40]).strip() or "untitled"
def _ai_title(orig_base: str, sample_text: str = "", hint: str = "") -> str:
    model = _get_title_model()
    if model is None: return _heuristic_title(orig_base, hint)
    prompt = (
        "ë‹¤ìŒ íŒŒì¼ì˜ ì œëª©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ê·œì¹™:\n"
        "1) ìµœëŒ€ 40ì, 2) ë¶ˆí•„ìš”í•œ ìˆ«ì/í™•ì¥ì ì œê±°, 3) í•µì‹¬ í‚¤ì›Œë“œ ìœ„ì£¼, 4) ë”°ì˜´í‘œ/ê´„í˜¸ ë‚¨ë°œ ê¸ˆì§€,\n"
        "5) ë¬¸ì¥í˜• ë§íˆ¬ë³´ë‹¤ ëª…ì‚¬êµ¬ ì„ í˜¸, 6) ì¶œë ¥ì€ ì œëª©ë§Œ(ë¶€ê°€ ì„¤ëª…/ë”°ì˜´í‘œ X).\n\n"
        f"[íŒŒì¼ëª… íŒíŠ¸]\n{orig_base}\n\n"
    )
    if hint: prompt += f"[ì¶”ê°€ íŒíŠ¸]\n{hint}\n\n"
    if sample_text: prompt += f"[ë³¸ë¬¸ ì¼ë¶€]\n{sample_text[:1200]}\n\n"
    try:
        title = llm_complete(model, prompt).strip()
        return (_safe_name(title)[:40]).strip() or _heuristic_title(orig_base, hint)
    except Exception:
        return _heuristic_title(orig_base, hint)

# ================= 8) ì†Œì±…ì ìƒì„± =======================
def generate_booklets_drive(topics: list[str], booklet_title: str, make_citations: bool=True):
    """ss['qe_google'] ê¸°ë°˜ìœ¼ë¡œ topicsë³„ .md ìƒì„± â†’ prepared_volumes/<ì„¸íŠ¸ëª…_íƒ€ì„ìŠ¤íƒ¬í”„>/ ì €ì¥"""
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaIoBaseUpload
    from src.rag_engine import _normalize_sa, get_text_answer

    def _safe(s: str) -> str:
        s = re.sub(r'[\\/:*?"<>|]+', " ", str(s)); s = re.sub(r"\s+", " ", s).strip(); return s[:120] or "untitled"

    creds = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
    drive = build("drive","v3",credentials=creds)

    def _ensure_child(parent_id: str, name: str) -> str:
        q = (f"'{parent_id}' in parents and name = '{name}' "
             "and mimeType = 'application/vnd.google-apps.folder' and trashed = false")
        res = drive.files().list(q=q, fields="files(id,name)", pageSize=1,
                                 includeItemsFromAllDrives=True, supportsAllDrives=True).execute()
        fs = res.get("files", []); 
        if fs: return fs[0]["id"]
        meta = {"name": name, "parents":[parent_id], "mimeType":"application/vnd.google-apps.folder"}
        f = drive.files().create(body=meta, fields="id").execute(); return f["id"]

    parent_volumes_id = _ensure_child(settings.GDRIVE_FOLDER_ID, "prepared_volumes")
    set_name = f"{_safe(booklet_title)}_{_ts()}"; set_folder = _ensure_child(parent_volumes_id, set_name)

    rows, manifest = [], {"title": booklet_title, "created_at": _ts(), "items": []}
    for topic in topics:
        guide = ("ë‹¹ì‹ ì€ ì˜ì–´ ë¬¸ë²• êµì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ í† í”½ì„ í•™ìƒìš© ì†Œì±…ì í˜•íƒœë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n"
                 f"â€¢ í† í”½: {topic}\n"
                 "â€¢ í•µì‹¬ ê°œë…ì€ í•œêµ­ì–´, ê·œì¹™/í˜•íƒœëŠ” ì˜ë¬¸ í˜¼ìš©\n"
                 "â€¢ ì˜ˆë¬¸ 3~5ê°œ(ì‰¬ì›€â†’ì¤‘ê°„), í•œ-ì˜ ë³‘ê¸°\n"
                 "â€¢ ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜ 3ê°œ\n"
                 "â€¢ ë¯¸ë‹ˆ ì—°ìŠµë¬¸ì œ 5ë¬¸í•­(+ì •ë‹µ/í•´ì„¤)\n"
                 "â€¢ 500~900ì ë‚´ì™¸\n")
        if make_citations: guide += "â€¢ ë§ˆì§€ë§‰ì— â€˜---\\n*ì°¸ê³  ìë£Œ: íŒŒì¼ëª… â€¦â€™ ì„¹ì…˜ í¬í•¨\n"
        md = get_text_answer(ss["qe_google"], f"[í† í”½]\n{topic}\n\n[ê³¼ì œ]\nìœ„ ê°€ì´ë“œë¡œ í•™ìƒìš© ë§ˆí¬ë‹¤ìš´ ì‘ì„±", guide)
        name = f"{_safe(topic)}.md"; buf = io.BytesIO(md.encode("utf-8"))
        media = MediaIoBaseUpload(buf, mimetype="text/markdown", resumable=False)
        meta = {"name": name, "parents": [set_folder]}
        file = drive.files().create(body=meta, media_body=media, fields="id,webViewLink").execute()
        rows.append({"topic": topic, "open": file.get("webViewLink")})
        manifest["items"].append({"topic": topic, "file_id": file["id"], "name": name})

    # overview & manifest
    ov = [f"# {booklet_title}", "", f"ìƒì„±ì‹œê°: {time.strftime('%Y-%m-%d %H:%M:%S')}", ""]
    for it in manifest["items"]: ov.append(f"- {it['topic']} â€” {it['name']}")
    overview_md = "\n".join(ov) + "\n"

    from googleapiclient.http import MediaIoBaseUpload
    drive.files().create(
        body={"name": "overview.md", "parents": [set_folder]},
        media_body=MediaIoBaseUpload(io.BytesIO(overview_md.encode("utf-8")), mimetype="text/markdown", resumable=False),
        fields="id").execute()
    drive.files().create(
        body={"name": "manifest.json", "parents": [set_folder]},
        media_body=MediaIoBaseUpload(io.BytesIO(json.dumps(manifest, ensure_ascii=False, indent=2).encode("utf-8")),
                                     mimetype="application/json", resumable=False),
        fields="id").execute()
    return {"folder_name": set_name, "folder_id": set_folder, "rows": rows}

# ================= 9) prepared ê°ì‹œ/ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ==========
from googleapiclient.discovery import build as _build_gd
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
from src.rag_engine import _normalize_sa
def _build_sa_drive():
    creds = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
    return _build_gd("drive","v3",credentials=creds)
def _find_file(drive, parent_id: str, name: str):
    q = f"'{parent_id}' in parents and name = '{name}' and trashed = false"
    res = drive.files().list(q=q, fields="files(id,name,mimeType)", pageSize=1,
                             includeItemsFromAllDrives=True, supportsAllDrives=True).execute()
    fs = res.get("files", []); return (fs[0]["id"] if fs else None)
def _load_manifest(drive):
    mid = _find_file(drive, settings.GDRIVE_FOLDER_ID, "prepared_manifest.json")
    data = {"items":{}, "updated_at": _ts()}
    if mid:
        req = drive.files().get_media(fileId=mid); buf = io.BytesIO(); MediaIoBaseDownload(buf, req).next_chunk()
        try: data = json.loads(buf.getvalue().decode("utf-8"))
        except Exception: pass
    return mid, data
def _save_manifest(drive, manifest, file_id=None):
    body = MediaIoBaseUpload(io.BytesIO(json.dumps(manifest, ensure_ascii=False, indent=2).encode("utf-8")),
                             mimetype="application/json", resumable=False)
    if file_id:
        drive.files().update(fileId=file_id, media_body=body).execute()
    else:
        drive.files().create(body={"name":"prepared_manifest.json","parents":[settings.GDRIVE_FOLDER_ID]},
                             media_body=body, fields="id").execute()
def _list_prepared(drive, max_items: int | None = None):
    q = f"'{settings.GDRIVE_FOLDER_ID}' in parents and trashed = false"
    fields = "files(id,name,mimeType,modifiedTime,version,md5Checksum,size), nextPageToken"
    token=None; items=[]; cap = max_items or FAST_LIST_LIMIT
    while True:
        page_size = min(1000, max(1, cap-len(items)))
        res = drive.files().list(q=q, fields=fields, pageSize=page_size, pageToken=token,
                                 includeItemsFromAllDrives=True, supportsAllDrives=True).execute()
        items.extend(res.get("files", [])); 
        if len(items) >= cap: break
        token=res.get("nextPageToken")
        if not token: break
    return items
def _list_prepared_all(drive):
    q = f"'{settings.GDRIVE_FOLDER_ID}' in parents and trashed = false"
    fields = "files(id,name,mimeType,modifiedTime,version,md5Checksum,size), nextPageToken"
    token=None; items=[]
    while True:
        res = drive.files().list(q=q, fields=fields, pageSize=1000, pageToken=token,
                                 includeItemsFromAllDrives=True, supportsAllDrives=True).execute()
        items.extend(res.get("files", [])); token=res.get("nextPageToken")
        if not token: break
    return items
def _file_sig(drive, meta: dict, fast: bool = False) -> str:
    """
    ë‚´ìš© ì„œëª…:
      - ì¼ë°˜ íŒŒì¼: md5Checksum ìš°ì„ . ì—†ìœ¼ë©´ (fast=True) ì„ì‹œì„œëª…(size+mtime) ë˜ëŠ” (fast=False) ë°”ì´ë„ˆë¦¬ SHA256
      - Google ë¬¸ì„œë¥˜: (fast=True) version+mtime ì„ì‹œì„œëª…, (fast=False) PDF export â†’ SHA256
    """
    mt = meta.get("mimeType", ""); fid = meta["id"]
    if not mt.startswith("application/vnd.google-apps/"):
        if meta.get("md5Checksum"): return "md5:"+meta["md5Checksum"]
        if fast:
            return f"tmp:{meta.get('size','?')}@{meta.get('modifiedTime','')}"
        req = drive.files().get_media(fileId=fid); buf = io.BytesIO(); MediaIoBaseDownload(buf, req).next_chunk()
        return "sha256:"+hashlib.sha256(buf.getvalue()).hexdigest()
    if fast:
        return f"ver:{meta.get('version','?')}@{meta.get('modifiedTime','')}"
    data = drive.files().export(fileId=fid, mimeType="application/pdf").execute()
    return "sha256:"+hashlib.sha256(data).hexdigest()

# ---- ì¼ë°˜ ì‚¬ìš©ììš©(ë¹ ë¥¸ ìŠ¤ìº”) ----
def watch_scan_and_schedule(topics_text: str, title: str, cite: bool, rename_title: bool=False):
    drive = _build_sa_drive()
    mid, manifest = _load_manifest(drive)
    known: dict = manifest.get("items", {})
    pending_full: list[str] = manifest.get("pending_full", [])
    heavy_budget = FAST_HASH_LIMIT

    # ëŒ€ê¸°ì—´ ì¼ë¶€ í™•ì •
    if pending_full and heavy_budget > 0:
        still=[]
        for fid in pending_full:
            if heavy_budget<=0: still.append(fid); continue
            meta = drive.files().get(fileId=fid, fields="id,name,mimeType,modifiedTime,version,md5Checksum,size").execute()
            try:
                sig = _file_sig(drive, meta, fast=False); heavy_budget -= 1
                known[fid] = {"name": meta.get("name","untitled"), "sig": sig, "processed_at": known.get(fid,{}).get("processed_at")}
            except Exception:
                still.append(fid)
        pending_full = still

    metas = _list_prepared(drive, max_items=FAST_LIST_LIMIT)
    name_sig_set = {(v.get("name"), v.get("sig")) for v in known.values()}
    new_or_changed = []
    for m in metas:
        fid, name = m["id"], m.get("name","untitled")
        if name == "prepared_manifest.json": continue
        is_google = m.get("mimeType","").startswith("application/vnd.google-apps/")
        has_md5 = bool(m.get("md5Checksum"))
        needs_heavy = (is_google or not has_md5)
        try:
            sig = _file_sig(drive, m, fast=not needs_heavy or heavy_budget<=0)
            if needs_heavy and heavy_budget<=0 and fid not in pending_full: pending_full.append(fid)
            if needs_heavy and heavy_budget>0:
                heavy_budget -= 1
        except Exception as e:
            st.warning(f"ì‹œê·¸ë‹ˆì²˜ ì‹¤íŒ¨: {name} â†’ {e}")
            continue
        prev = known.get(fid)
        if prev and prev.get("sig")==sig: continue
        if (name, sig) in name_sig_set:
            known[fid] = {"name": name, "sig": sig, "processed_at": prev.get("processed_at") if prev else _ts()}
            continue
        new_or_changed.append({"id":fid,"name":name,"sig":sig})
        known[fid] = {"name": name, "sig": sig, "processed_at": None}
        name_sig_set.add((name, sig))

    manifest["items"] = known; manifest["pending_full"] = pending_full; manifest["updated_at"] = _ts()
    _save_manifest(drive, manifest, mid)

    if not new_or_changed:
        return False, 0

    ss["_auto_booklets_pending"] = True
    ss["_auto_topics_text"] = topics_text
    ss["_auto_booklet_title"] = title
    ss["_auto_make_citations"] = cite
    ss.prep_both_done = False; ss.prep_both_running = True; ss.index_job = None
    st.info(f"prepared/ ì‹ ê·œ/ë³€ê²½ {len(new_or_changed)}ê°œ ê°ì§€ â†’ ì¸ë±ì‹±/ìµœì í™” ì‹œì‘")
    st.rerun()
    return True, len(new_or_changed)

# ---- ê´€ë¦¬ììš©(ì™„ì „ ìŠ¤ìº” + ì§„í–‰ë¥ /ì›Œì¹˜ë…/ì·¨ì†Œ) ----
def admin_full_scan_and_schedule(topics_text: str, title: str, cite: bool, rename_title: bool=False):
    drive = _build_sa_drive()
    mid, manifest = _load_manifest(drive)
    known: dict = manifest.get("items", {})
    name_sig_set = {(v.get("name"), v.get("sig")) for v in known.values()}

    metas = _list_prepared_all(drive)
    metas = [m for m in metas if m.get("name")!="prepared_manifest.json"]

    # ì§„í–‰íŒ
    box = st.container(border=True)
    with box:
        st.markdown("### ğŸ›¡ ê´€ë¦¬ì: ì´ˆê¸° ì „ì²´ ìŠ¤ìº”(ì •í™•ë„ ìš°ì„ )")
        prog = st.progress(0, text="ì¤€ë¹„ ì¤‘â€¦")
        info_line = st.empty()
        delay_line = st.empty()
        cancel_col, _ = st.columns([0.25, 0.75])
        with cancel_col:
            if st.button("â›” ê°•ì œ ì¤‘ë‹¨", use_container_width=True):
                ss["_admin_scan_cancel"] = True

    total = len(metas); done = 0
    started = time.time(); last_tick = time.time()
    new_or_changed = 0

    for m in metas:
        if ss.get("_admin_scan_cancel"):
            info_line.warning("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨.")
            break

        fid, name = m["id"], m.get("name","untitled")
        try:
            sig = _file_sig(drive, m, fast=False)  # í•­ìƒ í™•ì • í•´ì‹œ
        except Exception as e:
            done += 1
            pct = int(done/max(total,1)*100)
            prog.progress(pct, text=f"í•´ì‹œ ì‹¤íŒ¨ ìŠ¤í‚µ: {name} â†’ {e}")
            info_line.error(f"í•´ì‹œ ì‹¤íŒ¨: {name} â†’ {e}")
            last_tick = time.time()
            time.sleep(YIELD_SLEEP)
            continue

        prev = known.get(fid)
        if not (prev and prev.get("sig")==sig):
            if (name, sig) not in name_sig_set:
                new_or_changed += 1
                known[fid] = {"name": name, "sig": sig, "processed_at": None}
                name_sig_set.add((name, sig))
            else:
                known[fid] = {"name": name, "sig": sig, "processed_at": prev.get("processed_at") if prev else _ts()}

        done += 1
        pct = int(done/max(total,1)*100)
        elapsed = int(time.time()-started)
        mm, ss_ = divmod(elapsed, 60)
        prog.progress(pct, text=f"{pct}% | {done}/{total} | {mm:02d}:{ss_:02d} | {name}")
        info_line.info(f"ì§„í–‰: {done}/{total} (ì‹ ê·œ/ë³€ê²½ {new_or_changed})")
        # ì›Œì¹˜ë…(ì§€ì—° ê°ì§€)
        if time.time() - last_tick > STALL_WARN_SEC:
            delay_line.warning("â± ì§€ì—°(ë„¤íŠ¸ì›Œí¬/ì¿¼í„°) ë°œìƒ ê°€ëŠ¥ â€” ê³„ì† ëŒ€ê¸° ì¤‘â€¦")
        else:
            delay_line.empty()
        last_tick = time.time()
        time.sleep(YIELD_SLEEP)

    # ê²°ê³¼ ì €ì¥
    manifest["items"] = known; manifest["pending_full"] = []; manifest["updated_at"] = _ts()
    _save_manifest(drive, manifest, mid)

    if ss.get("_admin_scan_cancel"):
        ss["_admin_scan_cancel"] = False
        st.stop()

    if new_or_changed == 0:
        with box: st.success("ì™„ë£Œ â€” ì‹ ê·œ/ë³€ê²½ ì—†ìŒ (ëª¨ë‘ ìµœì‹ ).")
        return False, 0

    # íŒŒì´í”„ë¼ì¸ ì˜ˆì•½
    ss["_auto_booklets_pending"] = True
    ss["_auto_topics_text"] = topics_text
    ss["_auto_booklet_title"] = title
    ss["_auto_make_citations"] = cite
    ss.prep_both_done = False; ss.prep_both_running = True; ss.index_job = None
    with box: st.success(f"ì™„ë£Œ â€” ì‹ ê·œ/ë³€ê²½ {new_or_changed}ê°œ â†’ ì¸ë±ì‹±/ìµœì í™” ì‹œì‘")
    st.rerun()
    return True, new_or_changed

# ================= 10) ì—…ë¡œë“œ(ì›ë³¸â†’prepared) ============
with st.expander("ğŸ“¤ ê´€ë¦¬ì: ìë£Œ ì—…ë¡œë“œ (ì›ë³¸â†’prepared ì €ì¥)", expanded=False):
    st.caption("ì›ë³¸ì€ prepared/ì— ì €ì¥ë©ë‹ˆë‹¤. (ì˜µì…˜ ON) ì—…ë¡œë“œ í›„ ìë™ìœ¼ë¡œ ë¬¸ë²• ì†Œì±…ì(ìµœì í™”ë³¸)ë¥¼ Driveì— ì €ì¥í•©ë‹ˆë‹¤.")
    auto_title = st.toggle("AI ì œëª© ìë™ ìƒì„±(ì—…ë¡œë“œ í›„ ì´ë¦„ ë°”ê¾¸ê¸°)", value=True)
    title_hint = st.text_input("ì œëª© íŒíŠ¸(ì„ íƒ)", placeholder="ì˜ˆ: ê³ 1 ì˜ì–´ ë¬¸ë²• / í•™ì› êµì¬ / ì¤‘ê°„ê³ ì‚¬ ëŒ€ë¹„ ë“±")
    auto_optimize = st.toggle("ì—…ë¡œë“œ í›„ ìë™ ìµœì í™”(ë¬¸ë²• ì†Œì±…ì Drive ì €ì¥)", value=True)

    default_topics = [
        "Parts of Speech(í’ˆì‚¬)","Articles(ê´€ì‚¬)","Nouns & Pronouns(ëª…ì‚¬/ëŒ€ëª…ì‚¬)",
        "Verbs & Tenses(ì‹œì œ)","Modals(ì¡°ë™ì‚¬)","Passive(ìˆ˜ë™íƒœ)","Gerunds & Infinitives(ë™ëª…ì‚¬/ë¶€ì •ì‚¬)",
        "Adjectives & Adverbs(í˜•ìš©ì‚¬/ë¶€ì‚¬/ë¹„êµê¸‰)","Prepositions(ì „ì¹˜ì‚¬)","Phrasal Verbs(êµ¬ë™ì‚¬)",
        "Conjunctions & Clauses(ì ‘ì†ì‚¬/ì ˆ)","Conditionals(ì¡°ê±´ë¬¸)","Relative Clauses(ê´€ê³„ì‚¬ì ˆ)",
        "Reported Speech(í™”ë²•ì „í™˜)","Questions & Negation(ì˜ë¬¸ë¬¸/ë¶€ì •ë¬¸)","Sentence Structure(ë¬¸ì¥êµ¬ì¡°Â·ì–´ìˆœ)"
    ]
    topics_text = st.text_area("í† í”½ ëª©ë¡(ì¤„ë°”ê¿ˆ, ìë™ ìµœì í™”ìš©)", value="\n".join(default_topics), height=150, disabled=not auto_optimize)
    booklet_title = st.text_input("ì†Œì±…ì ì„¸íŠ¸ ì œëª©", value="Grammar Booklets", disabled=not auto_optimize)
    make_citations = st.checkbox("ì†Œì±…ìì— ì°¸ê³ ìë£Œ(ì¶œì²˜) ì„¹ì…˜ í¬í•¨", value=True, disabled=not auto_optimize)

    SUPPORTED_TYPES = ["pdf","docx","doc","pptx","ppt","md","txt","rtf","odt","html","epub","xlsx","xls","csv"]
    files = st.file_uploader("ë¡œì»¬ íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=SUPPORTED_TYPES, accept_multiple_files=True)
    gdocs_urls = st.text_area("Google Docs/Slides/Sheets URL (ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—¬ëŸ¬ ê°œ)", height=80)

    prog = st.progress(0, text="ëŒ€ê¸° ì¤‘â€¦"); status_area = st.empty(); result_area = st.empty()

    if st.button("ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸° â†’ prepared", type="primary", use_container_width=True):
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaIoBaseUpload
        from googleapiclient.errors import HttpError
        from src.rag_engine import _normalize_sa
        from src.google_oauth import is_signed_in, build_drive_service

        creds_sa = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
        drive_sa = build("drive","v3",credentials=creds_sa)
        drive_oauth = build_drive_service() if is_signed_in() else None

        created, total = [], 1
        if files: total += len(files)
        url_list = [u.strip() for u in (gdocs_urls.splitlines() if gdocs_urls else []) if u.strip()]
        if url_list: total += len(url_list)

        progress_state = {"done": 0, "total": total}
        def _tick(msg: str):
            progress_state["done"] += 1; pct = int(progress_state["done"]/max(progress_state["total"],1)*100)
            prog.progress(pct, text=msg); status_area.info(msg)

        try:
            # a) ë¡œì»¬ íŒŒì¼
            if files:
                for f in files:
                    data = f.read(); buf = io.BytesIO(data)
                    base = _safe_name(f.name)
                    ext = (base.rsplit(".",1)[-1].lower() if "." in base else "")
                    name = f"{_ts()}__{base}"
                    mime = _guess_mime_by_ext(base)
                    media = MediaIoBaseUpload(buf, mimetype=mime, resumable=False)
                    meta = {"name": name, "parents":[settings.GDRIVE_FOLDER_ID]}
                    _tick(f"ì—…ë¡œë“œ ì¤‘: {name}")
                    res = drive_sa.files().create(body=meta, media_body=media, fields="id,webViewLink").execute()
                    created.append({"id":res["id"],"name":name,"link":res.get("webViewLink",""),"ext":ext,"orig_base":base})

            # b) Google ë¬¸ì„œ ë§í¬
            def _parse_gdoc_id(s: str) -> str|None:
                for pat in [r"/d/([-\w]{15,})", r"[?&]id=([-\w]{15,})$", r"^([-\w]{15,})$"]:
                    m = re.search(pat, s.strip()); 
                    if m: return m.group(1)
                return None
            for raw in url_list:
                file_id = _parse_gdoc_id(raw)
                if not file_id: _tick("ì˜ëª»ëœ ë§í¬ ê±´ë„ˆëœ€"); continue
                drive_ro = drive_oauth or drive_sa
                try:
                    meta = drive_ro.files().get(fileId=file_id, fields="id,name,mimeType").execute()
                    name0, mtype = meta.get("name","untitled"), meta.get("mimeType","")
                except HttpError:
                    if drive_ro is drive_oauth:
                        try:
                            meta = drive_sa.files().get(fileId=file_id, fields="id,name,mimeType").execute()
                            name0, mtype = meta.get("name","untitled"), meta.get("mimeType",""); drive_ro = drive_sa
                        except Exception as e2:
                            status_area.error(f"ì ‘ê·¼ ì‹¤íŒ¨: {e2}"); continue
                    else:
                        status_area.error("ì ‘ê·¼ ì‹¤íŒ¨(ê³µìœ  í•„ìš”)"); continue
                GOOGLE_NATIVE = {
                    "application/vnd.google-apps.document": ("application/pdf",".pdf"),
                    "application/vnd.google-apps.presentation": ("application/pdf",".pdf"),
                    "application/vnd.google-apps.spreadsheet": ("application/pdf",".pdf"),
                }
                if mtype in GOOGLE_NATIVE:
                    export_mime, ext = GOOGLE_NATIVE[mtype]
                    _tick(f"ë‚´ë³´ë‚´ëŠ” ì¤‘: {name0}{ext}")
                    data = drive_ro.files().export(fileId=file_id, mimeType=export_mime).execute()
                    buf = io.BytesIO(data)
                    name = f"{_ts()}__{_safe_name(name0)}{ext}"
                    media = MediaIoBaseUpload(buf, mimetype=export_mime, resumable=False)
                    meta2 = {"name": name, "parents":[settings.GDRIVE_FOLDER_ID]}
                    res2 = drive_sa.files().create(body=meta2, media_body=media, fields="id,webViewLink").execute()
                    created.append({"id":res2["id"],"name":name,"link":res2.get("webViewLink",""),
                                    "ext":ext.strip("."),"orig_base":name0})
                else:
                    _tick(f"ë³µì‚¬ ì¤‘: {name0}")
                    body = {"name": f"{_ts()}__{_safe_name(name0)}", "parents":[settings.GDRIVE_FOLDER_ID]}
                    try:
                        res3 = drive_sa.files().copy(fileId=file_id, body=body, fields="id,webViewLink").execute()
                    except HttpError:
                        if drive_oauth:
                            res3 = drive_oauth.files().copy(fileId=file_id, body=body, fields="id,webViewLink").execute()
                        else:
                            status_area.error("ë³µì‚¬ ì‹¤íŒ¨(ê¶Œí•œ ë¶€ì¡±)"); continue
                    created.append({"id":res3["id"],"name":body["name"],"link":res3.get("webViewLink",""),
                                    "ext":"", "orig_base": name0})

            # c) (ì„ íƒ) AI ì œëª© ë³€ê²½
            renamed_rows = []
            if auto_title and created:
                used=set()
                for item in created:
                    fid, old = item["id"], item["name"]
                    ext = f".{item['ext']}" if item.get("ext") else ""
                    ai_title = _ai_title(item.get("orig_base", old), hint=title_hint)
                    new_name = _safe_name(f"{_ts()}__{ai_title}{ext}")
                    k=new_name; n=2
                    while k in used: k=f"{new_name} ({n})"; n+=1
                    try:
                        drive_sa.files().update(fileId=fid, body={"name":k}).execute()
                        renamed_rows.append({"original":old,"renamed_to":k,"open":item["link"]}); used.add(k)
                    except Exception as e:
                        renamed_rows.append({"original":old,"renamed_to":f"(ì‹¤íŒ¨) {e}","open":item["link"]})
            else:
                for item in created:
                    renamed_rows.append({"original":item["name"],"renamed_to":"(AI ì œëª© êº¼ì§)","open":item["link"]})

            # d) ê²°ê³¼í‘œ
            prog.progress(100, text="ì™„ë£Œ"); status_area.success(f"ì´ {len(created)}ê°œ í•­ëª© ì²˜ë¦¬ ì™„ë£Œ (prepared)")
            if renamed_rows:
                df = pd.DataFrame(renamed_rows)
                result_area.dataframe(
                    df, use_container_width=True, hide_index=True,
                    column_config={"original": st.column_config.TextColumn("ì›ë˜ íŒŒì¼ëª…"),
                                   "renamed_to": st.column_config.TextColumn("ë³€ê²½ í›„ íŒŒì¼ëª…"),
                                   "open": st.column_config.LinkColumn("ì—´ê¸°", display_text="ì—´ê¸°")}
                )
            st.toast("ì—…ë¡œë“œ/ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ", icon="âœ…")

            # e) ìë™ ìµœì í™” ì˜ˆì•½ + ì¸ë±ì‹± ìë™ ì‹œì‘
            if auto_optimize:
                ss["_auto_booklets_pending"] = True
                ss["_auto_topics_text"] = topics_text
                ss["_auto_booklet_title"] = booklet_title
                ss["_auto_make_citations"] = make_citations
            ss.prep_both_done = False; ss.prep_both_running = True; ss.index_job = None
            st.info("ì¸ë±ì‹±/ìµœì í™” íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤."); st.rerun()

        except Exception as e:
            prog.progress(0, text="ì˜¤ë¥˜"); status_area.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

# ================= 11) prepared ê°ì‹œ UI ================
with st.expander("ğŸ“¡ prepared í´ë” ê°ì‹œ(Drive ì§ì ‘ íˆ¬ì… â†’ ìµœì í™”/ìŠ¤í‚µ)", expanded=False):
    st.caption("prepared/ ì— íŒŒì¼ì„ ì§ì ‘ ë„£ì–´ë„ ìë™ ê°ì§€í•©ë‹ˆë‹¤. (ê´€ë¦¬ìëŠ” ì²« ë°©ë¬¸ ì‹œ ì™„ì „ ìŠ¤ìº”)")
    ss["_watch_on_load"] = st.toggle("í˜ì´ì§€ ì—´ë¦´ ë•Œ ìë™ ìŠ¤ìº”", value=ss["_watch_on_load"])
    ss["_watch_rename_title"] = st.toggle("ê°ì‹œ ì‹œì—ë„ AI ì œëª© ìë™ ì •ë¦¬(ì„ íƒ)", value=ss["_watch_rename_title"])

    topics_watch = st.text_area("í† í”½ ëª©ë¡(ê°ì‹œìš©, ì¤„ë°”ê¿ˆ)", value=ss.get("_auto_topics_text") or
                                "Verbs & Tenses(ì‹œì œ)\nPassive(ìˆ˜ë™íƒœ)\nConditionals(ì¡°ê±´ë¬¸)", height=100)
    title_watch = st.text_input("ì†Œì±…ì ì„¸íŠ¸ ì œëª©(ê°ì‹œìš©)", value=ss.get("_auto_booklet_title","Grammar Booklets"))
    cite_watch = st.checkbox("ì°¸ê³ ìë£Œ ì„¹ì…˜ í¬í•¨", value=ss.get("_auto_make_citations", True))

    if st.button("ğŸ“¡ ì§€ê¸ˆ ìŠ¤ìº” & ìµœì í™”", use_container_width=True):
        if IS_ADMIN:
            admin_full_scan_and_schedule(topics_watch, title_watch, cite_watch, ss["_watch_rename_title"])
        else:
            watch_scan_and_schedule(topics_watch, title_watch, cite_watch, ss["_watch_rename_title"])

# ================= 12) ì¸ë±ì‹± ë³´ê³ ì„œ ===================
rep = ss.get("indexing_report")
if rep:
    with st.expander("ğŸ§¾ ì¸ë±ì‹± ë³´ê³ ì„œ (ìŠ¤í‚µëœ íŒŒì¼ ë³´ê¸°)", expanded=False):
        st.write(f"ì´ íŒŒì¼(ë§¤ë‹ˆí˜ìŠ¤íŠ¸): {rep.get('total_manifest')}, "
                 f"ë¡œë”©ëœ ë¬¸ì„œ ìˆ˜: {rep.get('loaded_docs')}, "
                 f"ìŠ¤í‚µ: {rep.get('skipped_count')}")
        skipped = rep.get("skipped", [])
        if skipped: st.dataframe(pd.DataFrame(skipped), use_container_width=True, hide_index=True)
        else: st.caption("ìŠ¤í‚µëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ ğŸ‰")

# ================= 13) ë‘ë‡Œ ì¤€ë¹„(ì¸ë±ì‹±) ===============
st.markdown("---"); st.subheader("ğŸ§  ë‘ë‡Œ ì¤€ë¹„ â€” ì €ì¥ë³¸ ë¡œë“œ â†” ë³€ê²½ ì‹œ ì¦ë¶„ ì¸ë±ì‹± (ì¤‘ê°„ ì·¨ì†Œ/ì¬ê°œ)")

c_g, c_o = st.columns(2)
with c_g: st.caption("Gemini ì§„í–‰"); g_bar = st.empty(); g_msg = st.empty()
with c_o: st.caption("ChatGPT ì§„í–‰"); o_bar = st.empty(); o_msg = st.empty()

def _render_progress(slot_bar, slot_msg, pct: int, msg: str | None = None):
    p = max(0, min(100, int(pct)))
    slot_bar.markdown(
        f"<div class='gp-wrap'><div class='gp-fill' style='width:{p}%'></div><div class='gp-label'>{p}%</div></div>",
        unsafe_allow_html=True)
    if msg is not None: slot_msg.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)

def _is_cancelled() -> bool: return bool(ss.get("prep_cancel_requested", False))

from src.rag_engine import (
    set_embed_provider, make_llm, get_text_answer, CancelledError,
    start_index_builder, resume_index_builder, cancel_index_builder, llm_complete
)

def run_prepare_both_step():
    # 1) ì„ë² ë”© ì„¤ì •
    embed_provider = "openai"
    embed_api = (getattr(settings, "OPENAI_API_KEY", None).get_secret_value()
                 if getattr(settings, "OPENAI_API_KEY", None) else "")
    embed_model = getattr(settings, "OPENAI_EMBED_MODEL", "text-embedding-3-small")
    if not embed_api:
        embed_provider = "google"; embed_api = settings.GEMINI_API_KEY.get_secret_value()
        embed_model = getattr(settings, "EMBED_MODEL", "text-embedding-004")
    try:
        _render_progress(g_bar, g_msg, 3, f"ì„ë² ë”© ì„¤ì •({embed_provider})")
        _render_progress(o_bar, o_msg, 3, f"ì„ë² ë”© ì„¤ì •({embed_provider})")
        set_embed_provider(embed_provider, embed_api, embed_model)
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"ì„ë² ë”© ì‹¤íŒ¨: {e}")
        _render_progress(o_bar, o_msg, 100, f"ì„ë² ë”© ì‹¤íŒ¨: {e}")
        ss.prep_both_running = False; return

    # 2) ì¸ë±ìŠ¤ ìŠ¤í…
    def upd(p, m=None): _render_progress(g_bar, g_msg, p, m); _render_progress(o_bar, o_msg, p, m)
    def umsg(m): _render_progress(g_bar, g_msg, ss.get("p_shared", 0), m); _render_progress(o_bar, o_msg, ss.get("p_shared", 0), m)
    persist_dir = f"{getattr(settings,'PERSIST_DIR','/tmp/my_ai_teacher/storage_gdrive')}_shared"
    job = ss.get("index_job")
    try:
        if job is None:
            res = start_index_builder(update_pct=upd, update_msg=umsg,
                                      gdrive_folder_id=settings.GDRIVE_FOLDER_ID,
                                      raw_sa=settings.GDRIVE_SERVICE_ACCOUNT_JSON,
                                      persist_dir=persist_dir,
                                      manifest_path=getattr(settings, "MANIFEST_PATH", "/tmp/my_ai_teacher/drive_manifest.json"),
                                      max_docs=None, is_cancelled=_is_cancelled)
        else:
            res = resume_index_builder(job=job, update_pct=upd, update_msg=umsg, is_cancelled=_is_cancelled, batch_size=6)
        status = res.get("status")
        if status == "running":
            ss.index_job = res["job"]
            _render_progress(g_bar, g_msg, res.get("pct", 8), res.get("msg","ì§„í–‰ ì¤‘â€¦"))
            _render_progress(o_bar, o_msg, res.get("pct", 8), res.get("msg","ì§„í–‰ ì¤‘â€¦"))
            time.sleep(0.15); st.rerun(); return
        if status == "cancelled":
            ss.prep_both_running = False; ss.prep_cancel_requested = False; ss.index_job = None
            _render_progress(g_bar, g_msg, res.get("pct", 0), "ì‚¬ìš©ì ì·¨ì†Œ")
            _render_progress(o_bar, o_msg, res.get("pct", 0), "ì‚¬ìš©ì ì·¨ì†Œ"); return
        if status != "done":
            _render_progress(g_bar, g_msg, 100, "ì¸ë±ì‹± ì‹¤íŒ¨")
            _render_progress(o_bar, o_msg, 100, "ì¸ë±ì‹± ì‹¤íŒ¨")
            ss.prep_both_running = False; return
        index = res["index"]; ss.index_job = None
    except Exception as e:
        ss.prep_both_running = False; ss.index_job = None
        _render_progress(g_bar, g_msg, 100, f"ì—ëŸ¬: {e}")
        _render_progress(o_bar, o_msg, 100, f"ì—ëŸ¬: {e}"); return

    # 3) QE ìƒì„±
    try:
        g_llm = make_llm("google", settings.GEMINI_API_KEY.get_secret_value(),
                         getattr(settings, "LLM_MODEL", "gemini-1.5-pro"),
                         float(ss.get("temperature", 0.0)))
        ss["llm_google"] = g_llm
        ss["qe_google"] = index.as_query_engine(
            llm=g_llm,
            response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
            similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
        )
        _render_progress(g_bar, g_msg, 100, "ì™„ë£Œ!")
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"Gemini ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        if getattr(settings, "OPENAI_API_KEY", None) and settings.OPENAI_API_KEY.get_secret_value():
            o_llm = make_llm("openai", settings.OPENAI_API_KEY.get_secret_value(),
                             getattr(settings, "OPENAI_LLM_MODEL", "gpt-4o-mini"),
                             float(ss.get("temperature", 0.0)))
            ss["llm_openai"] = o_llm
            ss["qe_openai"] = index.as_query_engine(
                llm=o_llm,
                response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
                similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
            )
            _render_progress(o_bar, o_msg, 100, "ì™„ë£Œ!")
        else:
            _render_progress(o_bar, o_msg, 100, "í‚¤ ëˆ„ë½ â€” OPENAI_API_KEY í•„ìš”")
    except Exception as e:
        _render_progress(o_bar, o_msg, 100, f"ChatGPT ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # 4) ìë™ ì†Œì±…ì(ì˜ˆì•½ ì‹œ)
    if ss.get("_auto_booklets_pending"):
        try:
            topics = [t.strip() for t in ss.get("_auto_topics_text","").splitlines() if t.strip()]
            topics = topics or ["Verbs & Tenses(ì‹œì œ)","Passive(ìˆ˜ë™íƒœ)","Conditionals(ì¡°ê±´ë¬¸)"]
            title = ss.get("_auto_booklet_title","Grammar Booklets")
            citations = bool(ss.get("_auto_make_citations", True))
            with st.spinner("ìë™ ìµœì í™”(ë¬¸ë²• ì†Œì±…ì) ìƒì„± ì¤‘â€¦"):
                res_auto = generate_booklets_drive(topics, title, citations)
            st.success(f"ìë™ ìµœì í™” ì™„ë£Œ â†’ prepared_volumes/{res_auto['folder_name']}")
            if res_auto.get("rows"):
                st.dataframe(pd.DataFrame(res_auto["rows"]),
                             use_container_width=True, hide_index=True,
                             column_config={"topic": st.column_config.TextColumn("í† í”½"),
                                            "open": st.column_config.LinkColumn("ì—´ê¸°", display_text="ì—´ê¸°")})
        except Exception as e:
            st.warning(f"ìë™ ìµœì í™” ì‹¤íŒ¨: {e}")
        finally:
            ss["_auto_booklets_pending"] = False

    ss.prep_both_running = False; ss.prep_both_done = True
    time.sleep(0.2); st.rerun()

# ì‹¤í–‰/ì·¨ì†Œ ë²„íŠ¼
left, right = st.columns([0.7, 0.3])
with left:
    clicked = st.button("ğŸš€ í•œ ë²ˆì— ì¤€ë¹„í•˜ê¸°", key="prepare_both", use_container_width=True,
                        disabled=ss.prep_both_running or ss.prep_both_done)
with right:
    cancel_clicked = st.button("â›” ì¤€ë¹„ ì·¨ì†Œ", key="cancel_prepare", use_container_width=True, type="secondary",
                               disabled=not ss.prep_both_running)
from src.rag_engine import cancel_index_builder
if cancel_clicked and ss.prep_both_running:
    ss.prep_cancel_requested = True
    if ss.get("index_job"): cancel_index_builder(ss.index_job)
    st.rerun()
if clicked and not (ss.prep_both_running or ss.prep_both_done):
    ss.prep_cancel_requested = False; ss.prep_both_running = True; ss.index_job = None; st.rerun()

# ìë™ ìŠ¤ìº”: í˜ì´ì§€ ìµœì´ˆ 1íšŒ
if ss["_watch_on_load"] and not ss["_watch_ran_once"] and not ss.prep_both_running:
    ss["_watch_ran_once"] = True
    topics0 = ss.get("_auto_topics_text") or "Verbs & Tenses(ì‹œì œ)\nPassive(ìˆ˜ë™íƒœ)\nConditionals(ì¡°ê±´ë¬¸)"
    title0  = ss.get("_auto_booklet_title","Grammar Booklets")
    cite0   = bool(ss.get("_auto_make_citations", True))
    try:
        if IS_ADMIN and not ss.get("_admin_initial_fullscan_done", False):
            ss["_admin_initial_fullscan_done"] = True
            admin_full_scan_and_schedule(topics0, title0, cite0, ss["_watch_rename_title"])
        else:
            watch_scan_and_schedule(topics0, title0, cite0, ss["_watch_rename_title"])
    except Exception as e:
        st.warning(f"ì´ˆê¸° ìë™ ìŠ¤ìº” ì‹¤íŒ¨: {e}")

if ss.prep_both_running:
    run_prepare_both_step()

st.caption("ì¤€ë¹„ ë²„íŠ¼ì„ ë‹¤ì‹œ í™œì„±í™”í•˜ë ¤ë©´ ì•„ë˜ ì¬ì„¤ì • ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
if st.button("ğŸ”§ ì¬ì„¤ì •(ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”)", disabled=not ss.prep_both_done):
    ss.prep_both_done = False; ss["_watch_ran_once"] = False; ss["_admin_initial_fullscan_done"] = False; st.rerun()

# ================= 14) ê·¸ë£¹í† ë¡  UI =====================
st.markdown("---")
st.subheader("ğŸ’¬ ê·¸ë£¹í† ë¡  â€” í•™ìƒ â†” ğŸ¤–Gemini(ì¹œì ˆ/ê¼¼ê¼¼) â†” ğŸ¤–ChatGPT(ìœ ë¨¸ëŸ¬ìŠ¤/ë³´ì™„)")

ready_google = "qe_google" in ss
ready_openai = "qe_openai" in ss
if ss.session_terminated: st.warning("ì„¸ì…˜ì´ ì¢…ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”."); st.stop()
if not ready_google: st.info("ë¨¼ì € **[ğŸš€ í•œ ë²ˆì— ì¤€ë¹„í•˜ê¸°]**ë¡œ ë‘ë‡Œë¥¼ ì¤€ë¹„í•˜ì„¸ìš”. (OpenAI í‚¤ ì—†ìœ¼ë©´ Geminië§Œ ì‘ë‹µ)"); st.stop()

# ê³¼ê±° ë©”ì‹œì§€ ë Œë”
for m in ss.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

def _strip_sources(text: str) -> str: return re.sub(r"\n+---\n\*ì°¸ê³  ìë£Œ:.*$", "", text, flags=re.DOTALL)
def _build_context(messages, limit_pairs=2, max_chars=2000) -> str:
    pairs, buf_user = [], None
    for m in reversed(messages):
        role, content = m.get("role"), str(m.get("content","")).strip()
        if role == "assistant":
            content = re.sub(r"^\*\*ğŸ¤– .*?\*\*\s*\n+", "", content).strip()
            if buf_user is not None:
                pairs.append((buf_user, content)); buf_user = None
                if len(pairs) >= limit_pairs: break
        elif role == "user" and buf_user is None:
            buf_user = content
    pairs = list(reversed(pairs))
    blocks = [f"[í•™ìƒ]\n{u}\n\n[êµì‚¬]\n{a}" for u,a in pairs]
    ctx = "\n\n---\n\n".join(blocks).strip()
    return ctx[-max_chars:] if len(ctx) > max_chars else ctx

from src.prompts import EXPLAINER_PROMPT, ANALYST_PROMPT, READER_PROMPT
def _persona():
    mode = ss.get("mode_select", "ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…")
    base = EXPLAINER_PROMPT if mode=="ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…" else (ANALYST_PROMPT if mode=="ğŸ” êµ¬ë¬¸ ë¶„ì„" else READER_PROMPT)
    common = "ì—­í• : í•™ìƒì˜ ì˜ì–´ ì‹¤ë ¥ì„ ë•ëŠ” AI êµì‚¬.\nê·œì¹™: ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ë°íŒë‹¤. ì˜ˆì‹œëŠ” ì§§ê³  ì ì§„ì ìœ¼ë¡œ."
    return base + "\n" + common

GEMINI_STYLE = "ë‹¹ì‹ ì€ ì°©í•˜ê³  ë˜‘ë˜‘í•œ ì¹œêµ¬ ê°™ì€ êµì‚¬ì…ë‹ˆë‹¤. ì¹­ì°¬ê³¼ ê²©ë ¤, ì •í™•í•œ ì„¤ëª…."
CHATGPT_STYLE = ("ë‹¹ì‹ ì€ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ì§€ë§Œ ì •í™•í•œ ë™ë£Œ êµì‚¬ì…ë‹ˆë‹¤. ë™ë£Œ(Gemini)ì˜ ë‹µì„ ì½ê³  "
                 "ë¹ ì§„ ë¶€ë¶„ì„ ë³´ì™„/êµì •í•˜ê³  ë§ˆì§€ë§‰ì— <ìµœì¢… ì •ë¦¬>ë¡œ ìš”ì•½í•˜ì„¸ìš”. ê³¼í•œ ë†ë‹´ ê¸ˆì§€.")
mode = st.radio("í•™ìŠµ ëª¨ë“œ", ["ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…", "ğŸ” êµ¬ë¬¸ ë¶„ì„", "ğŸ“š ë…í•´ ë° ìš”ì•½"], horizontal=True, key="mode_select")

from src import chat_store
from src.drive_log import get_chatlog_folder_id, save_chatlog_markdown_oauth
def _jsonl_log(items):
    if not ss.save_logs: return
    try:
        parent_id = (getattr(settings, "CHATLOG_FOLDER_ID", None) or settings.GDRIVE_FOLDER_ID)
        sa = settings.GDRIVE_SERVICE_ACCOUNT_JSON
        if isinstance(sa, str):
            try: sa = json.loads(sa)
            except Exception: pass
        sub_id = get_chatlog_folder_id(parent_folder_id=parent_id, sa_json=sa)
        chat_store.append_jsonl(folder_id=sub_id, sa_json=sa, items=items)
        st.toast("ëŒ€í™” JSONL ì €ì¥ ì™„ë£Œ", icon="ğŸ’¾")
    except Exception as e:
        st.warning(f"ëŒ€í™” JSONL ì €ì¥ ì‹¤íŒ¨: {e}")

user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ë¶„ì„/ìš”ì•½í•  ë¬¸ì¥ì´ë‚˜ ê¸€ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
if user_input:
    ss.messages.append({"role":"user","content":user_input})
    with st.chat_message("user"): st.markdown(user_input)
    _jsonl_log([chat_store.make_entry(ss.session_id, "user", "user", user_input, mode, model="user")])

    from src.rag_engine import get_text_answer, llm_complete
    with st.spinner("ğŸ¤– Gemini ì„ ìƒë‹˜ì´ ë¨¼ì € ë‹µí•©ë‹ˆë‹¤â€¦"):
        prev_ctx = _build_context(ss.messages[:-1], limit_pairs=2, max_chars=2000)
        gemini_query = (f"[ì´ì „ ëŒ€í™”]\n{prev_ctx}\n\n" if prev_ctx else "") + f"[í•™ìƒ ì§ˆë¬¸]\n{user_input}"
        ans_g = get_text_answer(ss["qe_google"], gemini_query, _persona() + "\n" + GEMINI_STYLE)

    content_g = f"**ğŸ¤– Gemini**\n\n{ans_g}"
    ss.messages.append({"role":"assistant","content":content_g})
    with st.chat_message("assistant"): st.markdown(content_g)
    _jsonl_log([chat_store.make_entry(ss.session_id, "assistant", "Gemini", content_g, mode, model=getattr(settings,"LLM_MODEL","gemini"))])

    if "qe_openai" in ss:
        review_directive = ("ì—­í• : ë™ë£Œ AI ì˜ì–´êµì‚¬\n"
            "ëª©í‘œ: [ì´ì „ ëŒ€í™”], [í•™ìƒ ì§ˆë¬¸], [ë™ë£Œì˜ 1ì°¨ ë‹µë³€]ì„ ì½ê³  ì‚¬ì‹¤ì˜¤ë¥˜/ë¹ ì§„ì /ëª¨í˜¸í•¨ì„ ë³´ì™„.\n"
            "ì§€ì¹¨: 1)í•µì‹¬ ê°„ê²° ì¬ì •ë¦¬ 2)í‹€ë¦° ë¶€ë¶„ ê·¼ê±°ì™€ êµì • 3)ì˜ˆë¬¸ 2~3ê°œ 4)<ìµœì¢… ì •ë¦¬>ë¡œ ìš”ì•½. ì™¸ë¶€ê²€ìƒ‰ ê¸ˆì§€.")
        prev_all = _build_context(ss.messages, limit_pairs=2, max_chars=2000)
        augmented = ((f"[ì´ì „ ëŒ€í™”]\n{prev_all}\n\n" if prev_all else "") +
                     f"[í•™ìƒ ì§ˆë¬¸]\n{user_input}\n\n"
                     f"[ë™ë£Œì˜ 1ì°¨ ë‹µë³€(Gemini)]\n{_strip_sources(ans_g)}\n\n"
                     "[ë‹¹ì‹ ì˜ ì‘ì—…]\nìœ„ ê¸°ì¤€ìœ¼ë¡œë§Œ ë³´ì™„/ê²€ì¦.")
        with st.spinner("ğŸ¤ ChatGPT ì„ ìƒë‹˜ì´ ë³´ì™„/ê²€ì¦ ì¤‘â€¦"):
            ans_o = llm_complete(ss.get("llm_openai"),
                                 _persona() + "\n" + CHATGPT_STYLE + "\n\n" + review_directive + "\n\n" + augmented)
        content_o = f"**ğŸ¤– ChatGPT**\n\n{ans_o}"
        ss.messages.append({"role":"assistant","content":content_o})
        with st.chat_message("assistant"): st.markdown(content_o)
    else:
        with st.chat_message("assistant"):
            st.info("ChatGPT í‚¤ê°€ ì—†ì–´ Geminië§Œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤. OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ë©´ ë³´ì™„/ê²€ì¦ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

    if ss.auto_save_chatlog and ss.messages:
        try:
            if is_signed_in():
                svc = build_drive_service()
                parent_id = (st.secrets.get("OAUTH_CHAT_PARENT_ID") or "").strip() or None
                _fid = save_chatlog_markdown_oauth(ss.session_id, ss.messages, svc, parent_id)
                st.toast("ë‚´ ë“œë¼ì´ë¸Œì— ëŒ€í™” ì €ì¥ ì™„ë£Œ âœ…", icon="ğŸ’¾")
            else:
                st.info("êµ¬ê¸€ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ë©´ ëŒ€í™”ê°€ **ë‚´ ë“œë¼ì´ë¸Œ**ì— ì €ì¥ë©ë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"OAuth ì €ì¥ ì‹¤íŒ¨: {e}")

# EOF
