# app.py â€” ë‘ ì—”ì§„(ğŸ§ Gemini / ğŸ§ ChatGPT) ì¤€ë¹„ + ì„ íƒ ë‹µë³€ UI

import streamlit as st
import pandas as pd
import time

# ===== í˜ì´ì§€ ì„¤ì • ============================================================
st.set_page_config(page_title="ë‚˜ì˜ AI ì˜ì–´ êµì‚¬", layout="wide", initial_sidebar_state="collapsed")

# ===== ê¸°ë³¸ UI/ìŠ¤íƒ€ì¼ =========================================================
from src.ui import load_css, render_header
load_css()
render_header()

st.info("âœ… ë² ì´ìŠ¤ë¼ì¸ í™•ì¸ìš© í™”ë©´ì…ë‹ˆë‹¤. ì´ì œë¶€í„° Gemini/ChatGPT ë‘ ì—”ì§„ì„ ê°ê° ì¤€ë¹„í•˜ê³ , ë‹µë³€ ì‹œ ì„ íƒí•  ìˆ˜ ìˆì–´ìš”.")

# ===== Google Drive ì—°ê²° í…ŒìŠ¤íŠ¸ ===============================================
# ì„í¬íŠ¸ ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì˜¤ë¥˜ ë³´ì—¬ì£¼ê¸°
try:
    from src.rag_engine import smoke_test_drive, preview_drive_files
except Exception:
    st.error("`src.rag_engine` ì„í¬íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    import traceback, os
    st.write("íŒŒì¼ ì¡´ì¬ ì—¬ë¶€:", os.path.exists("src/rag_engine.py"))
    with st.expander("ì„í¬íŠ¸ ìŠ¤íƒ(ì›ì¸)", expanded=True):
        st.code(traceback.format_exc())
    st.stop()

st.markdown("## ğŸ”— Google Drive ì—°ê²° í…ŒìŠ¤íŠ¸")
st.caption("ë²„íŠ¼ì„ ëˆŒëŸ¬ Drive í´ë” ì—°ê²°ì´ ì •ìƒì¸ì§€ í™•ì¸í•˜ì„¸ìš”. (ì„œë¹„ìŠ¤ê³„ì •ì— Viewer ì´ìƒ ê³µìœ  í•„ìš”)")

col1, col2 = st.columns([0.65, 0.35])
with col1:
    if st.button("í´ë” íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ìµœì‹  10ê°œ)", use_container_width=True):
        ok, msg, rows = preview_drive_files(max_items=10)
        if ok and rows:
            df = pd.DataFrame(rows)
            df["type"] = df["mime"].str.replace("application/vnd.google-apps.", "", regex=False)
            df = df.rename(columns={"modified": "modified_at"})
            df = df[["name", "link", "type", "modified_at"]]
            st.dataframe(
                df,
                use_container_width=True,
                height=360,
                column_config={
                    "name": st.column_config.TextColumn("íŒŒì¼ëª…"),
                    "link": st.column_config.LinkColumn("open", display_text="ì—´ê¸°"),
                    "type": st.column_config.TextColumn("ìœ í˜•"),
                    "modified_at": st.column_config.TextColumn("ìˆ˜ì •ì‹œê°"),
                },
                hide_index=True,
            )
        elif ok:
            st.warning("í´ë”ì— íŒŒì¼ì´ ì—†ê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error(msg)
with col2:
    ok, msg = smoke_test_drive()
    st.success(msg) if ok else st.warning(msg)

# ===== ë‘ë‡Œ ì¤€ë¹„ (ì‹œë®¬ë ˆì´ì…˜) ==================================================
st.markdown("----")
st.subheader("ğŸ§  ë‘ë‡Œ ì¤€ë¹„ (ì‹œë®¬ë ˆì´ì…˜)")
if st.button("ë‘ë‡Œ ì¤€ë¹„ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
    bar_slot = st.empty(); msg_slot = st.empty()
    def render_progress(pct: int, msg: str | None = None):
        p = max(0, min(100, int(pct)))
        bar_slot.markdown(f"""
<div class="gp-wrap"><div class="gp-fill" style="width:{p}%"></div><div class="gp-label">{p}%</div></div>
""", unsafe_allow_html=True)
        if msg: msg_slot.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)
    render_progress(5, "ì‹œì‘â€¦"); time.sleep(0.2)
    render_progress(25, "ë¹„ë°€í‚¤ ì ê²€â€¦")
    missing = [k for k in ("GEMINI_API_KEY", "GDRIVE_FOLDER_ID") if not str(st.secrets.get(k, "")).strip()]
    if missing: render_progress(100, "ì‹¤íŒ¨"); st.error("í•„ìˆ˜ Secrets ì—†ìŒ: " + ", ".join(missing)); st.stop()
    render_progress(60, "í™˜ê²½ ì¤€ë¹„â€¦"); time.sleep(0.2)
    render_progress(90, "ë§ˆë¬´ë¦¬â€¦"); time.sleep(0.2)
    render_progress(100, "ì™„ë£Œ!"); time.sleep(0.2)
    bar_slot.empty(); msg_slot.empty()
    st.success("ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ â€” UI/ì§„í–‰ íë¦„ ì •ìƒì…ë‹ˆë‹¤.")

# ===== ë‘ë‡Œ ì¤€ë¹„ (ì‹¤ì „) â€” Gemini / ChatGPT ê°ê° ì¤€ë¹„ ============================
st.markdown("----")
st.subheader("ğŸ§  ë‘ë‡Œ ì¤€ë¹„ (ì‹¤ì „) â€” Gemini & ChatGPT")

from src.config import settings
try:
    from src.rag_engine import init_llama_settings, get_or_build_index, get_text_answer
except Exception:
    st.error("`src.rag_engine` ì„í¬íŠ¸(LLM/RAG) ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    import traceback
    with st.expander("ì„í¬íŠ¸ ìŠ¤íƒ(ì›ì¸)", expanded=True):
        st.code(traceback.format_exc())
    st.stop()

def _render_progress(slot_bar, slot_msg, pct: int, msg: str | None = None):
    p = max(0, min(100, int(pct)))
    slot_bar.markdown(f"""
<div class="gp-wrap"><div class="gp-fill" style="width:{p}%"></div><div class="gp-label">{p}%</div></div>
""", unsafe_allow_html=True)
    if msg is not None:
        slot_msg.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)

# ê³µê¸‰ìë³„ ê¸°ë³¸ ëª¨ë¸ (secrets ì—†ì„ ë•Œ ì•ˆì „ ê¸°ë³¸ê°’)
DEFAULTS = {
    "google": {"llm": "gemini-1.5-pro", "embed": "text-embedding-004"},
    "openai": {"llm": "gpt-4o-mini",     "embed": "text-embedding-3-small"},
}

def build_brain(provider: str):
    provider = provider.lower()
    bar = st.empty(); msg = st.empty()
    _render_progress(bar, msg, 0, f"{provider.title()} ë‘ë‡Œ ì¤€ë¹„ ì‹œì‘â€¦")

    # ëª¨ë¸ ì„ íƒ (secretsì— LLM_MODEL/EMBED_MODELê°€ ìˆìœ¼ë©´ ì°¸ê³ í•˜ë˜, ê³µê¸‰ìì— ë§ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    if provider == "google":
        api_key = settings.GEMINI_API_KEY.get_secret_value()
        llm_model = DEFAULTS["google"]["llm"] if "gemini" not in getattr(settings, "LLM_MODEL", "") else settings.LLM_MODEL
        embed_model = DEFAULTS["google"]["embed"] if "embedding" not in getattr(settings, "EMBED_MODEL", "") else settings.EMBED_MODEL
        persist_dir = f"{getattr(settings, 'PERSIST_DIR', '/tmp/my_ai_teacher/storage_gdrive')}_google"
    else:
        api_key = getattr(settings, "OPENAI_API_KEY", None).get_secret_value() if hasattr(settings, "OPENAI_API_KEY") else ""
        llm_model = getattr(settings, "OPENAI_LLM_MODEL", DEFAULTS["openai"]["llm"])
        embed_model = getattr(settings, "OPENAI_EMBED_MODEL", DEFAULTS["openai"]["embed"])
        persist_dir = f"{getattr(settings, 'PERSIST_DIR', '/tmp/my_ai_teacher/storage_gdrive')}_openai"

    if not api_key:
        _render_progress(bar, msg, 100, "í‚¤ ëˆ„ë½")
        st.error(f"{provider.title()} API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    # LLM/ì„ë² ë”© ì´ˆê¸°í™” (ì„ë² ë”©ì€ Settingsì— ì„¤ì •, LLM ê°ì²´ëŠ” ë°˜í™˜)
    try:
        llm = init_llama_settings(
            provider=provider,
            api_key=api_key,
            llm_model=llm_model,
            embed_model=embed_model,
            temperature=float(st.session_state.get("temperature", 0.0)),
        )
    except Exception as e:
        _render_progress(bar, msg, 100, "LLM/ì„ë² ë”© ì„¤ì • ì˜¤ë¥˜")
        st.error(f"LLM/ì„ë² ë”© ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        st.stop()

    # ì¸ë±ìŠ¤ ë¡œë”©/ë¹Œë“œ
    try:
        progress = {"pct": 0}
        def update_pct(pct: int, m: str | None = None):
            progress["pct"] = int(pct); _render_progress(bar, msg, progress["pct"], m)
        def update_msg(m: str):
            _render_progress(bar, msg, progress["pct"], m)

        index = get_or_build_index(
            update_pct=update_pct,
            update_msg=update_msg,
            gdrive_folder_id=settings.GDRIVE_FOLDER_ID,
            raw_sa=settings.GDRIVE_SERVICE_ACCOUNT_JSON,
            persist_dir=persist_dir,
            manifest_path=getattr(settings, "MANIFEST_PATH", "/tmp/my_ai_teacher/drive_manifest.json"),
        )
    except Exception as e:
        _render_progress(bar, msg, 100, "ì¸ë±ìŠ¤ ì¤€ë¹„ ì‹¤íŒ¨")
        st.error("ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í´ë” ê¶Œí•œ/ë„¤íŠ¸ì›Œí¬/requirementsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        with st.expander("ì˜¤ë¥˜ ìƒì„¸ ë³´ê¸°"):
            st.exception(e)
        st.stop()

    # ê³µê¸‰ìë³„ QueryEngine ìƒì„±(í•´ë‹¹ LLMì„ ëª…ì‹œ ì£¼ì…)
    qe = index.as_query_engine(
        llm=llm,
        response_mode=st.session_state.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
        similarity_top_k=int(st.session_state.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
    )

    # ì„¸ì…˜ì— ì €ì¥
    key = "qe_google" if provider == "google" else "qe_openai"
    st.session_state[key] = qe

    _render_progress(bar, msg, 100, "ì™„ë£Œ!")
    time.sleep(0.2); bar.empty(); msg.empty()
    st.success(f"{provider.title()} ë‘ë‡Œ ì¤€ë¹„ ì™„ë£Œ!")

# ë²„íŠ¼ 2ê°œ (ì¢Œ: Gemini / ìš°: ChatGPT)
c1, c2 = st.columns(2)
with c1:
    if st.button("ğŸ§  Gemini ë‘ë‡Œ ì¤€ë¹„", use_container_width=True):
        build_brain("google")
with c2:
    if st.button("ğŸ§  ChatGPT ë‘ë‡Œ ì¤€ë¹„", use_container_width=True):
        build_brain("openai")

# ===== ëŒ€í™” UI â€” ë‹µë³€í•  AI ì„ íƒ í›„ ì§ˆë¬¸ ========================================
st.markdown("---")
st.subheader("ğŸ’¬ ëŒ€í™”")

# ì¤€ë¹„ ìƒíƒœ ì•ˆë‚´
ready_google = "qe_google" in st.session_state
ready_openai = "qe_openai" in st.session_state
if not (ready_google or ready_openai):
    st.info("ë¨¼ì € ìœ„ì—ì„œ **Gemini** ë˜ëŠ” **ChatGPT** ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")
    st.stop()

# ëŒ€í™” ê¸°ë¡
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ë©”ì‹œì§€ ë Œë”
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ì–´ë–¤ AIë¡œ ë‹µë³€ ë°›ì„ì§€ ì„ íƒ
choices = []
if ready_google: choices.append("Gemini")
if ready_openai: choices.append("ChatGPT")
answer_with = st.radio("ë‹µë³€í•  AI ì„ íƒ", choices, horizontal=True, index=0)

# í”„ë¡¬í”„íŠ¸ë“¤
from src.prompts import EXPLAINER_PROMPT, ANALYST_PROMPT, READER_PROMPT
mode = st.radio("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…", "ğŸ” êµ¬ë¬¸ ë¶„ì„", "ğŸ“š ë…í•´ ë° ìš”ì•½"], horizontal=True, key="mode_select")

# ì…ë ¥ì°½
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜, ë¶„ì„/ìš”ì•½í•  ë¬¸ì¥ì´ë‚˜ ê¸€ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"): st.markdown(user_input)

    # í”„ë¡¬í”„íŠ¸ ì„ íƒ
    system_prompt = EXPLAINER_PROMPT if mode == "ğŸ’¬ ì´ìœ ë¬¸ë²• ì„¤ëª…" else (ANALYST_PROMPT if mode == "ğŸ” êµ¬ë¬¸ ë¶„ì„" else READER_PROMPT)

    # ì„ íƒëœ ì—”ì§„
    qe = st.session_state.get("qe_google" if answer_with == "Gemini" else "qe_openai")
    if qe is None:
        st.warning(f"{answer_with} ë‘ë‡Œê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì–´ìš”. ìœ„ì—ì„œ ë¨¼ì € ì¤€ë¹„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        with st.spinner(f"{answer_with}ê°€ ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
            answer = get_text_answer(qe, user_input, system_prompt)

        # ì–´ëŠ AIì¸ì§€ ë¼ë²¨ë§í•˜ì—¬ ì¶œë ¥
        label = "ğŸ¤– Gemini" if answer_with == "Gemini" else "ğŸ¤– ChatGPT"
        content = f"**{label}**\n\n{answer}"
        st.session_state.messages.append({"role": "assistant", "content": content})
        with st.chat_message("assistant"): st.markdown(content)

    st.rerun()
