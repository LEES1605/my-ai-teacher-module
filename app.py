# app.py ‚Äî Ïä§ÌÖù Ïù∏Îç±Ïã±(Ï§ëÍ∞ÑÏ∑®ÏÜå/Ïû¨Í∞ú) + ÎëêÎáåÏ§ÄÎπÑ ÏïàÏ†ïÌôî
#        + Ïù∏Îç±Ïã± Î≥¥Í≥†ÏÑú(Ïä§ÌÇµ ÌëúÏãú)
#        + Drive ÎåÄÌôîÎ°úÍ∑∏ Ï†ÄÏû•(‚ù∂ OAuth: Markdown / ‚ù∑ ÏÑúÎπÑÏä§Í≥ÑÏ†ï: JSONL, chat_log/)
#        + ÌéòÎ•¥ÏÜåÎÇò: ü§ñGemini(ÏπúÏ†à/ÍººÍºº), ü§ñChatGPT(Ïú†Î®∏Îü¨Ïä§/Î≥¥ÏôÑ)

from __future__ import annotations
import os, time, uuid, re, json
import pandas as pd
import streamlit as st

# ============= 0) ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï (Î∞òÎìúÏãú ÏµúÏÉÅÎã®) ====================================
st.set_page_config(page_title="ÎÇòÏùò AI ÏòÅÏñ¥ ÍµêÏÇ¨", layout="wide", initial_sidebar_state="collapsed")

# ============= 1) Î∂ÄÌä∏ Í∞ÄÎìú & Îü∞ÌÉÄÏûÑ ÏïàÏ†ïÌôî ===================================
ss = st.session_state
ss.setdefault("_boot_log", [])
ss.setdefault("_oauth_checked", False)

def _boot(msg: str): ss["_boot_log"].append(msg)

with st.sidebar:
    st.caption("üõ† Boot log (ÏûÑÏãú)")
    _boot_box = st.empty()

def _flush_boot():
    try:
        _boot_box.write("\n".join(ss["_boot_log"]) or "(empty)")
    except Exception:
        pass

_boot("A: page_config set"); _flush_boot()

# Îü∞ÌÉÄÏûÑ ÌäúÎãù(Î∂àÌïÑÏöîÌïú Î¶¨ÏÜåÏä§/Í≤ΩÌï© Î∞©ÏßÄ)
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_SERVER_ENABLE_WEBSOCKET_COMPRESSION"] = "false"

# ============= 2) ÏÑ∏ÏÖò ÌÇ§ Ï¥àÍ∏∞Ìôî ==============================================
ss.setdefault("session_id", uuid.uuid4().hex[:12])
ss.setdefault("messages", [])
ss.setdefault("auto_save_chatlog", True)    # OAuth Markdown Ï†ÄÏû•(ÎÇ¥ ÎìúÎùºÏù¥Î∏å)
ss.setdefault("save_logs", False)           # SA JSONL Ï†ÄÏû•(Í≥µÏú†ÎìúÎùºÏù¥Î∏å writer ÌïÑÏöî)
ss.setdefault("prep_both_running", False)
ss.setdefault("prep_both_done", ("qe_google" in ss) or ("qe_openai" in ss))
ss.setdefault("prep_cancel_requested", False)
ss.setdefault("session_terminated", False)
ss.setdefault("index_job", None)

# (ÏßÑÎã®) ÌïòÌä∏ÎπÑÌä∏
st.caption(f"heartbeat ‚úÖ keys={list(ss.keys())[:8]}")

# ============= 3) Í∏∞Î≥∏ UI Ìó§Îçî/Ïä§ÌÉÄÏùº =========================================
from src.ui import load_css, render_header
load_css()
render_header()
st.info("‚úÖ Î≥ÄÍ≤ΩÏù¥ ÏûàÏùÑ ÎïåÎßå Ïù∏Îç±Ïã±Ìï©ÎãàÎã§. Ï†ÄÏû•Îêú ÎëêÎáåÍ∞Ä ÏûàÏúºÎ©¥ Ï¶âÏãú Î°úÎìúÌï©ÎãàÎã§. (Ï§ëÍ∞Ñ Ï∑®ÏÜå/Ïû¨Í∞ú ÏßÄÏõê)")

# ============= 4) OAuth Î¶¨Îã§Ïù¥Î†âÌä∏ Ï≤òÎ¶¨(ÏµúÏ¢ÖÌôî 1ÌöåÎßå) ==========================
#  - Ïù¥Ï†Ñ ÏΩîÎìúÏóê ÏûàÏóàÎçò Ïù¥Ï§ë Ìò∏Ï∂úÏùÑ Ï†úÍ±∞ÌïòÏó¨ ÍπîÎÅîÌïòÍ≤å Ïú†ÏßÄ
try:
    from src.google_oauth import finish_oauth_if_redirected
    if not st.secrets.get("OAUTH_DISABLE_FINISH"):
        if not ss.get("_oauth_finalized", False):
            finalized = finish_oauth_if_redirected()
            if finalized:
                ss["_oauth_finalized"] = True
                try:
                    st.query_params.clear()
                except Exception:
                    st.experimental_set_query_params()
                st.rerun()
except Exception as e:
    st.warning(f"OAuth finalize skipped: {e}")

# ============= 5) ÏÇ¨Ïù¥ÎìúÎ∞î: OAuth Î°úÍ∑∏Ïù∏/Î°úÍ∑∏ÏïÑÏõÉ, Ï†ÄÏû• ÏòµÏÖò ==================
from src.google_oauth import start_oauth, is_signed_in, build_drive_service, get_user_email, sign_out
with st.sidebar:
    ss.auto_save_chatlog = st.toggle(
        "ÎåÄÌôî ÏûêÎèô Ï†ÄÏû• (OAuth/ÎÇ¥ ÎìúÎùºÏù¥Î∏å, Markdown)",
        value=ss.auto_save_chatlog
    )
    ss.save_logs = st.toggle(
        "ÎåÄÌôî JSONL Ï†ÄÏû• (ÏÑúÎπÑÏä§Í≥ÑÏ†ï/chat_log/)",
        value=ss.save_logs,
        help="Í≥µÏú†ÎìúÎùºÏù¥Î∏å Writer Í∂åÌïú ÌïÑÏöî. ÏøºÌÑ∞ Î¨∏Ï†ú Ïãú ÎÅÑÍ∏∞ Í∂åÏû•."
    )
    st.markdown("---")
    st.markdown("### Google Î°úÍ∑∏Ïù∏ (ÎÇ¥ ÎìúÎùºÏù¥Î∏å Ï†ÄÏû•)")
    if not is_signed_in():
        if st.button("üîê GoogleÎ°ú Î°úÍ∑∏Ïù∏"):
            url = start_oauth()
            st.markdown(f"[Ïó¨Í∏∞Î•º ÎàåÎü¨ Î°úÍ∑∏Ïù∏ÌïòÏÑ∏Ïöî]({url})")
    else:
        st.success(f"Î°úÍ∑∏Ïù∏Îê®: {get_user_email() or 'Ïïå Ïàò ÏóÜÏùå'}")
        if st.button("Î°úÍ∑∏ÏïÑÏõÉ"):
            sign_out()
            st.rerun()

# ============= 6) Google Drive Ïó∞Í≤∞ ÌÖåÏä§Ìä∏(ÏïàÏ†ïÌôî Î≤ÑÏ†Ñ) ========================
st.markdown("## üîó Google Drive Ïó∞Í≤∞ ÌÖåÏä§Ìä∏")
st.caption("ÏÑúÎπÑÏä§Í≥ÑÏ†ï Ï†ÄÏû•ÏùÄ Í≥µÏú†ÎìúÎùºÏù¥Î∏å Writer Í∂åÌïúÏù¥ ÌïÑÏöî. Ïù∏Îç±Ïã±ÏùÄ ReadonlyÎ©¥ Ï∂©Î∂ÑÌï©ÎãàÎã§.")

from src.config import settings
from src.rag_engine import smoke_test_drive, preview_drive_files, drive_diagnostics

try:
    ok_sa, head_sa, details_sa = drive_diagnostics(settings.GDRIVE_FOLDER_ID)  # (ok, Ìó§ÎìúÎùºÏù∏, ÏÉÅÏÑ∏ Î¶¨Ïä§Ìä∏[str])
    if ok_sa:
        st.success(head_sa)
    else:
        st.warning(head_sa)
    with st.expander("ÏÑúÎπÑÏä§Í≥ÑÏ†ï JSON ÏßÑÎã® ÏÉÅÏÑ∏", expanded=not ok_sa):
        st.code("\n".join(details_sa), language="text")
except Exception as e:
    st.warning("ÏßÑÎã® Ìï®Ïàò ÏòàÏô∏:")
    st.code(
        f"{type(e).__name__}: {e}\n"
        f"ÌÉÄÏûÖ={type(settings.GDRIVE_SERVICE_ACCOUNT_JSON).__name__}\n"
        f"ÌîÑÎ¶¨Î∑∞={str(settings.GDRIVE_SERVICE_ACCOUNT_JSON)[:200]}...",
        language="text"
    )

colL, colR = st.columns([0.65, 0.35], vertical_alignment="top")

with colL:
    if st.button("Ìè¥Îçî ÌååÏùº ÎØ∏Î¶¨Î≥¥Í∏∞ (ÏµúÏã† 10Í∞ú)", use_container_width=True):
        ok, msg, rows = preview_drive_files(max_items=10)
        if ok and rows:
            df = pd.DataFrame(rows)
            # Î≥¥Í∏∞ ÏπúÌôîÏ†ÅÏúºÎ°ú Í∞ÄÍ≥µ
            df["type"] = df["mime"].str.replace("application/vnd.google-apps.", "", regex=False)
            df = df.rename(columns={"modified": "modified_at"})[["name","link","type","modified_at"]]
            st.dataframe(
                df,
                use_container_width=True,
                height=360,
                column_config={
                    "name": st.column_config.TextColumn("ÌååÏùºÎ™Ö"),
                    "link": st.column_config.LinkColumn("open", display_text="Ïó¥Í∏∞"),
                    "type": st.column_config.TextColumn("Ïú†Ìòï"),
                    "modified_at": st.column_config.TextColumn("ÏàòÏ†ïÏãúÍ∞Å"),
                },
                hide_index=True
            )
            st.success(f"Ï¥ù {len(rows)}Í∞ú Ìï≠Î™© ÌëúÏãú (ÏµúÏã† 10Í∞ú Í∏∞Ï§Ä).")
        elif ok:
            st.info("Ìè¥ÎçîÏóê ÌååÏùºÏù¥ ÏóÜÍ±∞ÎÇò Ï†ëÍ∑ºÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
        else:
            st.error(msg)

with colR:
    ok, msg = smoke_test_drive()
    if ok:
        st.success(msg)     # ‚ö†Ô∏è Î∞òÌôòÍ∞íÏùÑ st.write Îì±ÏúºÎ°ú Îã§Ïãú Ï∞çÏßÄ ÏïäÏùå
    else:
        st.warning(msg)

# ============= 6.5) üì§ Í¥ÄÎ¶¨Ïûê: ÏûêÎ£å ÏóÖÎ°úÎìú (ÏõêÎ≥∏ ‚Üí prepared Ï†ÄÏû•) ===============
with st.expander("üì§ Í¥ÄÎ¶¨Ïûê: ÏûêÎ£å ÏóÖÎ°úÎìú (ÏõêÎ≥∏‚Üíprepared Ï†ÄÏû•)", expanded=False):
    st.caption(
        "ÏõêÎ≥∏ ÌååÏùºÏùÑ prepared Ìè¥ÎçîÏóê Ï†ÄÏû•Ìï©ÎãàÎã§. ÌÖçÏä§Ìä∏ Ï∂îÏ∂úÎ¨ºÏùÄ Ïù∏Îç±Ïä§ Ï∫êÏãúÏóêÎßå Ï†ÄÏû•Îê©ÎãàÎã§.\n"
        "Î°úÏª¨ ÌååÏùº ÏóÖÎ°úÎìú + Google Docs/Slides/Sheets URL Í∞ÄÏ†∏Ïò§Í∏∞ Î™®Îëê ÏßÄÏõêÌï©ÎãàÎã§.\n"
        "ÏòµÏÖòÏùÑ ÏºúÎ©¥ AIÍ∞Ä Ï†úÎ™©ÏùÑ Ï†ïÌï¥ ÌååÏùºÎ™ÖÏùÑ Î≥ÄÍ≤ΩÌï©ÎãàÎã§."
    )

    # ‚îÄ‚îÄ ÏòµÏÖò: AIÍ∞Ä Ï†úÎ™© ÏûêÎèô ÏÉùÏÑ± ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    auto_title = st.toggle("AI Ï†úÎ™© ÏûêÎèô ÏÉùÏÑ±(ÏóÖÎ°úÎìú/Í∞ÄÏ†∏Ïò§Í∏∞ ÌõÑ Ïù¥Î¶Ñ Î∞îÍæ∏Í∏∞)", value=True,
                           help="LLMÏù¥ ÏßßÍ≥† Î™ÖÌôïÌïú Ï†úÎ™©ÏùÑ ÎΩëÏïÑ ÌååÏùºÎ™ÖÏùÑ Î∞îÍøâÎãàÎã§. ÌÇ§Í∞Ä ÏóÜÏúºÎ©¥ Ìú¥Î¶¨Ïä§Ìã±ÏúºÎ°ú Ï†úÎ™© ÏÉùÏÑ±.")
    title_hint = st.text_input("Ï†úÎ™© ÌûåÌä∏(ÏÑ†ÌÉù)", placeholder="Ïòà: Í≥†1 ÏòÅÏñ¥ Î¨∏Î≤ï / ÌïôÏõê ÍµêÏû¨ / Ï§ëÍ∞ÑÍ≥†ÏÇ¨ ÎåÄÎπÑ Îì±")

    # ‚îÄ‚îÄ (A) Î°úÏª¨ ÌååÏùº ÏóÖÎ°úÎìú: Ïó¨Îü¨ ÌòïÏãù ÏßÄÏõê ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    SUPPORTED_TYPES = [
        "pdf", "docx", "doc", "pptx", "ppt", "md", "txt", "rtf", "odt", "html", "epub",
        "xlsx", "xls", "csv"
    ]
    files = st.file_uploader(
        "Î°úÏª¨ ÌååÏùº ÏÑ†ÌÉù (Ïó¨Îü¨ Í∞ú Í∞ÄÎä•)",
        type=SUPPORTED_TYPES,
        accept_multiple_files=True
    )

    # ‚îÄ‚îÄ (B) Google Docs/Slides/Sheets URLÎ°ú Í∞ÄÏ†∏Ïò§Í∏∞ (Ï§ÑÎ∞îÍøàÏúºÎ°ú Ïó¨Îü¨ Í∞ú) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    gdocs_urls = st.text_area(
        "Google Docs/Slides/Sheets URL Î∂ôÏó¨ÎÑ£Í∏∞ (Ïó¨Îü¨ Í∞úÎ©¥ Ï§ÑÎ∞îÍøàÏúºÎ°ú Íµ¨Î∂Ñ)",
        placeholder="Ïòà) https://docs.google.com/document/d/............/edit\nhttps://docs.google.com/presentation/d/............/edit",
        height=96
    )

    # ÏßÑÌñâ/ÏÉÅÌÉú ÏòÅÏó≠
    prog = st.progress(0, text="ÎåÄÍ∏∞ Ï§ë‚Ä¶")
    status_area = st.empty()
    result_area = st.empty()

    # ‚îÄ‚îÄ Ïú†Ìã∏: ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ/ÌååÏùºÎ™Ö Ï†ïÎ¶¨/ÌôïÏû•Ïûê‚ÜíMIME ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def _ts():
        import time
        return time.strftime("%Y%m%d_%H%M%S")

    def _safe_name(name: str) -> str:
        import re
        # Windows/NIX Í∏àÏßÄÎ¨∏Ïûê Ï†úÍ±∞
        name = re.sub(r'[\\/:*?"<>|]+', " ", name)
        name = re.sub(r"\s+", " ", name).strip()
        return name or "untitled"

    def _guess_mime_by_ext(fname: str) -> str:
        ext = (fname.rsplit(".", 1)[-1] if "." in fname else "").lower()
        MIMES = {
            "pdf":  "application/pdf",
            "docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "doc":  "application/msword",
            "pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
            "ppt":  "application/vnd.ms-powerpoint",
            "md":   "text/markdown",
            "txt":  "text/plain",
            "rtf":  "application/rtf",
            "odt":  "application/vnd.oasis.opendocument.text",
            "html": "text/html",
            "epub": "application/epub+zip",
            "xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            "xls":  "application/vnd.ms-excel",
            "csv":  "text/csv",
        }
        return MIMES.get(ext, "application/octet-stream")

    def _parse_gdoc_id(s: str) -> str | None:
        import re
        s = s.strip()
        if not s:
            return None
        for pat in [r"/d/([-\w]{15,})", r"[?&]id=([-\w]{15,})$", r"^([-\w]{15,})$"]:
            m = re.search(pat, s)
            if m:
                return m.group(1)
        return None

# ‚îÄ‚îÄ AI Ï†úÎ™© ÏÉùÏÑ±Í∏∞(LLM + Ìú¥Î¶¨Ïä§Ìã±) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from src.rag_engine import make_llm, llm_complete

def _get_title_model():
    """OpenAI ÏûàÏúºÎ©¥ OpenAI, ÏóÜÏúºÎ©¥ Gemini, Îëò Îã§ ÏóÜÏúºÎ©¥ None"""
    global _TITLE_MODEL                      # ‚Üê nonlocal ÎåÄÏã† global ÏÇ¨Ïö©
    if _TITLE_MODEL is not None:
        return _TITLE_MODEL
    try:
        from src.config import settings
        if getattr(settings, "OPENAI_API_KEY", None) and settings.OPENAI_API_KEY.get_secret_value():
            _TITLE_MODEL = make_llm(
                "openai",
                settings.OPENAI_API_KEY.get_secret_value(),
                getattr(settings, "OPENAI_LLM_MODEL", "gpt-4o-mini"),
                0.2,
            )
            return _TITLE_MODEL
        # OpenAI ÌÇ§ ÏóÜÏúºÎ©¥ GeminiÎ°ú
        _TITLE_MODEL = make_llm(
            "google",
            settings.GEMINI_API_KEY.get_secret_value(),
            getattr(settings, "LLM_MODEL", "gemini-1.5-pro"),
            0.2,
        )
        return _TITLE_MODEL
    except Exception:
        return None

def _heuristic_title(orig_base: str, hint: str = "") -> str:
    """ÌôïÏû•Ïûê Ï†úÍ±∞Îêú ÏõêÎûò Ïù¥Î¶Ñ + ÌûåÌä∏Î•º ÍπîÎÅîÌûà Ï†ïÎ¶¨Ìï¥ 40Ïûê ÎÇ¥Î°ú"""
    import re
    base = orig_base
    base = re.sub(r"\.[^.]+$", "", base)            # .ext Ï†úÍ±∞
    base = re.sub(r"^\d{8}_\d{6}__", "", base)      # ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ìå®ÌÑ¥ Ï†úÍ±∞
    base = base.replace("_", " ").replace("-", " ")
    base = re.sub(r"\s+", " ", base).strip()
    if hint:
        base = f"{hint.strip()} ‚Äî {base}" if base else hint.strip()
    return (base[:40]).strip() or "untitled"

def _ai_title(orig_base: str, sample_text: str = "", hint: str = "") -> str:
    """LLMÏúºÎ°ú ÏßßÏùÄ ÌïúÍµ≠Ïñ¥ Ï†úÎ™© ÏÉùÏÑ±(ÏµúÎåÄ 40Ïûê). Ïã§Ìå® Ïãú Ìú¥Î¶¨Ïä§Ìã±."""
    model = _get_title_model()
    if model is None:
        return _heuristic_title(orig_base, hint)

    prompt = (
        "Îã§Ïùå ÌååÏùºÏùò Ï†úÎ™©ÏùÑ ÌïúÍµ≠Ïñ¥Î°ú Í∞ÑÍ≤∞ÌïòÍ≤å ÎßåÎì§Ïñ¥ Ï£ºÏÑ∏Ïöî. Í∑úÏπô:\n"
        "1) ÏµúÎåÄ 40Ïûê, 2) Î∂àÌïÑÏöîÌïú Ïà´Ïûê/ÌôïÏû•Ïûê Ï†úÍ±∞, 3) ÌïµÏã¨ ÌÇ§ÏõåÎìú ÏúÑÏ£º, 4) Îî∞Ïò¥Ìëú/Í¥ÑÌò∏ ÎÇ®Î∞ú Í∏àÏßÄ,\n"
        "5) Î¨∏Ïû•Ìòï ÎßêÌà¨Î≥¥Îã§ Î™ÖÏÇ¨Íµ¨ ÏÑ†Ìò∏, 6) Ï∂úÎ†•ÏùÄ Ï†úÎ™©Îßå(Î∂ÄÍ∞Ä ÏÑ§Î™Ö/Îî∞Ïò¥Ìëú X).\n\n"
        f"[ÌååÏùºÎ™Ö ÌûåÌä∏]\n{orig_base}\n\n"
    )
    if hint:
        prompt += f"[Ï∂îÍ∞Ä ÌûåÌä∏]\n{hint}\n\n"
    if sample_text:
        prompt += f"[Î≥∏Î¨∏ ÏùºÎ∂Ä]\n{sample_text[:1200]}\n\n"

    try:
        title = llm_complete(model, prompt).strip()
        # ÏïàÏ†ÑÌôî (ÏïÑÎûò _safe_nameÏùÄ Í∞ôÏùÄ ÏÑπÏÖòÏóê Ïù¥ÎØ∏ Ï†ïÏùòÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§)
        title = _safe_name(title)
        return (title[:40]).strip() or _heuristic_title(orig_base, hint)
    except Exception:
        return _heuristic_title(orig_base, hint)

    # ‚îÄ‚îÄ ÏóÖÎ°úÎìú/Í∞ÄÏ†∏Ïò§Í∏∞ Ïã§Ìñâ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if st.button("ÏóÖÎ°úÎìú/Í∞ÄÏ†∏Ïò§Í∏∞ ‚Üí prepared", type="primary"):
        import io, time
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaIoBaseUpload
        from googleapiclient.errors import HttpError
        from src.rag_engine import _normalize_sa
        from src.config import settings
        from src.google_oauth import is_signed_in, build_drive_service

        # ÏÑúÎπÑÏä§Í≥ÑÏ†ï Drive(Ïì∞Í∏∞), OAuth Drive(ÏûàÏúºÎ©¥ ÏùΩÍ∏∞/Î≥µÏÇ¨)
        creds_sa = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
        drive_sa = build("drive", "v3", credentials=creds_sa)
        drive_oauth = build_drive_service() if is_signed_in() else None

        rows, done, total_steps = [], 0, 1
        if files: total_steps += len(files)
        url_list = [u.strip() for u in (gdocs_urls.splitlines() if gdocs_urls else []) if u.strip()]
        if url_list: total_steps += len(url_list)

        def _tick(msg):
            nonlocal done
            done += 1
            pct = int(done / max(total_steps, 1) * 100)
            prog.progress(pct, text=msg)
            status_area.info(msg)

        # ÏóÖÎ°úÎìú/Í∞ÄÏ†∏Ïò§Í∏∞ Í≤∞Í≥º(Drive id, name, link) Ï†ÄÏû•
        created = []  # [{id, name, link, ext, orig_base, sample_text?}]

        try:
            # 1) Î°úÏª¨ ÌååÏùº ÏóÖÎ°úÎìú
            if files:
                for f in files:
                    data = f.read()
                    buf = io.BytesIO(data)
                    base = _safe_name(f.name)
                    ext = (base.rsplit(".", 1)[-1].lower() if "." in base else "")
                    name = f"{_ts()}__{base}"
                    mime = _guess_mime_by_ext(base)

                    media = MediaIoBaseUpload(buf, mimetype=mime, resumable=False)
                    meta = {"name": name, "parents": [settings.GDRIVE_FOLDER_ID]}
                    _tick(f"ÏóÖÎ°úÎìú Ï§ë: {name}")
                    res = drive_sa.files().create(body=meta, media_body=media, fields="id,webViewLink").execute()
                    created.append({"id": res["id"], "name": name, "link": res.get("webViewLink",""),
                                    "ext": ext, "orig_base": base, "sample_text": ""})

                    time.sleep(0.05)

            # 2) Google Î¨∏ÏÑú ÎßÅÌÅ¨ ‚Üí export/copy ÌõÑ Ï†ÄÏû•
            for raw in url_list:
                file_id = _parse_gdoc_id(raw)
                if not file_id:
                    rows.append({"name": f"(ÏûòÎ™ªÎêú ÎßÅÌÅ¨) {raw[:40]}‚Ä¶", "open": ""})
                    _tick("ÏûòÎ™ªÎêú ÎßÅÌÅ¨ Í±¥ÎÑàÎúÄ")
                    continue

                drive_ro = drive_oauth or drive_sa  # Î°úÍ∑∏Ïù∏ÎêòÏñ¥ ÏûàÏúºÎ©¥ OAuth Ïö∞ÏÑ†
                try:
                    meta = drive_ro.files().get(fileId=file_id, fields="id,name,mimeType").execute()
                    name0 = meta.get("name", "untitled")
                    mtype = meta.get("mimeType", "")
                except HttpError as he:
                    if drive_ro is drive_oauth:
                        try:
                            meta = drive_sa.files().get(fileId=file_id, fields="id,name,mimeType").execute()
                            name0 = meta.get("name", "untitled")
                            mtype = meta.get("mimeType", "")
                            drive_ro = drive_sa
                        except Exception as e2:
                            rows.append({"name": f"(Ï†ëÍ∑º Ïã§Ìå®) {raw[:40]}‚Ä¶", "open": f"{type(e2).__name__}: Í∂åÌïú ÌïÑÏöî"})
                            _tick("Ï†ëÍ∑º Ïã§Ìå®(Í≥µÏú† ÌïÑÏöî)")
                            continue
                    else:
                        rows.append({"name": f"(Ï†ëÍ∑º Ïã§Ìå®) {raw[:40]}‚Ä¶", "open": f"{type(he).__name__}: Í∂åÌïú ÌïÑÏöî"})
                        _tick("Ï†ëÍ∑º Ïã§Ìå®(Í≥µÏú† ÌïÑÏöî)")
                        continue

                GOOGLE_NATIVE = {
                    "application/vnd.google-apps.document": ("application/pdf", ".pdf"),
                    "application/vnd.google-apps.presentation": ("application/pdf", ".pdf"),
                    "application/vnd.google-apps.spreadsheet": ("application/pdf", ".pdf"),
                }

                if mtype in GOOGLE_NATIVE:
                    export_mime, ext = GOOGLE_NATIVE[mtype]
                    _tick(f"ÎÇ¥Î≥¥ÎÇ¥Îäî Ï§ë: {name0}{ext} (Google Î¨∏ÏÑú)")
                    data = drive_ro.files().export(fileId=file_id, mimeType=export_mime).execute()
                    buf = io.BytesIO(data)
                    name = f"{_ts()}__{_safe_name(name0)}{ext}"
                    media = MediaIoBaseUpload(buf, mimetype=export_mime, resumable=False)
                    meta2 = {"name": name, "parents": [settings.GDRIVE_FOLDER_ID]}
                    res2 = drive_sa.files().create(body=meta2, media_body=media, fields="id,webViewLink").execute()
                    created.append({"id": res2["id"], "name": name, "link": res2.get("webViewLink",""),
                                    "ext": ext.strip("."), "orig_base": name0, "sample_text": ""})
                else:
                    # ÎÑ§Ïù¥Ìã∞Î∏åÍ∞Ä ÏïÑÎãå Í≤ΩÏö∞: preparedÎ°ú Î≥µÏÇ¨
                    _tick(f"Î≥µÏÇ¨ Ï§ë: {name0} (ÌååÏùº)")
                    body = {"name": f"{_ts()}__{_safe_name(name0)}", "parents": [settings.GDRIVE_FOLDER_ID]}
                    try:
                        res3 = drive_sa.files().copy(fileId=file_id, body=body, fields="id,webViewLink").execute()
                    except HttpError:
                        if drive_oauth:
                            res3 = drive_oauth.files().copy(fileId=file_id, body=body, fields="id,webViewLink").execute()
                        else:
                            rows.append({"name": f"(Î≥µÏÇ¨ Ïã§Ìå®) {name0}", "open": "Í∂åÌïú Î∂ÄÏ°± ‚Äî ÏÑúÎπÑÏä§Í≥ÑÏ†ïÏóê Í≥µÏú†ÌïòÍ±∞ÎÇò OAuth Î°úÍ∑∏Ïù∏"})
                            continue
                    created.append({"id": res3["id"], "name": body["name"], "link": res3.get("webViewLink",""),
                                    "ext": "", "orig_base": name0, "sample_text": ""})
                    time.sleep(0.05)

            # 3) (ÏòµÏÖò) AI Ï†úÎ™©ÏúºÎ°ú ÌååÏùºÎ™Ö Î≥ÄÍ≤Ω
            renamed_rows = []
            if auto_title and created:
                used = set()
                for item in created:
                    fid = item["id"]
                    old_name = item["name"]
                    ext = f".{item['ext']}" if item.get("ext") else ""
                    # ÏÉòÌîå ÌÖçÏä§Ìä∏ ÌôïÎ≥¥: Í∞ÑÎã®Ìûà ÏõêÎûò Ïù¥Î¶ÑÎßåÏúºÎ°úÎèÑ Í∞ÄÎä•, ÌÖçÏä§Ìä∏ ÌååÏùº/MDÎ©¥ ÏùºÎ∂Ä Î≥∏Î¨∏ÍπåÏßÄ
                    sample = ""
                    if item.get("ext") in {"txt", "md"}:
                        # ÌÖçÏä§Ìä∏/MDÎäî ÏõêÎ≥∏ ÏóÖÎ°úÎìú Ï†ÑÏóêÎèÑ ÏùΩÏùÑ Ïàò ÏûàÏßÄÎßå ÏßÄÍ∏àÏùÄ Ïù¥ÎØ∏ ÏóÖÎ°úÎìú ÏÉÅÌÉú.
                        # Í∞ÑÎã®Ìûà ÌååÏùºÎ™Ö Í∏∞Î∞òÏúºÎ°úÎèÑ Ï∂©Î∂Ñ. (Ï∂îÌõÑ Drive download ÌõÑ Î≥∏Î¨∏ ÏÇ¨Ïö© Í∞ÄÎä•)
                        sample = ""

                    ai_title = _ai_title(item.get("orig_base", old_name), sample_text=sample, hint=title_hint)
                    # ÏµúÏ¢Ö ÌååÏùºÎ™Ö: ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ__AIÏ†úÎ™© + ÏõêÎûò ÌôïÏû•Ïûê
                    new_name = f"{_ts()}__{ai_title}{ext}"
                    new_name = _safe_name(new_name)
                    # Ï§ëÎ≥µ ÏµúÏÜåÌôî(ÎèôÏùº Î∞∞Ïπò ÎÇ¥)
                    k = new_name; n = 2
                    while k in used:
                        k = f"{new_name} ({n})"; n += 1
                    new_name = k; used.add(new_name)

                    try:
                        upd = drive_sa.files().update(fileId=fid, body={"name": new_name}).execute()
                        renamed_rows.append({"original": old_name, "renamed_to": new_name, "open": item["link"]})
                    except Exception as e:
                        renamed_rows.append({"original": old_name, "renamed_to": f"(Ïù¥Î¶Ñ Î≥ÄÍ≤Ω Ïã§Ìå®) {e}", "open": item["link"]})
            else:
                for item in created:
                    renamed_rows.append({"original": item["name"], "renamed_to": "(AI Ï†úÎ™© ÏÉùÏÑ± Í∫ºÏßê)", "open": item["link"]})

            # 4) Í≤∞Í≥º ÌëúÏãú
            prog.progress(100, text="ÏôÑÎ£å")
            status_area.success(f"Ï¥ù {len(created)}Í∞ú Ìï≠Î™© Ï≤òÎ¶¨ ÏôÑÎ£å (prepared)")
            if renamed_rows:
                import pandas as pd
                df = pd.DataFrame(renamed_rows)
                result_area.dataframe(
                    df, use_container_width=True, hide_index=True,
                    column_config={
                        "original": st.column_config.TextColumn("ÏõêÎûò ÌååÏùºÎ™Ö"),
                        "renamed_to": st.column_config.TextColumn("Î≥ÄÍ≤Ω ÌõÑ ÌååÏùºÎ™Ö"),
                        "open": st.column_config.LinkColumn("Ïó¥Í∏∞", display_text="Ïó¥Í∏∞")
                    }
                )
            st.toast("ÏóÖÎ°úÎìú/Í∞ÄÏ†∏Ïò§Í∏∞ ÏôÑÎ£å ‚Äî Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ÏùÄ Ïù∏Îç±Ïã± Ïãú Î∞òÏòÅÎê©ÎãàÎã§.", icon="‚úÖ")

            # Ïù∏Îç±Ïã±ÏùÑ Îã§Ïãú ÎèåÎ¶¥ Ïàò ÏûàÎèÑÎ°ù Ï§ÄÎπÑ Î≤ÑÌäº Ïû¨ÌôúÏÑ±Ìôî
            ss.prep_both_done = False

        except Exception as e:
            prog.progress(0, text="Ïò§Î•ò")
            status_area.error(f"Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
# ==============================================================================

# ============= 6.7) üìö Î¨∏Î≤ïÏÑú ÌÜ†ÌîΩÎ≥Ñ ÏÜåÏ±ÖÏûê ÏÉùÏÑ±(Drive Ï†ÄÏû•) =====================
with st.expander("üìö Î¨∏Î≤ïÏÑú ÌÜ†ÌîΩÎ≥Ñ ÏÜåÏ±ÖÏûê ÏÉùÏÑ±(Drive Ï†ÄÏû•)", expanded=False):
    st.caption(
        "ÏõêÎ≥∏ÏùÄ prepared/Ïóê Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Î¨∏Î≤ï ÌÜ†ÌîΩÎ≥Ñ ÏµúÏ†ÅÌôîÎêú ÏÜåÏ±ÖÏûê(.md)Î•º "
        "prepared_volumes/ ÌïòÏúÑ Ìè¥ÎçîÏóê Ï†ÄÏû•Ìï©ÎãàÎã§. overview.mdÏôÄ manifest.jsonÎèÑ Ìï®Íªò ÏÉùÏÑ±Ìï©ÎãàÎã§."
    )

    default_topics = [
        "Parts of Speech(ÌíàÏÇ¨)", "Articles(Í¥ÄÏÇ¨)", "Nouns & Pronouns(Î™ÖÏÇ¨/ÎåÄÎ™ÖÏÇ¨)",
        "Verbs & Tenses(ÏãúÏ†ú: ÌòÑÏû¨/Í≥ºÍ±∞/ÏôÑÎ£å/ÏßÑÌñâ)", "Modals(Ï°∞ÎèôÏÇ¨)", "Passive(ÏàòÎèôÌÉú)",
        "Gerunds & Infinitives(ÎèôÎ™ÖÏÇ¨/Î∂ÄÏ†ïÏÇ¨)", "Adjectives & Adverbs(ÌòïÏö©ÏÇ¨/Î∂ÄÏÇ¨/ÎπÑÍµêÍ∏â)",
        "Prepositions(Ï†ÑÏπòÏÇ¨)", "Phrasal Verbs(Íµ¨ÎèôÏÇ¨)", "Conjunctions & Clauses(Ï†ëÏÜçÏÇ¨/Ï†à)",
        "Conditionals(Ï°∞Í±¥Î¨∏)", "Relative Clauses(Í¥ÄÍ≥ÑÏÇ¨Ï†à)", "Reported Speech(ÌôîÎ≤ïÏ†ÑÌôò)",
        "Questions & Negation(ÏùòÎ¨∏Î¨∏/Î∂ÄÏ†ïÎ¨∏)", "Sentence Structure(Î¨∏Ïû•Íµ¨Ï°∞¬∑Ïñ¥Ïàú)"
    ]
    topics_text = st.text_area(
        "ÌÜ†ÌîΩ Î™©Î°ù(Ï§ÑÎ∞îÍøàÏúºÎ°ú Íµ¨Î∂Ñ, ÏàòÏ†ï Í∞ÄÎä•)", 
        value="\n".join(default_topics), height=200
    )
    booklet_title = st.text_input("ÏÜåÏ±ÖÏûê ÏÑ∏Ìä∏ Ï†úÎ™©(Ìè¥ÎçîÎ™Ö)", value="Grammar Booklets")
    make_citations = st.toggle("ÏÜåÏ±ÖÏûê ÌïòÎã®Ïóê ‚ÄòÏ∞∏Í≥† ÏûêÎ£å(Ï∂úÏ≤ò)‚Äô Ìè¨Ìï®", value=True)
    start_btn = st.button("ÌÜ†ÌîΩÎ≥Ñ ÏÜåÏ±ÖÏûê ÏÉùÏÑ± ‚Üí Drive Ï†ÄÏû•", type="primary", use_container_width=True)

    if start_btn:
        if "qe_google" not in ss:
            st.warning("Î®ºÏ†Ä ÏÉÅÎã®Ïùò [üöÄ Ìïú Î≤àÏóê Ï§ÄÎπÑÌïòÍ∏∞]Î°ú Ïù∏Îç±Ïä§Î•º Ï§ÄÎπÑÌïòÏÑ∏Ïöî.")
        else:
            import re, json, time, io
            import pandas as pd
            from googleapiclient.discovery import build
            from googleapiclient.http import MediaIoBaseUpload
            from src.rag_engine import _normalize_sa, get_text_answer
            from src.config import settings

            def _ts(): return time.strftime("%Y%m%d_%H%M%S")
            def _safe(s: str) -> str:
                s = re.sub(r'[\\/:*?"<>|]+', " ", str(s))
                s = re.sub(r"\s+", " ", s).strip()
                return s[:120] or "untitled"

            # 1) Drive Ï§ÄÎπÑ: prepared_volumes/<ÏÑ∏Ìä∏Î™Ö_ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ>/ ÏÉùÏÑ±
            creds = _normalize_sa(settings.GDRIVE_SERVICE_ACCOUNT_JSON)
            drive = build("drive", "v3", credentials=creds)

            def _ensure_child(parent_id: str, name: str) -> str:
                q = (
                    f"'{parent_id}' in parents and name = '{name}' "
                    "and mimeType = 'application/vnd.google-apps.folder' and trashed = false"
                )
                res = drive.files().list(
                    q=q, fields="files(id,name)", pageSize=1,
                    includeItemsFromAllDrives=True, supportsAllDrives=True
                ).execute()
                files = res.get("files", [])
                if files: 
                    return files[0]["id"]
                meta = {"name": name, "parents":[parent_id], "mimeType": "application/vnd.google-apps.folder"}
                f = drive.files().create(body=meta, fields="id").execute()
                return f["id"]

            parent_volumes_id = _ensure_child(settings.GDRIVE_FOLDER_ID, "prepared_volumes")
            set_name = f"{_safe(booklet_title)}_{_ts()}"
            set_folder = _ensure_child(parent_volumes_id, set_name)

            # 2) ÌÜ†ÌîΩÎ≥Ñ ÏÉùÏÑ±
            topics = [t.strip() for t in topics_text.splitlines() if t.strip()]
            prog = st.progress(0, text="ÏÉùÏÑ± Ï§ë‚Ä¶")
            table_rows, manifest = [], {"title": booklet_title, "created_at": _ts(), "items": []}

            for i, topic in enumerate(topics, start=1):
                # ÌîÑÎ°¨ÌîÑÌä∏(ÏõêÏ†Ñ Í∏∞Î∞ò ÏöîÏïΩ)
                guide = (
                    "ÎãπÏã†ÏùÄ ÏòÅÏñ¥ Î¨∏Î≤ï ÍµêÏÇ¨ÏûÖÎãàÎã§. ÏïÑÎûò ÌÜ†ÌîΩÏùÑ ÌïôÏÉùÏö© ÏÜåÏ±ÖÏûê ÌòïÌÉúÎ°ú Ï†ïÎ¶¨ÌïòÏÑ∏Ïöî.\n"
                    f"‚Ä¢ ÌÜ†ÌîΩ: {topic}\n"
                    "‚Ä¢ ÌïµÏã¨ Í∞úÎÖêÏùÑ ÌïúÍµ≠Ïñ¥Î°ú, Í∑úÏπô/ÌòïÌÉúÎäî ÏòÅÎ¨∏ ÌòºÏö©\n"
                    "‚Ä¢ ÏòàÎ¨∏ 3~5Í∞ú (Ïâ¨Ïö¥‚ÜíÏ§ëÍ∞Ñ ÎÇúÏù¥ÎèÑ), Ìïú-ÏòÅ Î≥ëÍ∏∞\n"
                    "‚Ä¢ ÏûêÏ£º ÌïòÎäî Ïã§Ïàò/Ïò§Í∞úÎÖê 3Í∞ú Ï†ïÎ¶¨\n"
                    "‚Ä¢ ÎØ∏Îãà Ïó∞ÏäµÎ¨∏Ï†ú 5Î¨∏Ìï≠(+Ï†ïÎãµ/Ìï¥ÏÑ§)\n"
                    "‚Ä¢ Î∂ÑÎüâ 500~900Ïûê ÎÇ¥Ïô∏\n"
                )
                if make_citations:
                    guide += "‚Ä¢ ÎßàÏßÄÎßâÏóê ‚Äò---\\n*Ï∞∏Í≥† ÏûêÎ£å: ÌååÏùºÎ™Ö ‚Ä¶‚Äô ÏÑπÏÖò Ìè¨Ìï®\n"

                # ÏÉùÏÑ±
                md = get_text_answer(
                    ss["qe_google"],
                    f"[ÌÜ†ÌîΩ]\n{topic}\n\n[Í≥ºÏ†ú]\nÏúÑ Í∞ÄÏù¥ÎìúÎ•º Îî∞Î•¥Îêò, ÌïôÏÉùÏö© ÎßàÌÅ¨Îã§Ïö¥ÏúºÎ°ú ÏûëÏÑ±",
                    guide,
                )
                name = f"{_safe(topic)}.md"

                # DriveÏóê ÏóÖÎ°úÎìú
                buf = io.BytesIO(md.encode("utf-8"))
                media = MediaIoBaseUpload(buf, mimetype="text/markdown", resumable=False)
                meta = {"name": name, "parents": [set_folder]}
                file = drive.files().create(body=meta, media_body=media, fields="id,webViewLink").execute()

                table_rows.append({"topic": topic, "open": file.get("webViewLink")})
                manifest["items"].append({"topic": topic, "file_id": file["id"], "name": name})

                prog.progress(int(i/len(topics)*100), text=f"[{i}/{len(topics)}] {topic}")

            # 3) overview.md & manifest.json Ï†ÄÏû•
            overview_lines = [f"# {booklet_title}", "", f"ÏÉùÏÑ±ÏãúÍ∞Å: {time.strftime('%Y-%m-%d %H:%M:%S')} (KST)", ""]
            for it in manifest["items"]:
                overview_lines.append(f"- {it['topic']} ‚Äî {it['name']}")
            overview_md = "\n".join(overview_lines) + "\n"

            # overview
            ov_buf = io.BytesIO(overview_md.encode("utf-8"))
            ov_meta = {"name": "overview.md", "parents": [set_folder]}
            ov_media = MediaIoBaseUpload(ov_buf, mimetype="text/markdown", resumable=False)
            ov_file = drive.files().create(body=ov_meta, media_body=ov_media, fields="id,webViewLink").execute()

            # manifest
            mf_buf = io.BytesIO(json.dumps(manifest, ensure_ascii=False, indent=2).encode("utf-8"))
            mf_meta = {"name": "manifest.json", "parents": [set_folder]}
            mf_media = MediaIoBaseUpload(mf_buf, mimetype="application/json", resumable=False)
            mf_file = drive.files().create(body=mf_meta, media_body=mf_media, fields="id,webViewLink").execute()

            prog.progress(100, text="ÏôÑÎ£å")
            st.success(f"Ï¥ù {len(table_rows)}Í∞ú ÏÜåÏ±ÖÏûê ÏÉùÏÑ± ‚Üí Ìè¥Îçî: prepared_volumes/{set_name}")
            if table_rows:
                st.dataframe(
                    pd.DataFrame(table_rows),
                    use_container_width=True, hide_index=True,
                    column_config={
                        "topic": st.column_config.TextColumn("ÌÜ†ÌîΩ"),
                        "open": st.column_config.LinkColumn("Ïó¥Í∏∞", display_text="Ïó¥Í∏∞")
                    }
                )
            st.toast("Drive Ï†ÄÏû• ÏôÑÎ£å ‚Äî ÏõêÎ≥∏ÏùÄ prepared/ Ïú†ÏßÄ, ÏÜåÏ±ÖÏûêÎäî prepared_volumes/ Î≥¥Í¥Ä", icon="‚úÖ")
# ===============================================================================

# ============= 7) Ïù∏Îç±Ïã± Î≥¥Í≥†ÏÑú(Ïä§ÌÇµÎêú ÌååÏùº Ìè¨Ìï®) ===============================
rep = ss.get("indexing_report")
if rep:
    with st.expander("üßæ Ïù∏Îç±Ïã± Î≥¥Í≥†ÏÑú (Ïä§ÌÇµÎêú ÌååÏùº Î≥¥Í∏∞)", expanded=False):
        st.write(
            f"Ï¥ù ÌååÏùº(Îß§ÎãàÌéòÏä§Ìä∏): {rep.get('total_manifest')}, "
            f"Î°úÎî©Îêú Î¨∏ÏÑú Ïàò: {rep.get('loaded_docs')}, "
            f"Ïä§ÌÇµ: {rep.get('skipped_count')}"
        )
        skipped = rep.get("skipped", [])
        if skipped:
            st.dataframe(pd.DataFrame(skipped), use_container_width=True, hide_index=True)
        else:
            st.caption("Ïä§ÌÇµÎêú ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§ üéâ")

# ============= 8) ÎëêÎáå Ï§ÄÎπÑ(Ï¶ùÎ∂Ñ Ïù∏Îç±Ïã± ¬∑ Ï§ëÍ∞ÑÏ∑®ÏÜå/Ïû¨Í∞ú) =======================
st.markdown("---")
st.subheader("üß† ÎëêÎáå Ï§ÄÎπÑ ‚Äî Ï†ÄÏû•Î≥∏ Î°úÎìú ‚Üî Î≥ÄÍ≤Ω Ïãú Ï¶ùÎ∂Ñ Ïù∏Îç±Ïã± (Ï§ëÍ∞Ñ Ï∑®ÏÜå/Ïû¨Í∞ú)")

c_g, c_o = st.columns(2)
with c_g: st.caption("Gemini ÏßÑÌñâ"); g_bar = st.empty(); g_msg = st.empty()
with c_o: st.caption("ChatGPT ÏßÑÌñâ"); o_bar = st.empty(); o_msg = st.empty()

def _render_progress(slot_bar, slot_msg, pct: int, msg: str | None = None):
    p = max(0, min(100, int(pct)))
    slot_bar.markdown(
        f"<div class='gp-wrap'><div class='gp-fill' style='width:{p}%'></div>"
        f"<div class='gp-label'>{p}%</div></div>",
        unsafe_allow_html=True
    )
    if msg is not None:
        slot_msg.markdown(f"<div class='gp-msg'>{msg}</div>", unsafe_allow_html=True)

def _is_cancelled() -> bool:
    return bool(ss.get("prep_cancel_requested", False))

from src.rag_engine import (
    set_embed_provider, make_llm, CancelledError,
    start_index_builder, resume_index_builder, cancel_index_builder,
    get_text_answer, llm_complete,   # ÎåÄÌôî Îã®Í≥ÑÏóêÏÑú Ïû¨ÏÇ¨Ïö©
)

def run_prepare_both_step():
    # 1) ÏûÑÎ≤†Îî© ÏÑ§Ï†ï (OpenAI Ïö∞ÏÑ†, ÏóÜÏúºÎ©¥ Google)
    embed_provider = "openai"
    embed_api = (getattr(settings, "OPENAI_API_KEY", None).get_secret_value()
                 if getattr(settings, "OPENAI_API_KEY", None) else "")
    embed_model = getattr(settings, "OPENAI_EMBED_MODEL", "text-embedding-3-small")
    if not embed_api:
        embed_provider = "google"
        embed_api = settings.GEMINI_API_KEY.get_secret_value()
        embed_model = getattr(settings, "EMBED_MODEL", "text-embedding-004")
    try:
        _render_progress(g_bar, g_msg, 3, f"ÏûÑÎ≤†Îî© ÏÑ§Ï†ï({embed_provider})")
        _render_progress(o_bar, o_msg, 3, f"ÏûÑÎ≤†Îî© ÏÑ§Ï†ï({embed_provider})")
        set_embed_provider(embed_provider, embed_api, embed_model)
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"ÏûÑÎ≤†Îî© Ïã§Ìå®: {e}")
        _render_progress(o_bar, o_msg, 100, f"ÏûÑÎ≤†Îî© Ïã§Ìå®: {e}")
        ss.prep_both_running = False
        return

    # 2) Ïù∏Îç±Ïä§ Ïä§ÌÖù ÏßÑÌñâ
    def upd(p, m=None):
        _render_progress(g_bar, g_msg, p, m)
        _render_progress(o_bar, o_msg, p, m)

    def umsg(m):
        _render_progress(g_bar, g_msg, ss.get("p_shared", 0), m)
        _render_progress(o_bar, o_msg, ss.get("p_shared", 0), m)

    persist_dir = f"{getattr(settings,'PERSIST_DIR','/tmp/my_ai_teacher/storage_gdrive')}_shared"
    job = ss.get("index_job")

    try:
        if job is None:
            res = start_index_builder(
                update_pct=upd,
                update_msg=umsg,
                gdrive_folder_id=settings.GDRIVE_FOLDER_ID,
                raw_sa=settings.GDRIVE_SERVICE_ACCOUNT_JSON,
                persist_dir=persist_dir,
                manifest_path=getattr(settings, "MANIFEST_PATH", "/tmp/my_ai_teacher/drive_manifest.json"),
                max_docs=None,     # Ï†ÑÏ≤¥ Ïù∏Îç±Ïã±
                is_cancelled=_is_cancelled,
            )
        else:
            res = resume_index_builder(
                job=job,
                update_pct=upd,
                update_msg=umsg,
                is_cancelled=_is_cancelled,
                batch_size=6
            )

        status = res.get("status")
        if status == "running":
            ss.index_job = res["job"]
            _render_progress(g_bar, g_msg, res.get("pct", 8), res.get("msg", "ÏßÑÌñâ Ï§ë‚Ä¶"))
            _render_progress(o_bar, o_msg, res.get("pct", 8), res.get("msg", "ÏßÑÌñâ Ï§ë‚Ä¶"))
            time.sleep(0.15)
            st.rerun()
            return

        if status == "cancelled":
            ss.prep_both_running = False
            ss.prep_cancel_requested = False
            ss.index_job = None
            _render_progress(g_bar, g_msg, res.get("pct", 0), "ÏÇ¨Ïö©Ïûê Ï∑®ÏÜå")
            _render_progress(o_bar, o_msg, res.get("pct", 0), "ÏÇ¨Ïö©Ïûê Ï∑®ÏÜå")
            return

        if status != "done":
            _render_progress(g_bar, g_msg, 100, "Ïù∏Îç±Ïã± Ïã§Ìå®")
            _render_progress(o_bar, o_msg, 100, "Ïù∏Îç±Ïã± Ïã§Ìå®")
            ss.prep_both_running = False
            return

        index = res["index"]
        ss.index_job = None

    except Exception as e:
        ss.prep_both_running = False
        ss.index_job = None
        _render_progress(g_bar, g_msg, 100, f"ÏóêÎü¨: {e}")
        _render_progress(o_bar, o_msg, 100, f"ÏóêÎü¨: {e}")
        return

    # 3) QueryEngine ÏÉùÏÑ±
    try:
        g_llm = make_llm(
            "google",
            settings.GEMINI_API_KEY.get_secret_value(),
            getattr(settings, "LLM_MODEL", "gemini-1.5-pro"),
            float(ss.get("temperature", 0.0))
        )
        ss["llm_google"] = g_llm
        ss["qe_google"] = index.as_query_engine(
            llm=g_llm,
            response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
            similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
        )
        _render_progress(g_bar, g_msg, 100, "ÏôÑÎ£å!")
    except Exception as e:
        _render_progress(g_bar, g_msg, 100, f"Gemini Ï§ÄÎπÑ Ïã§Ìå®: {e}")

    try:
        if getattr(settings, "OPENAI_API_KEY", None) and settings.OPENAI_API_KEY.get_secret_value():
            o_llm = make_llm(
                "openai",
                settings.OPENAI_API_KEY.get_secret_value(),
                getattr(settings, "OPENAI_LLM_MODEL", "gpt-4o-mini"),
                float(ss.get("temperature", 0.0))
            )
            ss["llm_openai"] = o_llm
            ss["qe_openai"] = index.as_query_engine(
                llm=o_llm,
                response_mode=ss.get("response_mode", getattr(settings, "RESPONSE_MODE", "compact")),
                similarity_top_k=int(ss.get("similarity_top_k", getattr(settings, "SIMILARITY_TOP_K", 5))),
            )
            _render_progress(o_bar, o_msg, 100, "ÏôÑÎ£å!")
        else:
            _render_progress(o_bar, o_msg, 100, "ÌÇ§ ÎàÑÎùΩ ‚Äî OPENAI_API_KEY ÌïÑÏöî")
    except Exception as e:
        _render_progress(o_bar, o_msg, 100, f"ChatGPT Ï§ÄÎπÑ Ïã§Ìå®: {e}")

    ss.prep_both_running = False
    ss.prep_both_done = True
    time.sleep(0.2)
    st.rerun()

# Ïã§Ìñâ/Ï∑®ÏÜå Î≤ÑÌäº Ï§Ñ
left, right = st.columns([0.7, 0.3])
with left:
    clicked = st.button(
        "üöÄ Ìïú Î≤àÏóê Ï§ÄÎπÑÌïòÍ∏∞",
        key="prepare_both",
        use_container_width=True,
        disabled=ss.prep_both_running or ss.prep_both_done
    )
with right:
    cancel_clicked = st.button(
        "‚õî Ï§ÄÎπÑ Ï∑®ÏÜå",
        key="cancel_prepare",
        use_container_width=True,
        type="secondary",
        disabled=not ss.prep_both_running
    )

from src.rag_engine import cancel_index_builder  # Ïû¨ÎÖ∏Ï∂ú(Î™ÖÏãú)

if cancel_clicked and ss.prep_both_running:
    ss.prep_cancel_requested = True
    if ss.get("index_job"):
        cancel_index_builder(ss.index_job)
    st.rerun()

if clicked and not (ss.prep_both_running or ss.prep_both_done):
    ss.prep_cancel_requested = False
    ss.prep_both_running = True
    ss.index_job = None
    st.rerun()

if ss.prep_both_running:
    run_prepare_both_step()

st.caption("Ï§ÄÎπÑ Î≤ÑÌäºÏùÑ Îã§Ïãú ÌôúÏÑ±ÌôîÌïòÎ†§Î©¥ ÏïÑÎûò Ïû¨ÏÑ§Ï†ï Î≤ÑÌäºÏùÑ ÎàÑÎ•¥ÏÑ∏Ïöî.")
if st.button("üîß Ïû¨ÏÑ§Ï†ï(Î≤ÑÌäº Îã§Ïãú ÌôúÏÑ±Ìôî)", disabled=not ss.prep_both_done):
    ss.prep_both_done = False
    st.rerun()

# ============= 9) ÎåÄÌôî UI (Í∑∏Î£πÌÜ†Î°†) ===========================================
st.markdown("---")
st.subheader("üí¨ Í∑∏Î£πÌÜ†Î°† ‚Äî ÌïôÏÉù ‚Üî ü§ñGemini(ÏπúÏ†à/ÍººÍºº) ‚Üî ü§ñChatGPT(Ïú†Î®∏Îü¨Ïä§/Î≥¥ÏôÑ)")

ready_google = "qe_google" in ss
ready_openai = "qe_openai" in ss

if ss.session_terminated:
    st.warning("ÏÑ∏ÏÖòÏù¥ Ï¢ÖÎ£åÎêú ÏÉÅÌÉúÏûÖÎãàÎã§. ÏÉàÎ°úÍ≥†Ïπ®ÏúºÎ°ú Îã§Ïãú ÏãúÏûëÌïòÏÑ∏Ïöî.")
    st.stop()

if not ready_google:
    st.info("Î®ºÏ†Ä **[üöÄ Ìïú Î≤àÏóê Ï§ÄÎπÑÌïòÍ∏∞]**Î°ú ÎëêÎáåÎ•º Ï§ÄÎπÑÌïòÏÑ∏Ïöî. (OpenAI ÌÇ§ ÏóÜÏúºÎ©¥ GeminiÎßå ÏùëÎãµ)")
    st.stop()

# Í≥ºÍ±∞ Î©îÏãúÏßÄ Î†åÎçî
for m in ss.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Îß•ÎùΩ/ÎèÑÏö∞ÎØ∏
def _strip_sources(text: str) -> str:
    return re.sub(r"\n+---\n\*Ï∞∏Í≥† ÏûêÎ£å:.*$", "", text, flags=re.DOTALL)

def _build_context(messages, limit_pairs=2, max_chars=2000) -> str:
    pairs, buf_user = [], None
    for m in reversed(messages):
        role, content = m.get("role"), str(m.get("content","")).strip()
        if role == "assistant":
            content = re.sub(r"^\*\*ü§ñ .*?\*\*\s*\n+", "", content).strip()
            if buf_user is not None:
                pairs.append((buf_user, content))
                buf_user = None
                if len(pairs) >= limit_pairs:
                    break
        elif role == "user" and buf_user is None:
            buf_user = content
    pairs = list(reversed(pairs))
    blocks = [f"[ÌïôÏÉù]\n{u}\n\n[ÍµêÏÇ¨]\n{a}" for u,a in pairs]
    ctx = "\n\n---\n\n".join(blocks).strip()
    return ctx[-max_chars:] if len(ctx) > max_chars else ctx

from src.prompts import EXPLAINER_PROMPT, ANALYST_PROMPT, READER_PROMPT
def _persona():
    mode = ss.get("mode_select", "üí¨ Ïù¥Ïú†Î¨∏Î≤ï ÏÑ§Î™Ö")
    base = EXPLAINER_PROMPT if mode=="üí¨ Ïù¥Ïú†Î¨∏Î≤ï ÏÑ§Î™Ö" else (ANALYST_PROMPT if mode=="üîé Íµ¨Î¨∏ Î∂ÑÏÑù" else READER_PROMPT)
    common = "Ïó≠Ìï†: ÌïôÏÉùÏùò ÏòÅÏñ¥ Ïã§Î†•ÏùÑ ÎèïÎäî AI ÍµêÏÇ¨.\nÍ∑úÏπô: Í∑ºÍ±∞Í∞Ä Î∂àÏ∂©Î∂ÑÌïòÎ©¥ Í∑∏ ÏÇ¨Ïã§ÏùÑ Î™ÖÌôïÌûà Î∞ùÌûåÎã§. ÏòàÏãúÎäî ÏßßÍ≥† Ï†êÏßÑÏ†ÅÏúºÎ°ú."
    return base + "\n" + common

GEMINI_STYLE = "ÎãπÏã†ÏùÄ Ï∞©ÌïòÍ≥† ÎòëÎòëÌïú ÏπúÍµ¨ Í∞ôÏùÄ ÍµêÏÇ¨ÏûÖÎãàÎã§. Ïπ≠Ï∞¨Í≥º Í≤©Î†§, Ï†ïÌôïÌïú ÏÑ§Î™Ö."
CHATGPT_STYLE = (
    "ÎãπÏã†ÏùÄ Ïú†Î®∏Îü¨Ïä§ÌïòÏßÄÎßå Ï†ïÌôïÌïú ÎèôÎ£å ÍµêÏÇ¨ÏûÖÎãàÎã§. ÎèôÎ£å(Gemini)Ïùò ÎãµÏùÑ ÏùΩÍ≥† "
    "Îπ†ÏßÑ Î∂ÄÎ∂ÑÏùÑ Î≥¥ÏôÑ/ÍµêÏ†ïÌïòÍ≥† ÎßàÏßÄÎßâÏóê <ÏµúÏ¢Ö Ï†ïÎ¶¨>Î°ú ÏöîÏïΩÌïòÏÑ∏Ïöî. Í≥ºÌïú ÎÜçÎã¥ Í∏àÏßÄ."
)

mode = st.radio(
    "ÌïôÏäµ Î™®Îìú",
    ["üí¨ Ïù¥Ïú†Î¨∏Î≤ï ÏÑ§Î™Ö", "üîé Íµ¨Î¨∏ Î∂ÑÏÑù", "üìö ÎèÖÌï¥ Î∞è ÏöîÏïΩ"],
    horizontal=True, key="mode_select"
)

# ÏÑúÎπÑÏä§Í≥ÑÏ†ï JSONL Ï†ÄÏû• (chat_log/)
from src import chat_store
from src.drive_log import get_chatlog_folder_id, save_chatlog_markdown_oauth

def _jsonl_log(items):
    if not ss.save_logs:
        return
    try:
        parent_id = (getattr(settings, "CHATLOG_FOLDER_ID", None) or settings.GDRIVE_FOLDER_ID)
        sa = settings.GDRIVE_SERVICE_ACCOUNT_JSON
        if isinstance(sa, str):
            try:
                sa = json.loads(sa)
            except Exception:
                pass
        sub_id = get_chatlog_folder_id(parent_folder_id=parent_id, sa_json=sa)
        chat_store.append_jsonl(folder_id=sub_id, sa_json=sa, items=items)
        st.toast("ÎåÄÌôî JSONL Ï†ÄÏû• ÏôÑÎ£å", icon="üíæ")
    except Exception as e:
        st.warning(f"ÎåÄÌôî JSONL Ï†ÄÏû• Ïã§Ìå®: {e}")

# ÏûÖÎ†• & ÏùëÎãµ
user_input = st.chat_input("ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•ÌïòÍ±∞ÎÇò, Î∂ÑÏÑù/ÏöîÏïΩÌï† Î¨∏Ïû•Ïù¥ÎÇò Í∏ÄÏùÑ Î∂ôÏó¨ÎÑ£ÏúºÏÑ∏Ïöî.")
if user_input:
    ss.messages.append({"role":"user","content":user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    _jsonl_log([chat_store.make_entry(
        ss.session_id, "user", "user", user_input, mode, model="user"
    )])

    # Gemini 1Ï∞®
    with st.spinner("ü§ñ Gemini ÏÑ†ÏÉùÎãòÏù¥ Î®ºÏ†Ä ÎãµÌï©ÎãàÎã§‚Ä¶"):
        prev_ctx = _build_context(ss.messages[:-1], limit_pairs=2, max_chars=2000)
        gemini_query = (f"[Ïù¥Ï†Ñ ÎåÄÌôî]\n{prev_ctx}\n\n" if prev_ctx else "") + f"[ÌïôÏÉù ÏßàÎ¨∏]\n{user_input}"
        ans_g = get_text_answer(ss["qe_google"], gemini_query, _persona() + "\n" + GEMINI_STYLE)

    content_g = f"**ü§ñ Gemini**\n\n{ans_g}"
    ss.messages.append({"role":"assistant","content":content_g})
    with st.chat_message("assistant"):
        st.markdown(content_g)

    _jsonl_log([chat_store.make_entry(
        ss.session_id, "assistant", "Gemini", content_g, mode, model=getattr(settings,"LLM_MODEL","gemini")
    )])

    # ChatGPT Î≥¥ÏôÑ(ÌÇ§Í∞Ä ÏûàÏùÑ Îïå)
    if ready_openai:
        review_directive = (
            "Ïó≠Ìï†: ÎèôÎ£å AI ÏòÅÏñ¥ÍµêÏÇ¨\n"
            "Î™©Ìëú: [Ïù¥Ï†Ñ ÎåÄÌôî], [ÌïôÏÉù ÏßàÎ¨∏], [ÎèôÎ£åÏùò 1Ï∞® ÎãµÎ≥Ä]ÏùÑ ÏùΩÍ≥† ÏÇ¨Ïã§Ïò§Î•ò/Îπ†ÏßÑÏ†ê/Î™®Ìò∏Ìï®ÏùÑ Î≥¥ÏôÑ.\n"
            "ÏßÄÏπ®: 1)ÌïµÏã¨ Í∞ÑÍ≤∞ Ïû¨Ï†ïÎ¶¨ 2)ÌãÄÎ¶∞ Î∂ÄÎ∂Ñ Í∑ºÍ±∞ÏôÄ ÍµêÏ†ï 3)ÏòàÎ¨∏ 2~3Í∞ú 4)<ÏµúÏ¢Ö Ï†ïÎ¶¨>Î°ú ÏöîÏïΩ. Ïô∏Î∂ÄÍ≤ÄÏÉâ Í∏àÏßÄ."
        )
        prev_all = _build_context(ss.messages, limit_pairs=2, max_chars=2000)
        augmented = (
            (f"[Ïù¥Ï†Ñ ÎåÄÌôî]\n{prev_all}\n\n" if prev_all else "") +
            f"[ÌïôÏÉù ÏßàÎ¨∏]\n{user_input}\n\n"
            f"[ÎèôÎ£åÏùò 1Ï∞® ÎãµÎ≥Ä(Gemini)]\n{_strip_sources(ans_g)}\n\n"
            "[ÎãπÏã†Ïùò ÏûëÏóÖ]\nÏúÑ Í∏∞Ï§ÄÏúºÎ°úÎßå Î≥¥ÏôÑ/Í≤ÄÏ¶ù."
        )
        with st.spinner("ü§ù ChatGPT ÏÑ†ÏÉùÎãòÏù¥ Î≥¥ÏôÑ/Í≤ÄÏ¶ù Ï§ë‚Ä¶"):
            ans_o = llm_complete(
                ss.get("llm_openai"),
                _persona() + "\n" + CHATGPT_STYLE + "\n\n" + review_directive + "\n\n" + augmented
            )
        content_o = f"**ü§ñ ChatGPT**\n\n{ans_o}"
        ss.messages.append({"role":"assistant","content":content_o})
        with st.chat_message("assistant"):
            st.markdown(content_o)
    else:
        with st.chat_message("assistant"):
            st.info("ChatGPT ÌÇ§Í∞Ä ÏóÜÏñ¥ GeminiÎßå ÏùëÎãµÌñàÏäµÎãàÎã§. OPENAI_API_KEYÎ•º Ï∂îÍ∞ÄÌïòÎ©¥ Î≥¥ÏôÑ/Í≤ÄÏ¶ùÏù¥ ÌôúÏÑ±ÌôîÎê©ÎãàÎã§.")

    # OAuth Markdown Ï†ÄÏû•(ÎÇ¥ ÎìúÎùºÏù¥Î∏å)
    if ss.auto_save_chatlog and ss.messages:
        try:
            if is_signed_in():
                svc = build_drive_service()
                parent_id = (st.secrets.get("OAUTH_CHAT_PARENT_ID") or "").strip() or None
                _fid = save_chatlog_markdown_oauth(ss.session_id, ss.messages, svc, parent_id)
                st.toast("ÎÇ¥ ÎìúÎùºÏù¥Î∏åÏóê ÎåÄÌôî Ï†ÄÏû• ÏôÑÎ£å ‚úÖ", icon="üíæ")
            else:
                st.info("Íµ¨Í∏Ä Í≥ÑÏ†ïÏúºÎ°ú Î°úÍ∑∏Ïù∏ÌïòÎ©¥ ÎåÄÌôîÍ∞Ä **ÎÇ¥ ÎìúÎùºÏù¥Î∏å**Ïóê Ï†ÄÏû•Îê©ÎãàÎã§.")
        except Exception as e:
            st.warning(f"OAuth Ï†ÄÏû• Ïã§Ìå®: {e}")

# EOF
